<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your Spanish reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="Spanish reading, Spanish language learning, instant translations, reading adventure, improve Spanish, improve reading skills, educational platform, Spanish reading resources, online education, Spanish proficiency, learn Spanish, Spanish learning resources, bilingual education, language exchange, study Spanish online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title> TED-Ed : The 4 greatest threats to the survival of humanity</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>The 4 greatest threats to the survival of humanity</h1>
	<h2 class='speaker'> TED-Ed</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your Spanish speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">En enero de 1995, Rusia detectó
un misil nuclear en su dirección.<span class="tooltiptext">In January of 1995, Russia detected
a nuclear missile headed its way.</span></span>
		<span class="tooltip">La señal de alarma llegó
hasta el presidente,<span class="tooltiptext">The alert went all the way
to the president,</span></span>
		<span class="tooltip">que se estaba planteando contraatacar,<span class="tooltiptext">who was deciding whether to strike back</span></span>
		<span class="tooltip">hasta que otro radar contradijo
la alarma inicial.<span class="tooltiptext">when another system contradicted
the initial warning.</span></span>
		<span class="tooltip">Lo que se pensó era el primer misil 
de un ataque masivo<span class="tooltiptext">What they thought was the first missile
in a massive attack</span></span>
		<span class="tooltip">resultó ser una sonda espacial
que estudiaba la aurora boreal.<span class="tooltiptext">was actually a research rocket
studying the Northern Lights.</span></span>
		<span class="tooltip">El incidente ocurrió
tras el fin de la Guerra Fría.<span class="tooltiptext">This incident happened 
after the end of the Cold War,</span></span>
		<span class="tooltip">Sin embargo, fue una de las veces
que más cerca hemos estado<span class="tooltiptext">but was nevertheless one of the closest
calls we’ve had</span></span>
		<span class="tooltip">de iniciar una guerra mundial nuclear.<span class="tooltiptext">to igniting a global nuclear war.</span></span>
	</p>
	<p>
		<span class="tooltip">Con la creación de la bomba atómica,<span class="tooltiptext">With the invention of the atomic bomb,</span></span>
		<span class="tooltip">la humanidad ganó el poder
de autodestruirse por primera vez.<span class="tooltiptext">humanity gained the power to destroy
itself for the first time in our history.</span></span>
		<span class="tooltip">Desde entonces, la amenaza existencial,<span class="tooltiptext">Since then, our existential risk—</span></span>
		<span class="tooltip">el riesgo de extinguirse<span class="tooltiptext">risk of either extinction</span></span>
		<span class="tooltip">o de un colapso irrecuperable
de la civilización humana,<span class="tooltiptext">or the unrecoverable collapse 
of human civilization—</span></span>
		<span class="tooltip">ha aumentado progresivamente.<span class="tooltiptext">has steadily increased.</span></span>
		<span class="tooltip">Está en nuestras manos
reducir tal riesgo,<span class="tooltiptext">It’s well within our power
to reduce this risk,</span></span>
		<span class="tooltip">pero para hacerlo,<span class="tooltiptext">but in order to do so,</span></span>
		<span class="tooltip">debemos comprender cuáles acciones
representan una amenaza existencial<span class="tooltiptext">we have to understand which 
of our activities</span></span>
		<span class="tooltip">en el presente y cuáles en un futuro.<span class="tooltiptext">pose existential threats now, 
and which might in the future.</span></span>
	</p>
	<p>
		<span class="tooltip">Hasta ahora, nuestra especie ha existido
durante 2.000 siglos,<span class="tooltiptext">So far, our species has survived
2,000 centuries,</span></span>
		<span class="tooltip">cada uno con un riesgo de extinción
por causas naturales:<span class="tooltiptext">each with some extinction risk
from natural causes—</span></span>
		<span class="tooltip">impactos de asteroides, supervolcanes,
entre otros.<span class="tooltiptext">asteroid impacts, supervolcanoes,
and the like.</span></span>
		<span class="tooltip">Evaluar el riesgo existencial
es algo incierto porque,<span class="tooltiptext">Assessing existential risk is 
an inherently uncertain business</span></span>
		<span class="tooltip">cuando intentamos entender 
cuál es la probabilidad de un evento,<span class="tooltiptext">because usually when we try to figure out
how likely something is,</span></span>
		<span class="tooltip">solemos investigar
cuántas veces ha sucedido antes.<span class="tooltiptext">we check how often it&#39;s happened before.</span></span>
		<span class="tooltip">Pero nunca se ha visto 
la destrucción total de la humanidad.<span class="tooltiptext">But the complete destruction of humanity
has never happened before.</span></span>
		<span class="tooltip">Si bien no hay un método perfecto
para saber el riesgo por amenaza natural,<span class="tooltiptext">While there’s no perfect method to
determine our risk from natural threats,</span></span>
		<span class="tooltip">los expertos estiman 
que es de 1 en 10.000 por siglo.<span class="tooltiptext">experts estimate it’s about 
1 in 10,000 per century.</span></span>
	</p>
	<p>
		<span class="tooltip">Las armas nucleares fueron nuestra
primera contribución a esa base.<span class="tooltiptext">Nuclear weapons were our first
addition to that baseline.</span></span>
		<span class="tooltip">Aunque existen varios riesgos relacionados
con las armas nucleares,<span class="tooltiptext">While there are many risks associated
with nuclear weapons,</span></span>
		<span class="tooltip">el riesgo existencial proviene
de la posibilidad<span class="tooltiptext">the existential risk comes
from the possibility</span></span>
		<span class="tooltip">de una guerra mundial nuclear 
que resulte en un invierno nuclear,<span class="tooltiptext">of a global nuclear war that leads
to a nuclear winter,</span></span>
		<span class="tooltip">donde el hollín de las ciudades en llamas
bloquee el sol durante años,<span class="tooltiptext">where soot from burning cities
blocks out the sun for years,</span></span>
		<span class="tooltip">causando la pérdida de cultivos
de los que depende la humanidad.<span class="tooltiptext">causing the crops that humanity
depends on to fail.</span></span>
		<span class="tooltip">Aún no hemos tenido una guerra nuclear<span class="tooltiptext">We haven&#39;t had a nuclear war yet,</span></span>
		<span class="tooltip">y nuestro historial no es suficiente
para saber si son poco probables<span class="tooltiptext">but our track record is too short to tell
if they’re inherently unlikely</span></span>
		<span class="tooltip">o si solo hemos tenido suerte.<span class="tooltiptext">or we’ve simply been lucky.</span></span>
		<span class="tooltip">Tampoco podemos estar seguros<span class="tooltiptext">We also can’t say for sure</span></span>
		<span class="tooltip">de si una guerra nuclear mundial
causaría un invierno nuclear tan severo<span class="tooltiptext">whether a global nuclear war
would cause a nuclear winter so severe</span></span>
		<span class="tooltip">que sería una amenaza existencial
para la humanidad.<span class="tooltiptext">it would pose an existential threat
to humanity.</span></span>
	</p>
	<p>
		<span class="tooltip">Otra contribución al riesgo existencial 
fue el calentamiento global.<span class="tooltiptext">The next major addition to our existential
risk was climate change.</span></span>
		<span class="tooltip">Como una guerra nuclear,
el calentamiento global podría causar<span class="tooltiptext">Like nuclear war, 
climate change could result</span></span>
		<span class="tooltip">terribles escenarios 
que deberíamos intentar evitar,<span class="tooltiptext">in a lot of terrible scenarios 
that we should be working hard to avoid,</span></span>
		<span class="tooltip">pero que nos acercarían a la extinción
o a un colapso irrecuperable.<span class="tooltiptext">but that would stop short of causing
extinction or unrecoverable collapse.</span></span>
		<span class="tooltip">Esperamos el aumento
de unos cuantos grados Celsius,<span class="tooltiptext">We expect a few degrees
Celsius of warming,</span></span>
		<span class="tooltip">pero no podemos descartar
que sean 6 o incluso 10 grados,<span class="tooltiptext">but can’t yet completely 
rule out 6 or even 10 degrees,</span></span>
		<span class="tooltip">lo que causaría una calamidad
de proporciones sin precedentes.<span class="tooltiptext">which would cause a calamity of possibly
unprecedented proportions.</span></span>
		<span class="tooltip">Incluso en el peor de los casos,<span class="tooltiptext">Even in this worst-case scenario,</span></span>
		<span class="tooltip">no está claro si el calentamiento
significaría una amenaza directa,<span class="tooltiptext">it’s not clear whether warming would pose
a direct existential risk,</span></span>
		<span class="tooltip">pero tal disrupción invariablemente
nos dejaría más vulnerables<span class="tooltiptext">but the disruption it would cause
would likely make us more vulnerable</span></span>
		<span class="tooltip">a otros riesgos existenciales.<span class="tooltiptext">to other existential risks.</span></span>
	</p>
	<p>
		<span class="tooltip">Los riesgos más grandes quizás provengan 
de las tecnologías emergentes.<span class="tooltiptext">The greatest risks may come 
from technologies that are still emerging.</span></span>
		<span class="tooltip">Por ejemplo, las pandemias fabricadas.<span class="tooltiptext">Take engineered pandemics.</span></span>
		<span class="tooltip">Las catástrofes más grandes 
en la historia son resultado de pandemias.<span class="tooltiptext">The biggest catastrophes in human history
have been from pandemics.</span></span>
		<span class="tooltip">La biotecnología nos permite
modificar y crear gérmenes<span class="tooltiptext">And biotechnology is enabling
us to modify and create germs</span></span>
		<span class="tooltip">que podrían ser mucho más mortales
que los que ocurren naturalmente.<span class="tooltiptext">that could be much more deadly
than naturally occurring ones.</span></span>
		<span class="tooltip">Podrían desatar pandemias a través
de una guerra biológica o un accidente.<span class="tooltiptext">Such germs could cause pandemics 
through biowarfare and research accidents.</span></span>
		<span class="tooltip">La reducción del costo de la secuenciación
y modificación del genoma,<span class="tooltiptext">Decreased costs of genome sequencing
and modification,</span></span>
		<span class="tooltip">junto con la creciente 
disponibilidad de información peligrosa,<span class="tooltiptext">along with increased availability
of potentially dangerous information</span></span>
		<span class="tooltip">como la publicación de genomas
de virus letales,<span class="tooltiptext">like the published genomes 
of deadly viruses,</span></span>
		<span class="tooltip">también incrementan el número
de personas y grupos<span class="tooltiptext">also increase the number of people
and groups</span></span>
		<span class="tooltip">que podrían crear tales patógenos.<span class="tooltiptext">who could potentially create
such pathogens.</span></span>
	</p>
	<p>
		<span class="tooltip">Otra preocupación
es la IA sin afiliaciones.<span class="tooltiptext">Another concern is unaligned AI.</span></span>
		<span class="tooltip">Muchos investigadores creen 
que este será el siglo<span class="tooltiptext">Most AI researchers think this will be
the century</span></span>
		<span class="tooltip">en el que creemos inteligencia artificial 
que supere a los humanos<span class="tooltiptext">where we develop artificial intelligence
that surpasses human abilities</span></span>
		<span class="tooltip">en todas sus habilidades.<span class="tooltiptext">across the board.</span></span>
		<span class="tooltip">Si concedemos esta ventaja,
ponemos nuestro futuro en las manos<span class="tooltiptext">If we cede this advantage, we place
our future in the hands</span></span>
		<span class="tooltip">de los sistemas que creamos.<span class="tooltiptext">of the systems we create.</span></span>
		<span class="tooltip">Incluso si se crean con el beneficio
de la humanidad en mente,<span class="tooltiptext">Even if created solely with humanity’s 
best interests in mind,</span></span>
		<span class="tooltip">la IA superinteligente podría implicar
un riesgo existencial<span class="tooltiptext">superintelligent AI could pose 
an existential risk</span></span>
		<span class="tooltip">si no se apega perfectamente
a los valores humanos,<span class="tooltiptext">if it isn’t perfectly aligned 
with human values—</span></span>
		<span class="tooltip">Una tarea que los científicos
consideran muy difícil de lograr.<span class="tooltiptext">a task scientists are finding
extremely difficult.</span></span>
	</p>
	<p>
		<span class="tooltip">Con base en lo que sabemos 
hasta ahora,<span class="tooltiptext">Based on what we know at this point,</span></span>
		<span class="tooltip">algunos expertos estiman 
que el riesgo existencial antropogénico<span class="tooltiptext">some experts estimate the anthropogenic
existential risk</span></span>
		<span class="tooltip">es más de 100 veces superior
a la tasa de riesgo natural.<span class="tooltiptext">is more than 100 times higher 
than the background rate of natural risk.</span></span>
		<span class="tooltip">Pero estas probabilidades dependen
ampliamente de las decisiones humanas,<span class="tooltiptext">But these odds depend heavily
on human choices.</span></span>
		<span class="tooltip">porque la mayoría del riesgo se debe 
a los humanos y está dentro de su control.<span class="tooltiptext">Because most of the risk is from human
action, and it’s within human control.</span></span>
		<span class="tooltip">Si la protección de nuestro futuro 
se vuelve el tema principal del presente,<span class="tooltiptext">If we treat safeguarding humanity&#39;s future
as the defining issue of our time,</span></span>
		<span class="tooltip">podemos reducir tal riesgo.<span class="tooltiptext">we can reduce this risk.</span></span>
		<span class="tooltip">Que la humanidad alcance
su potencial,<span class="tooltiptext">Whether humanity fulfils its potential—</span></span>
		<span class="tooltip">o no,<span class="tooltiptext">or not—</span></span>
		<span class="tooltip">está en nuestras manos.<span class="tooltiptext">is in our hands.</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	