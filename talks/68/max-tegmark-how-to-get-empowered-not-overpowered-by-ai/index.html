<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your Spanish reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="Spanish reading, Spanish language learning, instant translations, reading adventure, improve Spanish, improve reading skills, educational platform, spanish reading resources, online education, Spanish proficiency, learn Spanish, Spanish learning resources, bilingual education, language exchange, study Spanish online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Max Tegmark : How to get empowered, not overpowered, by AI</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>How to get empowered, not overpowered, by AI</h1>
	<h2 class='speaker'>Max Tegmark</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your Spanish speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">After 13.8 billion years
of cosmic history,<span class="tooltiptext">بعد 13,8 مليار سنة من تاريخ الكون،</span></span>
		<span class="tooltip">our universe has woken up<span class="tooltiptext">استيقظ كوننا</span></span>
		<span class="tooltip">and become aware of itself.<span class="tooltiptext">وأصبح مدركًا لذاته.</span></span>
		<span class="tooltip">From a small blue planet,<span class="tooltiptext">من كوكب صغير أزرق،</span></span>
		<span class="tooltip">tiny, conscious parts of our universe
have begun gazing out into the cosmos<span class="tooltiptext">بدأت أجزاء صغيرة واعية من عالمنا 
تحدق بالكون</span></span>
		<span class="tooltip">with telescopes,<span class="tooltiptext">باستخدام التلسكوبات،</span></span>
		<span class="tooltip">discovering something humbling.<span class="tooltiptext">تكتشف شيئاً بتواضع.</span></span>
		<span class="tooltip">We&#39;ve discovered that our universe
is vastly grander<span class="tooltiptext">لقد اكتشفنا أن كوننا أعظم بكثير</span></span>
		<span class="tooltip">than our ancestors imagined<span class="tooltiptext">مما تصوره أسلافنا</span></span>
		<span class="tooltip">and that life seems to be an almost
imperceptibly small perturbation<span class="tooltiptext">وأن الحياة تبدو وكأنها اضطراب صغير 
غير محسوس</span></span>
		<span class="tooltip">on an otherwise dead universe.<span class="tooltiptext">على كون ميت.</span></span>
		<span class="tooltip">But we&#39;ve also discovered
something inspiring,<span class="tooltiptext">لكننا اكتشفنا أيضًا شيئا ملهمًا،</span></span>
		<span class="tooltip">which is that the technology
we&#39;re developing has the potential<span class="tooltiptext">وهو أن التكنولوجيا التي نطورها لها القدرة</span></span>
		<span class="tooltip">to help life flourish like never before,<span class="tooltiptext">على مساعدة ازدهار الحياة بشكل غير مسبوق،</span></span>
		<span class="tooltip">not just for centuries
but for billions of years,<span class="tooltiptext">ليس لعدة قرون فقط ولكن لمليارات السنين</span></span>
		<span class="tooltip">and not just on earth but throughout
much of this amazing cosmos.<span class="tooltiptext">وليس على هذه الأرض فقط 
ولكن في أنحاء أخرى من هذا الكون المذهل.</span></span>
	</p>
	<p>
		<span class="tooltip">I think of the earliest life as &quot;Life 1.0&quot;<span class="tooltiptext">شخصيًّا، أسمي بداية الحياة ب&quot;الحياة 1.0&quot;</span></span>
		<span class="tooltip">because it was really dumb,<span class="tooltiptext">لأنها كانت غبية حقاً،</span></span>
		<span class="tooltip">like bacteria, unable to learn
anything during its lifetime.<span class="tooltiptext">مثل البكتيريا، غير قادرة على تعلم أي شيء
خلال حياتها.</span></span>
		<span class="tooltip">I think of us humans as &quot;Life 2.0&quot;
because we can learn,<span class="tooltiptext">وأعتقد بأننا نحن البشر نمثل &quot;الحياة 2.0&quot;
لأننا نستطيع التعلم،</span></span>
		<span class="tooltip">which we in nerdy, geek speak,<span class="tooltiptext">وإذا ما تحدثنا عنه بهوس علمي</span></span>
		<span class="tooltip">might think of as installing
new software into our brains,<span class="tooltiptext">فقد ننظر له وكأنه تثبيت برمجية جديدة
داخل عقولنا</span></span>
		<span class="tooltip">like languages and job skills.<span class="tooltiptext">مثل اللغات ومهارات العمل.</span></span>
		<span class="tooltip">&quot;Life 3.0,&quot; which can design not only
its software but also its hardware<span class="tooltiptext">&quot;الحياة 3.0&quot; والتي لا تصمم برمجياتها فحسب 
بل وأجزائها الرئيسية أيضًا</span></span>
		<span class="tooltip">of course doesn&#39;t exist yet.<span class="tooltiptext">وهي بالطبع لا وجود لها حتى الآن.</span></span>
		<span class="tooltip">But perhaps our technology
has already made us &quot;Life 2.1,&quot;<span class="tooltiptext">لكن قد تكون التكنولوجيا الحالية 
قد صنعت لنا بالفعل &quot;الحياة 2.1&quot;</span></span>
		<span class="tooltip">with our artificial knees,
pacemakers and cochlear implants.<span class="tooltiptext">مع ركبنا الصناعية، وأجهزة تنظيم نبضات
القلب والقواقع السمعية المزروعة.</span></span>
	</p>
	<p>
		<span class="tooltip">So let&#39;s take a closer look
at our relationship with technology, OK?<span class="tooltiptext">لذا لنمعن النظر في علاقتنا مع التكنولوجيا،
حسنًا؟</span></span>
		<span class="tooltip">As an example,<span class="tooltiptext">على سبيل المثال،</span></span>
		<span class="tooltip">the Apollo 11 moon mission
was both successful and inspiring,<span class="tooltiptext">بعثة أبولو 11 إلى القمر كانت ناجحة 
وملهمة في ذات الوقت</span></span>
		<span class="tooltip">showing that when we humans
use technology wisely,<span class="tooltiptext">مبينةً أنه عندما نستخدم نحن البشر
التكنولوجيا بحكمة،</span></span>
		<span class="tooltip">we can accomplish things
that our ancestors could only dream of.<span class="tooltiptext">فإننا نستطيع إنجاز أشياء لم يستطع أسلافنا
إلا الحلم بها.</span></span>
		<span class="tooltip">But there&#39;s an even more inspiring journey<span class="tooltiptext">لكن توجد هناك رحلة أكثر إلهامًا</span></span>
		<span class="tooltip">propelled by something
more powerful than rocket engines,<span class="tooltiptext">مدفوعة بشيء أقوى من محركات الصواريخ</span></span>
		<span class="tooltip">where the passengers
aren&#39;t just three astronauts<span class="tooltiptext">حيث الركاب ليسوا مجرد ثلاثة من رواد الفضاء</span></span>
		<span class="tooltip">but all of humanity.<span class="tooltiptext">بل البشرية جمعاء.</span></span>
		<span class="tooltip">Let&#39;s talk about our collective
journey into the future<span class="tooltiptext">دعونا نتحدث عن رحلتنا الجماعية 
نحو المستقبل</span></span>
		<span class="tooltip">with artificial intelligence.<span class="tooltiptext">مع الذكاء الاصطناعي.</span></span>
	</p>
	<p>
		<span class="tooltip">My friend Jaan Tallinn likes to point out
that just as with rocketry,<span class="tooltiptext">يشير صديقي جان تالين إلى أنه 
كما هي الحال مع الصواريخ،</span></span>
		<span class="tooltip">it&#39;s not enough to make
our technology powerful.<span class="tooltiptext">ليس كافيًا أن نجعل التكنولوجيا لدينا أقوى.</span></span>
		<span class="tooltip">We also have to figure out,
if we&#39;re going to be really ambitious,<span class="tooltiptext">بل يجب علينا أن نعرف، هل سنكون حقًا طموحين</span></span>
		<span class="tooltip">how to steer it<span class="tooltiptext">فيما يتعلق بتوجيهها</span></span>
		<span class="tooltip">and where we want to go with it.<span class="tooltiptext">وإلى أين نريد الذهاب بها.</span></span>
		<span class="tooltip">So let&#39;s talk about all three
for artificial intelligence:<span class="tooltiptext">إذن لنتحدث عن هذه المحاور الثلاثة
في مجال الذكاء الاصطناعي:</span></span>
		<span class="tooltip">the power, the steering
and the destination.<span class="tooltiptext">القوة والقيادة والوجهة.</span></span>
	</p>
	<p>
		<span class="tooltip">Let&#39;s start with the power.<span class="tooltiptext">لنبدأ بالحديث عن القوة.</span></span>
		<span class="tooltip">I define intelligence very inclusively --<span class="tooltiptext">أنا أعرّف الذكاء ضمنيًا</span></span>
		<span class="tooltip">simply as our ability
to accomplish complex goals,<span class="tooltiptext">ببساطة على أنه قدرتنا 
على إنجاز أهداف معقدة،</span></span>
		<span class="tooltip">because I want to include both
biological and artificial intelligence.<span class="tooltiptext">لأنني أريد أن أشمل 
كلا من الذكاء الحيوي والاصطناعي.</span></span>
		<span class="tooltip">And I want to avoid
the silly carbon-chauvinism idea<span class="tooltiptext">وأرغب بتجنب 
فكرة &quot;الشوفينية الكربونية&quot; السخيفة</span></span>
		<span class="tooltip">that you can only be smart
if you&#39;re made of meat.<span class="tooltiptext">بأنك لا تكون ذكيًا 
إلا إذا كنت مصنوعًا من لحم.</span></span>
		<span class="tooltip">It&#39;s really amazing how the power
of AI has grown recently.<span class="tooltiptext">إنه لمذهل حقًا كيف تطورت
فكرة الذكاء الاصطناعي مؤخرًا.</span></span>
		<span class="tooltip">Just think about it.<span class="tooltiptext">فكروا بالأمر فحسب.</span></span>
		<span class="tooltip">Not long ago, robots couldn&#39;t walk.<span class="tooltiptext">حتى وقتٍ قريب، لم تكن الروبوتات 
قادرة على السير.</span></span>
		<span class="tooltip">Now, they can do backflips.<span class="tooltiptext">الآن، تستطيع القفز متأرجحةً للخلف.</span></span>
		<span class="tooltip">Not long ago,<span class="tooltiptext">حتى وقت قريب،</span></span>
		<span class="tooltip">we didn&#39;t have self-driving cars.<span class="tooltiptext">لم نمتلك سيارات ذاتية القيادة.</span></span>
		<span class="tooltip">Now, we have self-flying rockets.<span class="tooltiptext">الآن، لدينا صواريخ ذاتية التحليق.</span></span>
		<span class="tooltip">Not long ago,<span class="tooltiptext">حتى وقت قريب،</span></span>
		<span class="tooltip">AI couldn&#39;t do face recognition.<span class="tooltiptext">لم يكن الذكاء الاصطناعي قادرًا
على التعرف على الوجوه.</span></span>
		<span class="tooltip">Now, AI can generate fake faces<span class="tooltiptext">الآن، الذكاء الاصطناعي لديه القدرة 
على توليد وجوه مزيفة.</span></span>
		<span class="tooltip">and simulate your face
saying stuff that you never said.<span class="tooltiptext">ومحاكاة وجهك لقول أشياء لم تقلها أبدًا</span></span>
		<span class="tooltip">Not long ago,<span class="tooltiptext">حتى وقت قريب،</span></span>
		<span class="tooltip">AI couldn&#39;t beat us at the game of Go.<span class="tooltiptext">كان الذكاء الاصطناعي عاجزًا
عن هزيمتنا في لعبة &quot;غو&quot;.</span></span>
		<span class="tooltip">Then, Google DeepMind&#39;s AlphaZero AI
took 3,000 years of human Go games<span class="tooltiptext">ثم أَخَذَ ألفا زيرو من &quot;جوجل ديب مايند&quot;
3000 سنة من ألعاب &quot;غو&quot; التي لعبها البشر</span></span>
		<span class="tooltip">and Go wisdom,<span class="tooltiptext">واستراتيجة اللعبة،</span></span>
		<span class="tooltip">ignored it all and became the world&#39;s best
player by just playing against itself.<span class="tooltiptext">وتجاهل ذلك كله، ليصبح أفضل لاعب في العالم 
فقط باللعب ضد نفسه.</span></span>
		<span class="tooltip">And the most impressive feat here
wasn&#39;t that it crushed human gamers,<span class="tooltiptext">والأكثر إثارة للإعجاب 
لم يكن سحقه للاعبين بشر،</span></span>
		<span class="tooltip">but that it crushed human AI researchers<span class="tooltiptext">لكن حقيقة أنه هزم 
باحثين في الذكاء الاصطناعي</span></span>
		<span class="tooltip">who had spent decades
handcrafting game-playing software.<span class="tooltiptext">أمضوا عشرات السنين
في تصميم برمجيات قادرة على اللعب.</span></span>
		<span class="tooltip">And AlphaZero crushed human AI researchers
not just in Go but even at chess,<span class="tooltiptext">ولم يسحق ألفا زيرو الباحثين في لعبة &quot;غو&quot; فحسب 
بل في الشطرنج أيضًا،</span></span>
		<span class="tooltip">which we have been working on since 1950.<span class="tooltiptext">والتي كانوا يعملون عليها منذ عام 1950.</span></span>
	</p>
	<p>
		<span class="tooltip">So all this amazing recent progress in AI
really begs the question:<span class="tooltiptext">لهذا كل هذا التطور الحديث
في الذكاء الاصطناعي يطرح التساؤل:</span></span>
		<span class="tooltip">How far will it go?<span class="tooltiptext">إلى أي مدى سيصل هذا الذكاء؟</span></span>
		<span class="tooltip">I like to think about this question<span class="tooltiptext">أنا أحب التفكير بهذا السؤال</span></span>
		<span class="tooltip">in terms of this abstract
landscape of tasks,<span class="tooltiptext">من منطلق هذا الملخص لتضاريس المهام،</span></span>
		<span class="tooltip">where the elevation represents
how hard it is for AI to do each task<span class="tooltiptext">حيث الارتفاع يمثل مدى صعوبة 
قيام الذكاء الاصطناعي بالمهمة</span></span>
		<span class="tooltip">at human level,<span class="tooltiptext">بنفس المستوى البشري</span></span>
		<span class="tooltip">and the sea level represents
what AI can do today.<span class="tooltiptext">ويمثل مستوى البحر 
ما يستطيع الذكاء الاصطناعي فعله اليوم.</span></span>
		<span class="tooltip">The sea level is rising
as AI improves,<span class="tooltiptext">مستوى البحر يرتفع والذكاء الاصطناعي يتطور،</span></span>
		<span class="tooltip">so there&#39;s a kind of global warming
going on here in the task landscape.<span class="tooltiptext">لهذا يوجد نوع من الاحتباس الحراري يحدث
هنا على مخطط تضاريس المهام.</span></span>
		<span class="tooltip">And the obvious takeaway
is to avoid careers at the waterfront --<span class="tooltiptext">والرسالة الواضحة هنا، هي تجنب
الوظائف على الواجهة البحرية...</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(ضحك)</span></span>
	</p>
	<p>
		<span class="tooltip">which will soon be
automated and disrupted.<span class="tooltiptext">والتي ستصبح قريبا، وظائف آلية وغير متاحة.</span></span>
		<span class="tooltip">But there&#39;s a much
bigger question as well.<span class="tooltiptext">ولكن هناك أيضًا سؤال أكبر بكثير</span></span>
		<span class="tooltip">How high will the water end up rising?<span class="tooltiptext">إلى أي مدى سترتفع المياه؟</span></span>
		<span class="tooltip">Will it eventually rise
to flood everything,<span class="tooltiptext">هل ستنتهي بإغراق كل شيء؟</span></span>
		<span class="tooltip">matching human intelligence at all tasks.<span class="tooltiptext">وتوازي الذكاء البشري في كل المهام</span></span>
		<span class="tooltip">This is the definition
of artificial general intelligence --<span class="tooltiptext">هذا هو تعريف الذكاء الاصطناعي العام...</span></span>
		<span class="tooltip">AGI,<span class="tooltiptext">أو ال(إيه جي آي)،</span></span>
		<span class="tooltip">which has been the holy grail
of AI research since its inception.<span class="tooltiptext">والذي يمثل الكأس المقدسة لأبحاث 
الذكاء الاصطناعي منذ نشأتها.</span></span>
		<span class="tooltip">By this definition, people who say,<span class="tooltiptext">بحسب هذا التعريف الأشخاص الذين يقولون:</span></span>
		<span class="tooltip">&quot;Ah, there will always be jobs
that humans can do better than machines,&quot;<span class="tooltiptext">&quot;آه، ستبقى هنالك دومًا تلك الأعمال
التي يؤديها البشر أفضل من الآلات&quot;.</span></span>
		<span class="tooltip">are simply saying
that we&#39;ll never get AGI.<span class="tooltiptext">ببساطة يقولون إننا لن نحصل 
على الذكاء الاصطناعي العام.</span></span>
		<span class="tooltip">Sure, we might still choose
to have some human jobs<span class="tooltiptext">بالتأكيد، قد نختار الإبقاء 
على بعض الوظائف البشرية</span></span>
		<span class="tooltip">or to give humans income
and purpose with our jobs,<span class="tooltiptext">أو أن نمنح البشر الدخل والهدف
من خلال الأعمال،</span></span>
		<span class="tooltip">but AGI will in any case
transform life as we know it<span class="tooltiptext">لكن الذكاء الاصطناعي العام على كل حال
سوف يحول الحياة كما نعرفها</span></span>
		<span class="tooltip">with humans no longer being
the most intelligent.<span class="tooltiptext">إلى حياة حيث البشر ليسوا الأذكى.</span></span>
		<span class="tooltip">Now, if the water level does reach AGI,<span class="tooltiptext">الآن، في حال وصل مستوى الماء
إلى (إيه جي آي)</span></span>
		<span class="tooltip">then further AI progress will be driven
mainly not by humans but by AI,<span class="tooltiptext">فإن أي تقدم أكبر في الذكاء الاصطناعي
لن يقوده البشر بل الذكاء الاصطناعي نفسه</span></span>
		<span class="tooltip">which means that there&#39;s a possibility<span class="tooltiptext">مما يعني أن هنالك احتمال</span></span>
		<span class="tooltip">that further AI progress
could be way faster<span class="tooltiptext">بأن يصبح التقدم في الذكاء الاصطناعي 
أسرع بكثير</span></span>
		<span class="tooltip">than the typical human research
and development timescale of years,<span class="tooltiptext">من الأبحاث البشرية النموذجية
والمقياس الزمني للتطور لسنوات،</span></span>
		<span class="tooltip">raising the controversial possibility
of an intelligence explosion<span class="tooltiptext">مثيرًا الاحتمالية المثيرة للجدل 
حول انفجار في مستوى الذكاء</span></span>
		<span class="tooltip">where recursively self-improving AI<span class="tooltiptext">حيث الذكاء الاصطناعي 
المطور ذاتيًا بشكل متكرر</span></span>
		<span class="tooltip">rapidly leaves human
intelligence far behind,<span class="tooltiptext">يترك بسرعة الذكاء البشري وراءه بكثير،</span></span>
		<span class="tooltip">creating what&#39;s known
as superintelligence.<span class="tooltiptext">مبتكرًا ما يعرف بالذكاء الخارق.</span></span>
	</p>
	<p>
		<span class="tooltip">Alright, reality check:<span class="tooltiptext">حسنا، لنتحقق من الواقع:</span></span>
		<span class="tooltip">Are we going to get AGI any time soon?<span class="tooltiptext">هل سنحصل على (إيه جي آي)
في أي وقت قريب؟</span></span>
		<span class="tooltip">Some famous AI researchers,
like Rodney Brooks,<span class="tooltiptext">بعض باحثي الذكاء الاصطناعي المشاهير
مثل رودني بروكس</span></span>
		<span class="tooltip">think it won&#39;t happen
for hundreds of years.<span class="tooltiptext">يعتقدون بأن هذا لن يحدث لمئات السنين.</span></span>
		<span class="tooltip">But others, like Google DeepMind
founder Demis Hassabis,<span class="tooltiptext">لكن آخرين مثل مؤسس &quot;جوجل ديب مايند&quot;
ديميس هاسابس</span></span>
		<span class="tooltip">are more optimistic<span class="tooltiptext">أكثر تفاؤلا</span></span>
		<span class="tooltip">and are working to try to make
it happen much sooner.<span class="tooltiptext">ويعملون لجعلها تحدث في وقت أقرب بكثير.</span></span>
		<span class="tooltip">And recent surveys have shown
that most AI researchers<span class="tooltiptext">وإضافة إلى ذلك أظهرت دراسات أن أغلب 
باحثي الذكاء الاصطناعي</span></span>
		<span class="tooltip">actually share Demis&#39;s optimism,<span class="tooltiptext">في الحقيقة يشاركون &quot;ديميس&quot; تفاؤله.</span></span>
		<span class="tooltip">expecting that we will
get AGI within decades,<span class="tooltiptext">متوقعين أننا سنحصل على الـ(إيه جي آي)
في غضون عقود.</span></span>
		<span class="tooltip">so within the lifetime of many of us,<span class="tooltiptext">أي خلال حياة العديد منا.</span></span>
		<span class="tooltip">which begs the question -- and then what?<span class="tooltiptext">وهنا يطرح السؤال: ثم ماذا؟</span></span>
		<span class="tooltip">What do we want the role of humans to be<span class="tooltiptext">ماذا نريد من البشر أن يفعلوا</span></span>
		<span class="tooltip">if machines can do everything better
and cheaper than us?<span class="tooltiptext">إذا استطاعت الآلات فعل كل شيء
بشكل أفضل وأوفر منا؟</span></span>
	</p>
	<p>
		<span class="tooltip">The way I see it, we face a choice.<span class="tooltiptext">أنا أرى بأننا أمام خيارين.</span></span>
		<span class="tooltip">One option is to be complacent.<span class="tooltiptext">أحد الخيارات هو أن نكون راضين.</span></span>
		<span class="tooltip">We can say, &quot;Oh, let&#39;s just build machines
that can do everything we can do<span class="tooltiptext">نستطيع أن نقول: &quot;أوه، هيا لنبني آلات 
تستطيع عمل كل شيء نعمله</span></span>
		<span class="tooltip">and not worry about the consequences.<span class="tooltiptext">ولا نقلق حول العواقب.</span></span>
		<span class="tooltip">Come on, if we build technology
that makes all humans obsolete,<span class="tooltiptext">إذا بنينا تكنولوجيا من شأنها 
جعل كل البشر عديمي الجدوى</span></span>
		<span class="tooltip">what could possibly go wrong?&quot;<span class="tooltiptext">ما العواقب التي يمكن أن تحدث؟&quot;</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(ضحك)</span></span>
	</p>
	<p>
		<span class="tooltip">But I think that would be
embarrassingly lame.<span class="tooltiptext">ولكني أعتقد بأنه سيكون ضعفًا محرجًا.</span></span>
		<span class="tooltip">I think we should be more ambitious --
in the spirit of TED.<span class="tooltiptext">أعتقد بأننا يجب أن نمتلك طموحًا أكبر، 
اقتداءً بTED.</span></span>
		<span class="tooltip">Let&#39;s envision a truly inspiring
high-tech future<span class="tooltiptext">دعونا نتصور مستقبلاً ملهمًا 
بتكنولوجيا عالية</span></span>
		<span class="tooltip">and try to steer towards it.<span class="tooltiptext">ونحاول التوجه نحوه.</span></span>
		<span class="tooltip">This brings us to the second part
of our rocket metaphor: the steering.<span class="tooltiptext">هذا يأخذنا إلى الجزء الثاني 
من خطتنا الصاروخية: التوجيه.</span></span>
		<span class="tooltip">We&#39;re making AI more powerful,<span class="tooltiptext">نحن نجعل الذكاء الاصطناعي أكثر قوة</span></span>
		<span class="tooltip">but how can we steer towards a future<span class="tooltiptext">ولكن كيف يمكننا التوجه نحو المستقبل</span></span>
		<span class="tooltip">where AI helps humanity flourish
rather than flounder?<span class="tooltiptext">وجعل الذكاء الاصطناعي عونًا 
لازدهار البشرية عوضًا عن تعثرها؟</span></span>
		<span class="tooltip">To help with this,<span class="tooltiptext">لتحقيق ذلك،</span></span>
		<span class="tooltip">I cofounded the Future of Life Institute.<span class="tooltiptext">ساعدت ببناء مؤسسة &quot;مستقبل الحياة&quot;</span></span>
		<span class="tooltip">It&#39;s a small nonprofit promoting
beneficial technology use,<span class="tooltiptext">وهي جمعية خيرية لتعزيز
استخدام التكنولوجيا المفيدة</span></span>
		<span class="tooltip">and our goal is simply
for the future of life to exist<span class="tooltiptext">وهدفنا ببساطة يتمثل في خلق مستقبل للحياة.</span></span>
		<span class="tooltip">and to be as inspiring as possible.<span class="tooltiptext">وأن نكون ملهمين قدر الإمكان</span></span>
		<span class="tooltip">You know, I love technology.<span class="tooltiptext">أتعلمون، أنا أحب التكنولوجيا.</span></span>
		<span class="tooltip">Technology is why today
is better than the Stone Age.<span class="tooltiptext">التكنولوجيا هي السبب في كون الحاضر 
أفضل من العصور الحجرية.</span></span>
		<span class="tooltip">And I&#39;m optimistic that we can create
a really inspiring high-tech future ...<span class="tooltiptext">وأنا متفائل بأننا نستطيع
ابتكار مستقبل تكنولوجي حديث مثير</span></span>
		<span class="tooltip">if -- and this is a big if --<span class="tooltiptext">إذا...وهذا افتراض كبير...</span></span>
		<span class="tooltip">if we win the wisdom race --<span class="tooltiptext">إذا كسبنا مسابقة الحكمة...</span></span>
		<span class="tooltip">the race between the growing
power of our technology<span class="tooltiptext">هذه المسابقة بين القوة النامية للتكنولوجيا</span></span>
		<span class="tooltip">and the growing wisdom
with which we manage it.<span class="tooltiptext">والحكمة النامية التي نديرها بها.</span></span>
		<span class="tooltip">But this is going to require
a change of strategy<span class="tooltiptext">ولكن هذا الفوز يتطلب تغييرًا 
في الاستراتيجية.</span></span>
		<span class="tooltip">because our old strategy
has been learning from mistakes.<span class="tooltiptext">لأن استراتيجيتنا القديمة 
مبنية على التعلم من الأخطاء.</span></span>
		<span class="tooltip">We invented fire,<span class="tooltiptext">نحن اخترعنا النار،</span></span>
		<span class="tooltip">screwed up a bunch of times --<span class="tooltiptext">أخفقنا عدة مرات...</span></span>
		<span class="tooltip">invented the fire extinguisher.<span class="tooltiptext">ثم اخترعنا طفاية الحريق.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(ضحك)</span></span>
	</p>
	<p>
		<span class="tooltip">We invented the car,
screwed up a bunch of times --<span class="tooltiptext">نحن اخترعنا السيارة،
أخفقنا عدة مرات...</span></span>
		<span class="tooltip">invented the traffic light,
the seat belt and the airbag,<span class="tooltiptext">فاخترعنا إشارة المرور وحزام الأمان
والوسادة الهوائية</span></span>
		<span class="tooltip">but with more powerful technology
like nuclear weapons and AGI,<span class="tooltiptext">ولكن مع تكنولوجيا أكثر قوة كالسلاح النووي 
والذكاء الاصطناعي،</span></span>
		<span class="tooltip">learning from mistakes
is a lousy strategy,<span class="tooltiptext">فالتعلم من الأخطاء استراتيجية سيئة،</span></span>
		<span class="tooltip">don&#39;t you think?<span class="tooltiptext">أليس كذلك؟</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(ضحك)</span></span>
	</p>
	<p>
		<span class="tooltip">It&#39;s much better to be proactive
rather than reactive;<span class="tooltiptext">الأفضل هو أن تكون فاعلًا
عوضًا عن كونك متفاعلًا،</span></span>
		<span class="tooltip">plan ahead and get things
right the first time<span class="tooltiptext">خطط مسبقًا وليكن كل شيء صحيحًا
منذ المرة الأولى</span></span>
		<span class="tooltip">because that might be
the only time we&#39;ll get.<span class="tooltiptext">لأنها قد تكون الفرصة الوحيدة المتاحة لك.</span></span>
		<span class="tooltip">But it is funny because
sometimes people tell me,<span class="tooltiptext">ولكن الأمر مضحك لأن الناس 
يقولون لي في بعض الأحيان:</span></span>
		<span class="tooltip">&quot;Max, shhh, don&#39;t talk like that.<span class="tooltiptext">&quot;ماكس، صه لا تتكلم هكذا.</span></span>
		<span class="tooltip">That&#39;s Luddite scaremongering.&quot;<span class="tooltiptext">هذا ترهيب وتخويف أعداء التكنولوجيا&quot;.</span></span>
		<span class="tooltip">But it&#39;s not scaremongering.<span class="tooltiptext">ولكنه ليس تخويفًا أو ترهيبًا.</span></span>
		<span class="tooltip">It&#39;s what we at MIT
call safety engineering.<span class="tooltiptext">إنه ما نطلق عليه في جامعة ماساتشوستس 
ب&quot;الهندسة الآمنة&quot;.</span></span>
		<span class="tooltip">Think about it:<span class="tooltiptext">فكروا بالأمر:</span></span>
		<span class="tooltip">before NASA launched
the Apollo 11 mission,<span class="tooltiptext">قبل أن تطلق ناسا مركبة أبولو 13،</span></span>
		<span class="tooltip">they systematically thought through
everything that could go wrong<span class="tooltiptext">فكروا بطريقة منظمة بكل خطأ محتمل حدوثه</span></span>
		<span class="tooltip">when you put people
on top of explosive fuel tanks<span class="tooltiptext">عندما تضع أشخاصًا 
على رأس خزانات وقود متفجرة</span></span>
		<span class="tooltip">and launch them somewhere
where no one could help them.<span class="tooltiptext">وترسلهم لمكان حيث لا يستطيع أحد مساعدتهم.</span></span>
		<span class="tooltip">And there was a lot that could go wrong.<span class="tooltiptext">وكانت هناك الكثير من الأخطاء المحتملة.</span></span>
		<span class="tooltip">Was that scaremongering?<span class="tooltiptext">هل كان ذلك تخويفًا وترهيبًا؟</span></span>
		<span class="tooltip">No.<span class="tooltiptext">لا.</span></span>
		<span class="tooltip">That&#39;s was precisely
the safety engineering<span class="tooltiptext">لقد كان بالضبط &quot;الهندسة الآمنة&quot;</span></span>
		<span class="tooltip">that ensured the success of the mission,<span class="tooltiptext">التي ضمنت نجاح المهمة.</span></span>
		<span class="tooltip">and that is precisely the strategy
I think we should take with AGI.<span class="tooltiptext">وهذه بالتحديد الاستراتيجية التي أعتقد 
بوجوب اتخاذها مع الذكاء الاصطناعي</span></span>
		<span class="tooltip">Think through what can go wrong
to make sure it goes right.<span class="tooltiptext">فكر بكل خطأ يحتمل أن يحدث 
لتتأكد من فعل الأمر بالشكل الصحيح.</span></span>
	</p>
	<p>
		<span class="tooltip">So in this spirit,
we&#39;ve organized conferences,<span class="tooltiptext">وبهذا الفكر، نظمنا مؤتمرات</span></span>
		<span class="tooltip">bringing together leading
AI researchers and other thinkers<span class="tooltiptext">لجمع قادة باحثي الذكاء الاصطناعي 
والمفكرين الآخرين</span></span>
		<span class="tooltip">to discuss how to grow this wisdom
we need to keep AI beneficial.<span class="tooltiptext">لمناقشة كيفية تنمية هذه الفلسفة 
التي نحتاجها لجعل الذكاء الاصناعي مفيدًا.</span></span>
		<span class="tooltip">Our last conference
was in Asilomar, California last year<span class="tooltiptext">عُقد آخر مؤتمر السنة الماضية 
في أسيلمار، كالفورنيا</span></span>
		<span class="tooltip">and produced this list of 23 principles<span class="tooltiptext">وقُدِّمت خلاله قائمة بثلاثة وعشرين مبدأ</span></span>
		<span class="tooltip">which have since been signed
by over 1,000 AI researchers<span class="tooltiptext">وقَّع عليها أكثر من ألف باحث 
في الذكاء الاصطناعي</span></span>
		<span class="tooltip">and key industry leaders,<span class="tooltiptext">والقادة في هذه الصناعة.</span></span>
		<span class="tooltip">and I want to tell you
about three of these principles.<span class="tooltiptext">وأريد أن أخبركم عن ثلاثة من هذه المبادئ.</span></span>
	</p>
	<p>
		<span class="tooltip">One is that we should avoid an arms race
and lethal autonomous weapons.<span class="tooltiptext">أحدها هو أنه يجدر بنا تجنب سباق التسلح
والأسلحة الذاتية القاتلة.</span></span>
		<span class="tooltip">The idea here is that any science
can be used for new ways of helping people<span class="tooltiptext">الفكرة هنا هو أن أي علم يمكن استخدامه 
كطرق جديدة في خدمة البشر،</span></span>
		<span class="tooltip">or new ways of harming people.<span class="tooltiptext">أو كطرق جديدة في إيذاء البشر.</span></span>
		<span class="tooltip">For example, biology and chemistry
are much more likely to be used<span class="tooltiptext">على سبيل المثال: الأحياء والكيمياء 
تُستخدم عادةً</span></span>
		<span class="tooltip">for new medicines or new cures
than for new ways of killing people,<span class="tooltiptext">في العلاج والأدوية الجديدة أكثر
من استخدامها في الطرق الجديدة لقتل البشر.</span></span>
		<span class="tooltip">because biologists
and chemists pushed hard --<span class="tooltiptext">لأن علماء الأحياء والكيمياء حاربوا بقوة</span></span>
		<span class="tooltip">and successfully --<span class="tooltiptext">وبنجاح</span></span>
		<span class="tooltip">for bans on biological
and chemical weapons.<span class="tooltiptext">لحظر وإدانة الأسلحة الكيميائية والبيولوجية</span></span>
		<span class="tooltip">And in the same spirit,<span class="tooltiptext">وبنفس الفكر،</span></span>
		<span class="tooltip">most AI researchers want to stigmatize
and ban lethal autonomous weapons.<span class="tooltiptext">يريد باحثو الذكاء الاصطناعي إدانة 
وحظر الأسلحة القاتلة الذاتية.</span></span>
		<span class="tooltip">Another Asilomar AI principle<span class="tooltiptext">ومن مبادئ أسيلمار للذكاء الاصطناعي</span></span>
		<span class="tooltip">is that we should mitigate
AI-fueled income inequality.<span class="tooltiptext">هو وجوب تخفيف عدم المساواة 
في الدخل المرتبط بالذكاء الاصطناعي</span></span>
		<span class="tooltip">I think that if we can grow
the economic pie dramatically with AI<span class="tooltiptext">أعتقد بأنه إذا استطعنا تنمية الكعكة
الاقتصادية بشكل كبير مع الذكاء الاصطناعي</span></span>
		<span class="tooltip">and we still can&#39;t figure out
how to divide this pie<span class="tooltiptext">وما زلنا لا نستطيع معرفة كيفية 
توزيع هذه الكعكة</span></span>
		<span class="tooltip">so that everyone is better off,<span class="tooltiptext">بحيث يكون الجميع بحال أفضل،</span></span>
		<span class="tooltip">then shame on us.<span class="tooltiptext">فعارٌ علينا!</span></span>
	</p>
	<p>
		<span class="tooltip">(Applause)<span class="tooltiptext">(تصفيق)</span></span>
	</p>
	<p>
		<span class="tooltip">Alright, now raise your hand
if your computer has ever crashed.<span class="tooltiptext">حسنًا، الآن ارفعوا أيديكم في حال 
تعطل حاسوبكم أحد المرات.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(ضحك)</span></span>
	</p>
	<p>
		<span class="tooltip">Wow, that&#39;s a lot of hands.<span class="tooltiptext">واو، هذه أيدٍ كثيرة.</span></span>
		<span class="tooltip">Well, then you&#39;ll appreciate
this principle<span class="tooltiptext">حسنًا، إذن ستقدرون هذا المبدأ</span></span>
		<span class="tooltip">that we should invest much more
in AI safety research,<span class="tooltiptext">والذي يقتضي زيادة الاستثمار
في أبحاث أمان الذكاء الاصطناعي،</span></span>
		<span class="tooltip">because as we put AI in charge
of even more decisions and infrastructure,<span class="tooltiptext">لأننا إذا جعلنا الذكاء الاصطناعي مسؤولًا
عن البنية التحتية وعن قرارات أكثر،</span></span>
		<span class="tooltip">we need to figure out how to transform
today&#39;s buggy and hackable computers<span class="tooltiptext">سنحتاج لمعرفة كيفية نقل مركبات 
الحواسيب القابلة للاختراق اليوم</span></span>
		<span class="tooltip">into robust AI systems
that we can really trust,<span class="tooltiptext">إلى روبورتات ذكية
بشكل نستطيع معه الثقة بها،</span></span>
		<span class="tooltip">because otherwise,<span class="tooltiptext">لأنه بخلاف ذلك،</span></span>
		<span class="tooltip">all this awesome new technology
can malfunction and harm us,<span class="tooltiptext">فكل التكنولوجيا الجديدة المدهشة 
قد تتعطل وتؤذينا،</span></span>
		<span class="tooltip">or get hacked and be turned against us.<span class="tooltiptext">أو تُخترَق وتُقلب ضدنا.</span></span>
		<span class="tooltip">And this AI safety work
has to include work on AI value alignment,<span class="tooltiptext">ونظام الأمان هذا يجب 
أن يشمل العمل على القيم المحايدة،</span></span>
		<span class="tooltip">because the real threat
from AGI isn&#39;t malice,<span class="tooltiptext">لأن التهديد الأكبر من الذكاء الاصطناعي
العام ليس الإيذاء،</span></span>
		<span class="tooltip">like in silly Hollywood movies,<span class="tooltiptext">كما في أفلام هوليوود التافهة،</span></span>
		<span class="tooltip">but competence --<span class="tooltiptext">بل المنافسة...</span></span>
		<span class="tooltip">AGI accomplishing goals
that just aren&#39;t aligned with ours.<span class="tooltiptext">(إيه جي آي) يحقق أهدافًا لا تتماشى معنا.</span></span>
		<span class="tooltip">For example, when we humans drove
the West African black rhino extinct,<span class="tooltiptext">على سبيل المثال: عندما تسببنا نحن البشر 
بانقراض وحيد القرن بغرب أفريقيا،</span></span>
		<span class="tooltip">we didn&#39;t do it because we were a bunch
of evil rhinoceros haters, did we?<span class="tooltiptext">لم نفعلها لأننا كنا أشرار 
كارهين لوحيد القرن، أليس كذلك؟</span></span>
		<span class="tooltip">We did it because
we were smarter than them<span class="tooltiptext">لقد فعلنا ذلك لأننا أذكى منهم</span></span>
		<span class="tooltip">and our goals weren&#39;t aligned with theirs.<span class="tooltiptext">وأهدافنا لم تتماشى مع أهدافهم.</span></span>
		<span class="tooltip">But AGI is by definition smarter than us,<span class="tooltiptext">ولكن الذكاء الاصطناعي العام أذكى منا،</span></span>
		<span class="tooltip">so to make sure that we don&#39;t put
ourselves in the position of those rhinos<span class="tooltiptext">ولذلك لنتأكد بأننا لم نضع أنفسنا 
في موقف وحيدي القرن</span></span>
		<span class="tooltip">if we create AGI,<span class="tooltiptext">عند صنعنا للذكاء الاصطناعي العام،</span></span>
		<span class="tooltip">we need to figure out how
to make machines understand our goals,<span class="tooltiptext">سنحتاج لمعرفة كيف نصنع آلات تفهم أهدافنا،</span></span>
		<span class="tooltip">adopt our goals and retain our goals.<span class="tooltiptext">تتبنى أهدافنا وتحتفظ بها.</span></span>
	</p>
	<p>
		<span class="tooltip">And whose goals should these be, anyway?<span class="tooltiptext">وأهداف من يجب أن تكون هذه الأهداف؟</span></span>
		<span class="tooltip">Which goals should they be?<span class="tooltiptext">أي أهداف ستكون هي الأهداف المرغوبة؟</span></span>
	</p>
	<p>
		<span class="tooltip">This brings us to the third part
of our rocket metaphor: the destination.<span class="tooltiptext">هذا يأخذنا إلى الجزء الثالث وهو: الوجهة.</span></span>
		<span class="tooltip">We&#39;re making AI more powerful,<span class="tooltiptext">نحن نجعل الذكاء الاصطناعي أكثر قوة،</span></span>
		<span class="tooltip">trying to figure out how to steer it,<span class="tooltiptext">ونحاول أن نعرف كيف نوجهه،</span></span>
		<span class="tooltip">but where do we want to go with it?<span class="tooltiptext">ولكن أين نريد التوجه به؟</span></span>
		<span class="tooltip">This is the elephant in the room
that almost nobody talks about --<span class="tooltiptext">هذا هو &quot;الفيل الذي بالغرفة&quot; 
الذي لا يريد أحد التحدث عنه...</span></span>
		<span class="tooltip">not even here at TED --<span class="tooltiptext">حتى هنا في TED...</span></span>
		<span class="tooltip">because we&#39;re so fixated
on short-term AI challenges.<span class="tooltiptext">لأننا نركز اهتمامنا 
على تحديات الذكاء الاصطناعي قصيرة المدى.</span></span>
		<span class="tooltip">Look, our species is trying to build AGI,<span class="tooltiptext">انظروا، أمثالنا يحاولون بناء الذكاء 
الاصطناعي العام</span></span>
		<span class="tooltip">motivated by curiosity and economics,<span class="tooltiptext">يدفعهم لذلك حب الاستطلاع والربح</span></span>
		<span class="tooltip">but what sort of future society
are we hoping for if we succeed?<span class="tooltiptext">ولكن ما هو المجتمع المستقبلي 
الذي نريد بناءه إذا نجحنا؟</span></span>
		<span class="tooltip">We did an opinion poll on this recently,<span class="tooltiptext">عملنا استطلاع رأي مؤخرًا بهذا الشأن،</span></span>
		<span class="tooltip">and I was struck to see<span class="tooltiptext">وقد كنت مندهشًا لرؤية</span></span>
		<span class="tooltip">that most people actually
want us to build superintelligence:<span class="tooltiptext">أن غالبية الأشخاص 
أرادوا أن نبني الذكاء الخارق:</span></span>
		<span class="tooltip">AI that&#39;s vastly smarter
than us in all ways.<span class="tooltiptext">الذكاء الاصطناعي الذي يفوقنا ذكاءً
بمراحل كثيرة.</span></span>
		<span class="tooltip">What there was the greatest agreement on
was that we should be ambitious<span class="tooltiptext">وكان هناك اتفاق عظيم في الرأي يقتضي
أنه يجب علينا أن نكون طموحين</span></span>
		<span class="tooltip">and help life spread into the cosmos,<span class="tooltiptext">ونساعد في نشر الحياة بالكون،</span></span>
		<span class="tooltip">but there was much less agreement
about who or what should be in charge.<span class="tooltiptext">ولكن كان هناك اتفاق أقل بكثير حول 
من سيكون مسؤولاً عنه.</span></span>
		<span class="tooltip">And I was actually quite amused<span class="tooltiptext">وحقيقةً لقد كنت مستمتعًا</span></span>
		<span class="tooltip">to see that there&#39;s some some people
who want it to be just machines.<span class="tooltiptext">برؤية أن هناك عدد من الأشخاص أرادوا 
أن تكون الآلات فقط هي المسؤولة.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(ضحك)</span></span>
	</p>
	<p>
		<span class="tooltip">And there was total disagreement
about what the role of humans should be,<span class="tooltiptext">وكان هناك اختلاف كبير في الآراء 
حول دور البشر المستقبلي،</span></span>
		<span class="tooltip">even at the most basic level,<span class="tooltiptext">حتى في المستويات الأساسية،</span></span>
		<span class="tooltip">so let&#39;s take a closer look
at possible futures<span class="tooltiptext">لذلك دعونا نلقي نظرة على المستقبل المحتمل</span></span>
		<span class="tooltip">that we might choose
to steer toward, alright?<span class="tooltiptext">الذي قد نتجه نحوه، حسنًا؟</span></span>
	</p>
	<p>
		<span class="tooltip">So don&#39;t get me wrong here.<span class="tooltiptext">لا تفهموني بشكل خاطئ.</span></span>
		<span class="tooltip">I&#39;m not talking about space travel,<span class="tooltiptext">لست أتحدث عن السفر عبر الفضاء،</span></span>
		<span class="tooltip">merely about humanity&#39;s
metaphorical journey into the future.<span class="tooltiptext">بل حول رحلة البشر المجازية تجاه المستقبل.</span></span>
		<span class="tooltip">So one option that some
of my AI colleagues like<span class="tooltiptext">أحد الخيارات والذي أعجب أحد زملائي</span></span>
		<span class="tooltip">is to build superintelligence
and keep it under human control,<span class="tooltiptext">يقتضي أن نبني الذكاء الخارق 
ونجعله تحت سيطرة البشر،</span></span>
		<span class="tooltip">like an enslaved god,<span class="tooltiptext">كإله مستعبَد،</span></span>
		<span class="tooltip">disconnected from the internet<span class="tooltiptext">بحيث يكون مفصولًا عن الإنترنت</span></span>
		<span class="tooltip">and used to create unimaginable
technology and wealth<span class="tooltiptext">ويستخدم لخلق تكنولوجيا وثروة هائلة</span></span>
		<span class="tooltip">for whoever controls it.<span class="tooltiptext">لصالح من يديرها.</span></span>
		<span class="tooltip">But Lord Acton warned us<span class="tooltiptext">ولكن لورد أكتون حذرنا</span></span>
		<span class="tooltip">that power corrupts,
and absolute power corrupts absolutely,<span class="tooltiptext">من أن السلطة قد تخلق الفساد 
والسلطة المطلقة ستخلق الفساد بلا شك،</span></span>
		<span class="tooltip">so you might worry that maybe
we humans just aren&#39;t smart enough,<span class="tooltiptext">لذلك قد يثير ذلك القلق 
حول عدم امتلاك البشر للذكاء الكافي،</span></span>
		<span class="tooltip">or wise enough rather,<span class="tooltiptext">أو الحكمة الكافية،</span></span>
		<span class="tooltip">to handle this much power.<span class="tooltiptext">للتحكم في هذه السلطة والقوة.</span></span>
		<span class="tooltip">Also, aside from any
moral qualms you might have<span class="tooltiptext">أيضًا بجانب تأنيب الضمير الذي قد تشعر به</span></span>
		<span class="tooltip">about enslaving superior minds,<span class="tooltiptext">حول استعباد عقول خارقة،</span></span>
		<span class="tooltip">you might worry that maybe
the superintelligence could outsmart us,<span class="tooltiptext">يجب عليك أن تقلق حول إمكانية 
تفوّق الذكاء الصناعي الخارق علينا،</span></span>
		<span class="tooltip">break out and take over.<span class="tooltiptext">ثم يستقل ويتولى الأمور.</span></span>
		<span class="tooltip">But I also have colleagues
who are fine with AI taking over<span class="tooltiptext">ولكن بعض زملائي متصالحون
مع فكرة تولي الذكاء الصناعي القيادة</span></span>
		<span class="tooltip">and even causing human extinction,<span class="tooltiptext">بل وحتى إمكانية تسببه بانقراض البشر،</span></span>
		<span class="tooltip">as long as we feel the the AIs
are our worthy descendants,<span class="tooltiptext">ما دمنا نشعر أن أنظمة الذكاء الاصطناعي 
هي ورثتنا الكفؤ،</span></span>
		<span class="tooltip">like our children.<span class="tooltiptext">كأبنائنا.</span></span>
		<span class="tooltip">But how would we know that the AIs
have adopted our best values<span class="tooltiptext">ولكن كيف نعرف أن هذه الأنظمة 
تمتلك أفضل قيمنا</span></span>
		<span class="tooltip">and aren&#39;t just unconscious zombies
tricking us into anthropomorphizing them?<span class="tooltiptext">وليست مجرد زومبي غير واع يلاحقنا لتجسيده؟</span></span>
		<span class="tooltip">Also, shouldn&#39;t those people
who don&#39;t want human extinction<span class="tooltiptext">أيضًا، ألا يمتلك هؤلاء 
الذين لا يريدون فناء البشر</span></span>
		<span class="tooltip">have a say in the matter, too?<span class="tooltiptext">رأيًا حول المسألة؟</span></span>
		<span class="tooltip">Now, if you didn&#39;t like either
of those two high-tech options,<span class="tooltiptext">الآن إذا لم تعجبك 
خيارات التكنولوجيا المتقدمة،</span></span>
		<span class="tooltip">it&#39;s important to remember
that low-tech is suicide<span class="tooltiptext">فمن المهم أن تتذكر 
بأن التكنولوجيا البسيطة انتحار</span></span>
		<span class="tooltip">from a cosmic perspective,<span class="tooltiptext">من منطلق كوني،</span></span>
		<span class="tooltip">because if we don&#39;t go far
beyond today&#39;s technology,<span class="tooltiptext">لأنه إذا لم نتجاوز تكنولوجيا اليوم،</span></span>
		<span class="tooltip">the question isn&#39;t whether humanity
is going to go extinct,<span class="tooltiptext">فإن السؤال لن يكون 
حول إمكانية انقراض البشر،</span></span>
		<span class="tooltip">merely whether
we&#39;re going to get taken out<span class="tooltiptext">بل حول إمكانية إخراجنا من النظام الكوني</span></span>
		<span class="tooltip">by the next killer asteroid, supervolcano<span class="tooltiptext">بواسطة الكويكبات القاتلة والبراكين الضخمة</span></span>
		<span class="tooltip">or some other problem
that better technology could have solved.<span class="tooltiptext">أو مشاكل أخرى 
تستطيع التكنولوجيا الحديثة معالجتها.</span></span>
	</p>
	<p>
		<span class="tooltip">So, how about having
our cake and eating it ...<span class="tooltiptext">لذلك ماذا عن الحصول على كعكتنا ثم تناولها</span></span>
		<span class="tooltip">with AGI that&#39;s not enslaved<span class="tooltiptext">مع ذكاء اصطناعي خارق وغير مستعبد</span></span>
		<span class="tooltip">but treats us well because its values
are aligned with ours?<span class="tooltiptext">ولكن يعاملنا جيدًا لأن لديه قيمًا 
تتماشى مع قيمنا؟</span></span>
		<span class="tooltip">This is the gist of what Eliezer Yudkowsky
has called &quot;friendly AI,&quot;<span class="tooltiptext">هذا خلاصة ما كان يدعوه إيليزر يودكاوسكي
بـ&quot;الذكاء الاصطناعي اللطيف&quot;</span></span>
		<span class="tooltip">and if we can do this,
it could be awesome.<span class="tooltiptext">وإذا استطعنا القيام بهذا الأمر 
فسيكون أمرًا رائعًا.</span></span>
		<span class="tooltip">It could not only eliminate negative
experiences like disease, poverty,<span class="tooltiptext">فلن يقضي على الأمور السلبية فقط 
كالأمراض والفقر</span></span>
		<span class="tooltip">crime and other suffering,<span class="tooltiptext">والجرائم والمعاناة،</span></span>
		<span class="tooltip">but it could also give us
the freedom to choose<span class="tooltiptext">بل قد تعطينا حرية الاختيار</span></span>
		<span class="tooltip">from a fantastic new diversity
of positive experiences --<span class="tooltiptext">من تنوع جديد وعظيم لتجارب إيجابية...</span></span>
		<span class="tooltip">basically making us
the masters of our own destiny.<span class="tooltiptext">فتجعلنا ببساطة أسياد على مصائرنا.</span></span>
	</p>
	<p>
		<span class="tooltip">So in summary,<span class="tooltiptext">خلاصة الأمر،</span></span>
		<span class="tooltip">our situation with technology
is complicated,<span class="tooltiptext">علاقتنا بالتكنولوجيا معقدة،</span></span>
		<span class="tooltip">but the big picture is rather simple.<span class="tooltiptext">ولكن الصورة العامة بسيطة.</span></span>
		<span class="tooltip">Most AI researchers
expect AGI within decades,<span class="tooltiptext">يتنبأ غالبية الباحثين 
بحدوث الذكاء الاصطناعي الخارق خلال عقود،</span></span>
		<span class="tooltip">and if we just bumble
into this unprepared,<span class="tooltiptext">وإذا مشينا تجاه هذا الحدث بتخبط 
وعدم استعداد،</span></span>
		<span class="tooltip">it will probably be
the biggest mistake in human history --<span class="tooltiptext">سيكون أكبر خطأ نرتكبه في تاريخ البشرية...</span></span>
		<span class="tooltip">let&#39;s face it.<span class="tooltiptext">دعونا نواجه الأمر.</span></span>
		<span class="tooltip">It could enable brutal,
global dictatorship<span class="tooltiptext">قد تسمح بظهور دكتاتورية وحشية عالميًا</span></span>
		<span class="tooltip">with unprecedented inequality,
surveillance and suffering,<span class="tooltiptext">مع عدم مساواة غير مسبوقة ورقابة ومعاناة،</span></span>
		<span class="tooltip">and maybe even human extinction.<span class="tooltiptext">بل وربما يمتد الأمر لانقراض البشر.</span></span>
		<span class="tooltip">But if we steer carefully,<span class="tooltiptext">ولكن إذا تحركنا بحذر،</span></span>
		<span class="tooltip">we could end up in a fantastic future
where everybody&#39;s better off:<span class="tooltiptext">قد ينتهي بنا الأمر في مستقبل رائع 
حيث يتحسن حال الجميع:</span></span>
		<span class="tooltip">the poor are richer, the rich are richer,<span class="tooltiptext">يغتني الفقراء ويزداد الأغنياء ثراءً،</span></span>
		<span class="tooltip">everybody is healthy
and free to live out their dreams.<span class="tooltiptext">الجميع صحيون ويعيشون أحلامهم.</span></span>
	</p>
	<p>
		<span class="tooltip">Now, hang on.<span class="tooltiptext">ولكن تمهلوا.</span></span>
		<span class="tooltip">Do you folks want the future
that&#39;s politically right or left?<span class="tooltiptext">هل تريدون أيها القوم مستقبلاً
يساريًّا سياسيًا أم يمينيًّا؟</span></span>
		<span class="tooltip">Do you want the pious society
with strict moral rules,<span class="tooltiptext">هل تريدون مجتمعًا متدينًا 
بقواعد أخلاقية صارمة</span></span>
		<span class="tooltip">or do you an hedonistic free-for-all,<span class="tooltiptext">أم تريدون حرية المتع والشهوات للجميع،</span></span>
		<span class="tooltip">more like Burning Man 24/7?<span class="tooltiptext">كمهرجان الرجل المحترق؟</span></span>
		<span class="tooltip">Do you want beautiful beaches,
forests and lakes,<span class="tooltiptext">هل تريدون شواطئ جميلة وغابات وبحيرات،</span></span>
		<span class="tooltip">or would you prefer to rearrange
some of those atoms with the computers,<span class="tooltiptext">أم تفضلون إعادة ترتيب بعض تلك الذرات 
مع أجهزة الكمبيوتر،</span></span>
		<span class="tooltip">enabling virtual experiences?<span class="tooltiptext">وتمكين الخبرات الافتراضية؟</span></span>
		<span class="tooltip">With friendly AI, we could simply
build all of these societies<span class="tooltiptext">مع الذكاء الاصطناعي الصديق نستطيع ببساطة 
بناء كل هذه المجتمعات</span></span>
		<span class="tooltip">and give people the freedom
to choose which one they want to live in<span class="tooltiptext">وإعطاء الأشخاص حرية اختيار أي منها 
للعيش فيه</span></span>
		<span class="tooltip">because we would no longer
be limited by our intelligence,<span class="tooltiptext">لأننا لن نعود محدودين بمقدار الذكاء 
الذي نمتلكه،</span></span>
		<span class="tooltip">merely by the laws of physics.<span class="tooltiptext">بل بقوانين الفيزياء فقط.</span></span>
		<span class="tooltip">So the resources and space
for this would be astronomical --<span class="tooltiptext">ولذلك فإن الموارد والمساحة 
لهذا المشروع ستكون ضخمة...</span></span>
		<span class="tooltip">literally.<span class="tooltiptext">فعليًا.</span></span>
	</p>
	<p>
		<span class="tooltip">So here&#39;s our choice.<span class="tooltiptext">وسيكون هذا خيارنا.</span></span>
		<span class="tooltip">We can either be complacent
about our future,<span class="tooltiptext">إما أن نرضى بمستقبلنا،</span></span>
		<span class="tooltip">taking as an article of blind faith<span class="tooltiptext">ونؤمن بشكل أعمى</span></span>
		<span class="tooltip">that any new technology
is guaranteed to be beneficial,<span class="tooltiptext">بأن أي تكنولوجيا جديدة لابد وأن تكون مفيدة</span></span>
		<span class="tooltip">and just repeat that to ourselves
as a mantra over and over and over again<span class="tooltiptext">ونكرر ذلك على أنفسنا، مرارًا وتكرارًا
كتعويذة ما</span></span>
		<span class="tooltip">as we drift like a rudderless ship
towards our own obsolescence.<span class="tooltiptext">ونحن ننجرف كسفينة بلا دفة تجاه هلاكنا.</span></span>
		<span class="tooltip">Or we can be ambitious --<span class="tooltiptext">أو نستطيع أن نكون طموحين...</span></span>
		<span class="tooltip">thinking hard about how
to steer our technology<span class="tooltiptext">ونفكر بعمق حول كيفية توجيه التكنولوجيا</span></span>
		<span class="tooltip">and where we want to go with it<span class="tooltiptext">وأين نريد الذهاب بها</span></span>
		<span class="tooltip">to create the age of amazement.<span class="tooltiptext">لخلق عصر مدهش.</span></span>
		<span class="tooltip">We&#39;re all here to celebrate
the age of amazement,<span class="tooltiptext">نحن هنا جميعًا لنحتفل بعصر الدهشة،</span></span>
		<span class="tooltip">and I feel that its essence should lie
in becoming not overpowered<span class="tooltiptext">وأشعر بأن جوهره يجب أن يكمن
في عدم المبالغة بامتلاك القوة</span></span>
		<span class="tooltip">but empowered by our technology.<span class="tooltiptext">وأن تكون القوة بواسطة التكنولوجيا.</span></span>
	</p>
	<p>
		<span class="tooltip">Thank you.<span class="tooltiptext">شكرًا لكم.</span></span>
	</p>
	<p>
		<span class="tooltip">(Applause)<span class="tooltiptext">(تصفيق)</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	