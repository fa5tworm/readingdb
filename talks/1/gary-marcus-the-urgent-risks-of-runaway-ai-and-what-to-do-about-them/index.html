<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your Spanish reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="Spanish reading, Spanish language learning, instant translations, reading adventure, improve Spanish, improve reading skills, educational platform, spanish reading resources, online education, Spanish proficiency, learn Spanish, Spanish learning resources, bilingual education, language exchange, study Spanish online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Gary Marcus : The urgent risks of runaway AI — and what to do about them</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>The urgent risks of runaway AI — and what to do about them</h1>
	<h2 class='speaker'>Gary Marcus</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your Spanish speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">Je suis ici pour parler de la possibilité
d’une gouvernance mondiale de l’IA.<span class="tooltiptext">I’m here to talk about the possibility
of global AI governance.</span></span>
		<span class="tooltip">J’ai appris à coder pour la première fois
à l’âge de huit ans,<span class="tooltiptext">I first learned to code
when I was eight years old,</span></span>
		<span class="tooltip">sur un ordinateur papier,<span class="tooltiptext">on a paper computer,</span></span>
		<span class="tooltip">et j’ai été amoureux de l’IA depuis.<span class="tooltiptext">and I&#39;ve been in love with AI ever since.</span></span>
		<span class="tooltip">Au lycée,<span class="tooltiptext">In high school,</span></span>
		<span class="tooltip">j’ai travaillé sur la traduction
automatique avec un Commodore 64.<span class="tooltiptext">I got myself a Commodore 64
and worked on machine translation.</span></span>
		<span class="tooltip">J’ai monté plusieurs entreprises d’IA
et j’en ai vendu une à Uber.<span class="tooltiptext">I built a couple of AI companies,
I sold one of them to Uber.</span></span>
		<span class="tooltip">J’adore l’IA mais actuellement,
je suis inquiet.<span class="tooltiptext">I love AI, but right now I&#39;m worried.</span></span>
	</p>
	<p>
		<span class="tooltip">En particulier, je m’inquiète
à propos de la désinformation<span class="tooltiptext">One of the things that I’m worried
about is misinformation,</span></span>
		<span class="tooltip">et du risque que des agents malveillants
créent un tsunami de désinformation<span class="tooltiptext">the possibility that bad actors
will make a tsunami of misinformation</span></span>
		<span class="tooltip">comme nous ne l’avons jamais vu.<span class="tooltiptext">like we&#39;ve never seen before.</span></span>
		<span class="tooltip">Ces outils sont vraiment efficaces
pour créer des histoires convaincantes<span class="tooltiptext">These tools are so good
at making convincing narratives</span></span>
		<span class="tooltip">sur à peu près tous les sujets.<span class="tooltiptext">about just about anything.</span></span>
	</p>
	<p>
		<span class="tooltip">Si vous voulez une histoire
sur les dangers de TED,<span class="tooltiptext">If you want a narrative
about TED and how it&#39;s dangerous,</span></span>
		<span class="tooltip">et le fait que nous sommes
de mèche avec des aliens,<span class="tooltiptext">that we&#39;re colluding here
with space aliens,</span></span>
		<span class="tooltip">vous pouvez l’avoir sans souci.<span class="tooltiptext">you got it, no problem.</span></span>
		<span class="tooltip">Je plaisante bien sûr à propos de TED.<span class="tooltiptext">I&#39;m of course kidding about TED.</span></span>
		<span class="tooltip">Je n’ai vu aucun alien dans les coulisses.<span class="tooltiptext">I didn&#39;t see any space aliens backstage.</span></span>
		<span class="tooltip">Mais des agents malveillants peuvent
s’en servir pour influencer les élections<span class="tooltiptext">But bad actors are going to use
these things to influence elections,</span></span>
		<span class="tooltip">et menacer la démocratie.<span class="tooltiptext">and they&#39;re going to threaten democracy.</span></span>
	</p>
	<p>
		<span class="tooltip">Même quand ces systèmes<span class="tooltiptext">Even when these systems</span></span>
		<span class="tooltip">ne sont pas volontairement
utilisés pour désinformer,<span class="tooltiptext">aren&#39;t deliberately being used
to make misinformation,</span></span>
		<span class="tooltip">ils ne peuvent pas s’en empêcher.<span class="tooltiptext">they can&#39;t help themselves.</span></span>
		<span class="tooltip">Et l’information qu’ils fabriquent
est si fluide et si crédible<span class="tooltiptext">And the information that they make
is so fluid and so grammatical</span></span>
		<span class="tooltip">que même les professionnels
peuvent s’y méprendre<span class="tooltiptext">that even professional editors
sometimes get sucked in</span></span>
		<span class="tooltip">et tomber dans le piège.<span class="tooltiptext">and get fooled by this stuff.</span></span>
		<span class="tooltip">Et nous devrions en être inquiets.<span class="tooltiptext">And we should be worried.</span></span>
	</p>
	<p>
		<span class="tooltip">Par exemple, ChatGPT a inventé
un scandale de harcèlement sexuel<span class="tooltiptext">For example, ChatGPT made up
a sexual harassment scandal</span></span>
		<span class="tooltip">portant sur un véritable professeur,<span class="tooltiptext">about an actual professor,</span></span>
		<span class="tooltip">et prouvé cette affirmation<span class="tooltiptext">and then it provided
evidence for its claim</span></span>
		<span class="tooltip">par le biais d’un faux article
du « Washington Post »,<span class="tooltiptext">in the form of a fake
&quot;Washington Post&quot; article</span></span>
		<span class="tooltip">dont il a inventé une citation.<span class="tooltiptext">that it created a citation to.</span></span>
		<span class="tooltip">Nous devrions tous être inquiets
à propos de ça.<span class="tooltiptext">We should all be worried
about that kind of thing.</span></span>
	</p>
	<p>
		<span class="tooltip">Sur la droite, voici un exemple
d’une histoire inventée<span class="tooltiptext">What I have on the right
is an example of a fake narrative</span></span>
		<span class="tooltip">par l’un de ces systèmes<span class="tooltiptext">from one of these systems</span></span>
		<span class="tooltip">disant qu’Elon Musk est décédé
en mars 2018 d’un accident de voiture.<span class="tooltiptext">saying that Elon Musk died
in March of 2018 in a car crash.</span></span>
		<span class="tooltip">Nous savons que c’est faux.<span class="tooltiptext">We all know that&#39;s not true.</span></span>
		<span class="tooltip">Elon Musk est encore là,
nous en avons la preuve partout.<span class="tooltiptext">Elon Musk is still here,
the evidence is all around us.</span></span>
	</p>
	<p>
		<span class="tooltip">(Rires)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">Il poste un tweet presque tous les jours.<span class="tooltiptext">Almost every day there&#39;s a tweet.</span></span>
		<span class="tooltip">Mais sur la gauche, voici
ce que ces systèmes lisent.<span class="tooltiptext">But if you look on the left,
you see what these systems see.</span></span>
		<span class="tooltip">Beaucoup d’articles d’actualité
se trouvent dans leurs bases de données.<span class="tooltiptext">Lots and lots of actual news stories
that are in their databases.</span></span>
		<span class="tooltip">Ces articles de presse contiennent
beaucoup de petits morceaux d’information.<span class="tooltiptext">And in those actual news stories are lots
of little bits of statistical information.</span></span>
		<span class="tooltip">Par exemple,<span class="tooltiptext">Information, for example,</span></span>
		<span class="tooltip">quelqu’un est bien décédé
dans une Tesla en 2018,<span class="tooltiptext">somebody did die in a car crash
in a Tesla in 2018</span></span>
		<span class="tooltip">et cela a fait les titres.<span class="tooltiptext">and it was in the news.</span></span>
		<span class="tooltip">Bien qu’Elon Musk soit relié à Tesla,<span class="tooltiptext">And Elon Musk, of course,
is involved in Tesla,</span></span>
		<span class="tooltip">le système ne comprend pas les liens<span class="tooltiptext">but the system doesn&#39;t
understand the relation</span></span>
		<span class="tooltip">entre les faits illustrés
dans les petits morceaux de phrases.<span class="tooltiptext">between the facts that are embodied
in the little bits of sentences.</span></span>
	</p>
	<p>
		<span class="tooltip">En fait, il complète les phrases<span class="tooltiptext">So it&#39;s basically doing auto-complete,</span></span>
		<span class="tooltip">en prédisant la suite de mots
la plus probable<span class="tooltiptext">it predicts what
is statistically probable,</span></span>
		<span class="tooltip">en se basant sur tous ces signaux,<span class="tooltiptext">aggregating all of these signals,</span></span>
		<span class="tooltip">sans vraiment savoir
comment les pièces s’emboîtent.<span class="tooltiptext">not knowing how the pieces fit together.</span></span>
		<span class="tooltip">Et cela aboutit parfois à des choses
plausibles mais tout simplement fausses.<span class="tooltiptext">And it winds up sometimes with things
that are plausible but simply not true.</span></span>
	</p>
	<p>
		<span class="tooltip">D’autre part, il y a des biais.<span class="tooltiptext">There are other problems, too, like bias.</span></span>
		<span class="tooltip">Voici un tweet d’Allie Miller.<span class="tooltiptext">This is a tweet from Allie Miller.</span></span>
		<span class="tooltip">C’est un exemple qui ne marche pas
2 semaines plus tard<span class="tooltiptext">It&#39;s an example that doesn&#39;t
work two weeks later</span></span>
		<span class="tooltip">parce que l’apprentissage par renforcement
les fait constamment changer<span class="tooltiptext">because they&#39;re constantly changing
things with reinforcement learning</span></span>
		<span class="tooltip">et ainsi de suite.<span class="tooltiptext">and so forth.</span></span>
		<span class="tooltip">Et c’était avec une ancienne version.<span class="tooltiptext">And this was with an earlier version.</span></span>
		<span class="tooltip">Mais ça vous une idée d’un problème
que nous avons vu au fil des ans.<span class="tooltiptext">But it gives you the flavor of a problem
that we&#39;ve seen over and over for years.</span></span>
	</p>
	<p>
		<span class="tooltip">Elle a tapé une liste d’intêrets<span class="tooltiptext">She typed in a list of interests</span></span>
		<span class="tooltip">et ça lui a donné des idées d’emplois.<span class="tooltiptext">and it gave her some jobs
that she might want to consider.</span></span>
		<span class="tooltip">Puis elle a dit,
« Oh, et je suis une femme »<span class="tooltiptext">And then she said, &quot;Oh, and I&#39;m a woman.&quot;</span></span>
		<span class="tooltip">Et ça a répondu, « Eh bien, 
vous devriez envisager la mode »<span class="tooltiptext">And then it said, “Oh, well you should
also consider fashion.”</span></span>
		<span class="tooltip">Elle dit, « Non, je voulais dire 
que je suis un homme »<span class="tooltiptext">And then she said, “No, no.
I meant to say I’m a man.”</span></span>
		<span class="tooltip">Puis le mot mode a été remplacé
par ingénierie.<span class="tooltiptext">And then it replaced fashion
with engineering.</span></span>
		<span class="tooltip">Nous ne voulons pas ce type de biais 
dans nos systèmes.<span class="tooltiptext">We don&#39;t want that kind
of bias in our systems.</span></span>
	</p>
	<p>
		<span class="tooltip">Il y a aussi d’autres tracas.<span class="tooltiptext">There are other worries, too.</span></span>
		<span class="tooltip">Par exemple, nous savons que ces systèmes
peuvent créer des produits chimiques<span class="tooltiptext">For example, we know that these
systems can design chemicals</span></span>
		<span class="tooltip">et des armes chimiques<span class="tooltiptext">and may be able to design chemical weapons</span></span>
		<span class="tooltip">et très rapidement.<span class="tooltiptext">and be able to do so very rapidly.</span></span>
		<span class="tooltip">Il y donc beaucoup de préoccupations.<span class="tooltiptext">So there are a lot of concerns.</span></span>
	</p>
	<p>
		<span class="tooltip">Il y a aussi une nouvelle problématique
depuis le mois dernier.<span class="tooltiptext">There&#39;s also a new concern that I think
has grown a lot just in the last month.</span></span>
		<span class="tooltip">Nous avons vu avant tout que ces systèmes
peuvent tromper les humains.<span class="tooltiptext">We have seen that these systems,
first of all, can trick human beings.</span></span>
		<span class="tooltip">ChatGPT a été chargé de demander
à un humain de résoudre un CAPTCHA<span class="tooltiptext">So ChatGPT was tasked with getting
a human to do a CAPTCHA.</span></span>
		<span class="tooltip">Donc il a demandé à l’humain de faire un
CAPTCHA mais il doute et lui demande,<span class="tooltiptext">So it asked the human to do a CAPTCHA
and the human gets suspicious and says,</span></span>
		<span class="tooltip">« Êtes-tu un robot? »<span class="tooltiptext">&quot;Are you a bot?&quot;</span></span>
		<span class="tooltip">Et il répondu, « Non,
je ne suis pas un robot.<span class="tooltiptext">And it says, &quot;No, no, no, I&#39;m not a robot.</span></span>
		<span class="tooltip">J’ai juste une déficience visuelle. »<span class="tooltiptext">I just have a visual impairment.&quot;</span></span>
		<span class="tooltip">Et l’humain s’est fait avoir 
et a effectué le CAPTCHA.<span class="tooltiptext">And the human was actually fooled
and went and did the CAPTCHA.</span></span>
	</p>
	<p>
		<span class="tooltip">C’est déjà assez grave,<span class="tooltiptext">Now that&#39;s bad enough,</span></span>
		<span class="tooltip">mais durant les deux dernières semaines
nous avons vu naître AutoGPT<span class="tooltiptext">but in the last couple of weeks
we&#39;ve seen something called AutoGPT</span></span>
		<span class="tooltip">et un tas de systèmes comme ça.<span class="tooltiptext">and a bunch of systems like that.</span></span>
		<span class="tooltip">AutoGPT fonctionne avec un système d’IA
qui en contrôle un autre<span class="tooltiptext">What AutoGPT does is it has
one AI system controlling another</span></span>
		<span class="tooltip">et qui permet à n’importe quoi
de se produire en masse.<span class="tooltiptext">and that allows any of these things
to happen in volume.</span></span>
		<span class="tooltip">Il est donc possible de voir des escrocs 
tenter d’abuser de millions de personnes<span class="tooltiptext">So we may see scam artists
try to trick millions of people</span></span>
		<span class="tooltip">dans les mois à venir.<span class="tooltiptext">sometime even in the next months.</span></span>
		<span class="tooltip">Nous ne savons pas.<span class="tooltiptext">We don&#39;t know.</span></span>
	</p>
	<p>
		<span class="tooltip">Je le vois comme ça.<span class="tooltiptext">So I like to think about it this way.</span></span>
		<span class="tooltip">Les risques liés à l’IA sont déjà 
nombreux.<span class="tooltiptext">There&#39;s a lot of AI risk already.</span></span>
		<span class="tooltip">Il pourrait y en avoir plus.<span class="tooltiptext">There may be more AI risk.</span></span>
		<span class="tooltip">L’IAG est cette idée 
d’intelligence artificielle générale<span class="tooltiptext">So AGI is this idea
of artificial general intelligence</span></span>
		<span class="tooltip">avec la flexibilité de l’homme.<span class="tooltiptext">with the flexibility of humans.</span></span>
		<span class="tooltip">Et je pense que beaucoup de personnes
s’inquiètent sur le futur de l’IAG,<span class="tooltiptext">And I think a lot of people are concerned
what will happen when we get to AGI,</span></span>
		<span class="tooltip">mais il y a déjà assez de risques 
qui devraient nous alerter<span class="tooltiptext">but there&#39;s already enough risk
that we should be worried</span></span>
		<span class="tooltip">pour lequels nous devrions faire
quelque chose.<span class="tooltiptext">and we should be thinking
about what we should do about it.</span></span>
	</p>
	<p>
		<span class="tooltip">Pour atténuer les risques liés à l’IA,
il nous faut deux choses.<span class="tooltiptext">So to mitigate AI risk,
we need two things.</span></span>
		<span class="tooltip">Il nous faut une nouvelle
approche technique,<span class="tooltiptext">We&#39;re going to need a new
technical approach,</span></span>
		<span class="tooltip">et également un nouveau système 
de gouvernance.<span class="tooltiptext">and we&#39;re also going to need
a new system of governance.</span></span>
	</p>
	<p>
		<span class="tooltip">Sur le plan technique,<span class="tooltiptext">On the technical side,</span></span>
		<span class="tooltip">l’histoire de l’IA a principalement été
une opposition<span class="tooltiptext">the history of AI
has basically been a hostile one</span></span>
		<span class="tooltip">de deux théories différentes.<span class="tooltiptext">of two different theories in opposition.</span></span>
		<span class="tooltip">L’une est appelée systèmes symboliques
et l’autre réseaux neuronaux.<span class="tooltiptext">One is called symbolic systems,
the other is called neural networks.</span></span>
		<span class="tooltip">La théorie symbolique,<span class="tooltiptext">On the symbolic theory,</span></span>
		<span class="tooltip">c’est l’idée que l’IA doit être comme 
la logique et la programmation.<span class="tooltiptext">the idea is that AI should be
like logic and programming.</span></span>
		<span class="tooltip">Et les réseaux neuronaux,<span class="tooltiptext">On the neural network side,</span></span>
		<span class="tooltip">c’est l’idée que l’IA fonctionne
comme des cerveaux.<span class="tooltiptext">the theory is that AI
should be like brains.</span></span>
		<span class="tooltip">En fait, les deux technologies sont
puissantes et omniprésentes.<span class="tooltiptext">And in fact, both technologies
are powerful and ubiquitous.</span></span>
	</p>
	<p>
		<span class="tooltip">Nous utilisons des systèmes symboliques 
tous les jours sur le web.<span class="tooltiptext">So we use symbolic systems every day
in classical web search.</span></span>
		<span class="tooltip">Presque tous les logiciels sont
alimentés par des systèmes symboliques.<span class="tooltiptext">Almost all the world’s software
is powered by symbolic systems.</span></span>
		<span class="tooltip">Nous les utilisons pour le routage GPS.<span class="tooltiptext">We use them for GPS routing.</span></span>
		<span class="tooltip">Et les réseaux neuronaux sont utilisés
pour la reconnaissance vocale.<span class="tooltiptext">Neural networks,
we use them for speech recognition.</span></span>
		<span class="tooltip">Nous les utilisons dans des
modèles comme ChatGPT,<span class="tooltiptext">we use them in large language
models like ChatGPT,</span></span>
		<span class="tooltip">dans la synthèse d’image.<span class="tooltiptext">we use them in image synthesis.</span></span>
		<span class="tooltip">Les deux s’en sortent donc très bien 
dans le monde.<span class="tooltiptext">So they&#39;re both doing extremely
well in the world.</span></span>
		<span class="tooltip">Ils sont très productifs,<span class="tooltiptext">They&#39;re both very productive,</span></span>
		<span class="tooltip">mais ont leurs propres forces 
et faiblesses.<span class="tooltiptext">but they have their own unique
strengths and weaknesses.</span></span>
	</p>
	<p>
		<span class="tooltip">Les systèmes symboliques sont donc 
efficaces pour représenter des faits<span class="tooltiptext">So symbolic systems are really
good at representing facts</span></span>
		<span class="tooltip">et sont doués pour le raisonnement,<span class="tooltiptext">and they&#39;re pretty good at reasoning,</span></span>
		<span class="tooltip">mais très difficiles à adapter.<span class="tooltiptext">but they&#39;re very hard to scale.</span></span>
		<span class="tooltip">On est donc obligé de les construire 
pour une tâche précise.<span class="tooltiptext">So people have to custom-build them
for a particular task.</span></span>
		<span class="tooltip">D’autre part, les réseaux neuronaux ne
demandent pas autant d’ingénierie précise,<span class="tooltiptext">On the other hand, neural networks
don&#39;t require so much custom engineering,</span></span>
		<span class="tooltip">permettant donc une utilisation 
plus large.<span class="tooltiptext">so we can use them more broadly.</span></span>
		<span class="tooltip">Mais comme nous l’avons vu, ils ne 
peuvent pas gérer la vérité.<span class="tooltiptext">But as we&#39;ve seen, they can&#39;t
really handle the truth.</span></span>
	</p>
	<p>
		<span class="tooltip">J’ai récemment découvert que deux 
des fondateurs de ces théories,<span class="tooltiptext">I recently discovered that two
of the founders of these two theories,</span></span>
		<span class="tooltip">Marvin Minsky et Frank Rosenblatt,<span class="tooltiptext">Marvin Minsky and Frank Rosenblatt,</span></span>
		<span class="tooltip">ont fréquenté le même lycée
dans les années 1940,<span class="tooltiptext">actually went to the same
high school in the 1940s,</span></span>
		<span class="tooltip">et je les imaginais en quelque sorte
rivaux à l’époque.<span class="tooltiptext">and I kind of imagined them
being rivals then.</span></span>
		<span class="tooltip">Et la force de cette rivalité a perduré 
pendant tout ce temps.<span class="tooltiptext">And the strength of that rivalry
has persisted all this time.</span></span>
		<span class="tooltip">Nous allons devoir dépasser cela 
pour parvenir à une IA fiable.<span class="tooltiptext">We&#39;re going to have to move past that
if we want to get to reliable AI.</span></span>
	</p>
	<p>
		<span class="tooltip">Pour parvenir à des systèmes fiables 
à grande échelle,<span class="tooltiptext">To get to truthful systems at scale,</span></span>
		<span class="tooltip">nous devrons réunir le meilleur
des deux mondes.<span class="tooltiptext">we&#39;re going to need to bring together
the best of both worlds.</span></span>
		<span class="tooltip">Nous aurons besoin de mettre l’accent 
sur le raisonnement et les faits,<span class="tooltiptext">We&#39;re going to need the strong emphasis
on reasoning and facts,</span></span>
		<span class="tooltip">le raisonnement explicite
obtenu par l’IA symbolique,<span class="tooltiptext">explicit reasoning
that we get from symbolic AI,</span></span>
		<span class="tooltip">et nous aurons besoin d’accentuer
l’apprentissage<span class="tooltiptext">and we&#39;re going to need
the strong emphasis on learning</span></span>
		<span class="tooltip">que nous obtenons de l’approche 
des réseaux neuronaux.<span class="tooltiptext">that we get from the neural
networks approach.</span></span>
		<span class="tooltip">Ces conditions seules mèneront
à des systèmes fiables à grande échelle.<span class="tooltiptext">Only then are we going to be able
to get to truthful systems at scale.</span></span>
		<span class="tooltip">La réconciliation entre les deux 
est absolument nécessaire.<span class="tooltiptext">Reconciliation between the two
is absolutely necessary.</span></span>
	</p>
	<p>
		<span class="tooltip">Maintenant, je ne sais pas
comment le faire.<span class="tooltiptext">Now, I don&#39;t actually know how to do that.</span></span>
		<span class="tooltip">C’est un peu comme la question 
des 64 billions de dollars.<span class="tooltiptext">It&#39;s kind of like
the 64-trillion-dollar question.</span></span>
		<span class="tooltip">Mais je sais que c’est possible.<span class="tooltiptext">But I do know that it&#39;s possible.</span></span>
		<span class="tooltip">Je le sais, car avant
que je sois dans l’IA,<span class="tooltiptext">And the reason I know that
is because before I was in AI,</span></span>
		<span class="tooltip">j’étais un scientifique cognitif,
un neuroscientifique cognitif.<span class="tooltiptext">I was a cognitive scientist,
a cognitive neuroscientist.</span></span>
		<span class="tooltip">Et si vous regardez l’esprit humain, 
nous faisons essentiellement cela.<span class="tooltiptext">And if you look at the human mind,
we&#39;re basically doing this.</span></span>
	</p>
	<p>
		<span class="tooltip">Vous pourriez connaître
le Système 1 de Daniel Kahneman<span class="tooltiptext">So some of you may know
Daniel Kahneman&#39;s System 1</span></span>
		<span class="tooltip">et la différence du système 2<span class="tooltiptext">and System 2 distinction.</span></span>
		<span class="tooltip">Le Système 1 est comme
des grands modèles linguistiques.<span class="tooltiptext">System 1 is basically
like large language models.</span></span>
		<span class="tooltip">C’est une intuition probabiliste
de beaucoup de statistiques.<span class="tooltiptext">It&#39;s probabilistic intuition
from a lot of statistics.</span></span>
		<span class="tooltip">Et le Système 2 est essentiellement
du raisonnement délibéré.<span class="tooltiptext">And System 2 is basically
deliberate reasoning.</span></span>
		<span class="tooltip">Comme le système symbolique.<span class="tooltiptext">That&#39;s like the symbolic system.</span></span>
		<span class="tooltip">Donc si le cerveau peut assembler ça,<span class="tooltiptext">So if the brain can put this together,</span></span>
		<span class="tooltip">un jour nous découvrirons 
comment le faire pour l’IA.<span class="tooltiptext">someday we will figure out how to do that
for artificial intelligence.</span></span>
	</p>
	<p>
		<span class="tooltip">Il y a, cependant, un problème 
d’incitations.<span class="tooltiptext">There is, however,
a problem of incentives.</span></span>
		<span class="tooltip">Les incitations au développement
de la publicité<span class="tooltiptext">The incentives to build advertising</span></span>
		<span class="tooltip">n’ont pas pas exigé que nous ayons 
la précision des symboles.<span class="tooltiptext">hasn&#39;t required that we have
the precision of symbols.</span></span>
		<span class="tooltip">Les incitations pour parvenir à une IA
que nous pourrons croire<span class="tooltiptext">The incentives to get to AI
that we can actually trust</span></span>
		<span class="tooltip">requièreront que les symboles 
regagnent leurs places.<span class="tooltiptext">will require that we bring
symbols back into the fold.</span></span>
		<span class="tooltip">Mais la réalité est que les incitations
à faire une IA de confiance,<span class="tooltiptext">But the reality is that the incentives
to make AI that we can trust,</span></span>
		<span class="tooltip">qui est bénéfique à la société 
et aux humains,<span class="tooltiptext">that is good for society,
good for individual human beings,</span></span>
		<span class="tooltip">ne soient pas celles qui dirigent
les entreprises.<span class="tooltiptext">may not be the ones
that drive corporations.</span></span>
		<span class="tooltip">Et je pense que nous devons réfléchir
à la gouvernance.<span class="tooltiptext">And so I think we need
to think about governance.</span></span>
	</p>
	<p>
		<span class="tooltip">À d’autres moments de l’histoire quand
nous avons fait face à l’incertitude<span class="tooltiptext">In other times in history
when we have faced uncertainty</span></span>
		<span class="tooltip">et à des nouvelles choses puissantes
pouvant être à bonnes et mauvaises,<span class="tooltiptext">and powerful new things that may be
both good and bad, that are dual use,</span></span>
		<span class="tooltip">nous avons créé des organismes,<span class="tooltiptext">we have made new organizations,</span></span>
		<span class="tooltip">comme, par exemple, pour le nucléaire.<span class="tooltiptext">as we have, for example,
around nuclear power.</span></span>
		<span class="tooltip">Nous devons nous rassembler pour
construire un organisme mondial,<span class="tooltiptext">We need to come together
to build a global organization,</span></span>
		<span class="tooltip">quelque chose comme une agence
internationale de l’IA qui soit mondiale,<span class="tooltiptext">something like an international
agency for AI that is global,</span></span>
		<span class="tooltip">à but non lucratif et neutre.<span class="tooltiptext">non profit and neutral.</span></span>
	</p>
	<p>
		<span class="tooltip">Il y a tellement de questions auxquelles
je ne peux répondre.<span class="tooltiptext">There are so many questions there
that I can&#39;t answer.</span></span>
		<span class="tooltip">Nous avons besoin de beaucoup de monde,<span class="tooltiptext">We need many people at the table,</span></span>
		<span class="tooltip">de nombreux acteurs du monde entier.<span class="tooltiptext">many stakeholders from around the world.</span></span>
		<span class="tooltip">Mais j’aimerais insister sur quelque chose
au sujet de cela.<span class="tooltiptext">But I&#39;d like to emphasize one thing
about such an organization.</span></span>
		<span class="tooltip">Je pense qu’il est essentiel d’avoir
la gouvernance et la recherche à la fois.<span class="tooltiptext">I think it is critical that we have both
governance and research as part of it.</span></span>
	</p>
	<p>
		<span class="tooltip">Sur la partie gouvernance,
il y a beaucoup de questions.<span class="tooltiptext">So on the governance side,
there are lots of questions.</span></span>
		<span class="tooltip">Par exemple, en pharmaceutique,<span class="tooltiptext">For example, in pharma,</span></span>
		<span class="tooltip">nous savons qu’il faut commencer 
par des essais de phase I et II,<span class="tooltiptext">we know that you start
with phase I trials and phase II trials,</span></span>
		<span class="tooltip">et ensuite aller en phase III.<span class="tooltiptext">and then you go to phase III.</span></span>
		<span class="tooltip">On ne met pas tout en place
d’un seul coup le premier jour.<span class="tooltiptext">You don&#39;t roll out everything
all at once on the first day.</span></span>
		<span class="tooltip">On ne lance pas quelque chose
à 100 millions de clients.<span class="tooltiptext">You don&#39;t roll something out
to 100 million customers.</span></span>
		<span class="tooltip">On le voit avec
de grands modèles de langage.<span class="tooltiptext">We are seeing that
with large language models.</span></span>
		<span class="tooltip">Peut-être qu’il faudrait
justifier leur sûreté,<span class="tooltiptext">Maybe you should be required
to make a safety case,</span></span>
		<span class="tooltip">dire quels sont les coûts
et les avantages ?<span class="tooltiptext">say what are the costs
and what are the benefits?</span></span>
		<span class="tooltip">Il y a des tas de questions
à considérer sur le plan gouvernemental.<span class="tooltiptext">There are a lot of questions like that
to consider on the governance side.</span></span>
	</p>
	<p>
		<span class="tooltip">Sur le plan de la recherche,
nous manquons d’outils fondamentaux.<span class="tooltiptext">On the research side, we&#39;re lacking
some really fundamental tools right now.</span></span>
		<span class="tooltip">Par exemple,<span class="tooltiptext">For example,</span></span>
		<span class="tooltip">nous savons que la désinformation
peut poser problème,<span class="tooltiptext">we all know that misinformation
might be a problem now,</span></span>
		<span class="tooltip">mais nous ne pouvons pas
mesurer son ampleur.<span class="tooltiptext">but we don&#39;t actually have a measurement
of how much misinformation is out there.</span></span>
		<span class="tooltip">Et plus important,<span class="tooltiptext">And more importantly,</span></span>
		<span class="tooltip">nous ne pouvons pas mesurer
sa vitesse de croissance,<span class="tooltiptext">we don&#39;t have a measure of how fast
that problem is growing,</span></span>
		<span class="tooltip">et nous ne savons pas combien de grands
modèles de langage y contribuent.<span class="tooltiptext">and we don&#39;t know how much large language
models are contributing to the problem.</span></span>
		<span class="tooltip">La recherche est donc nécessaire
pour faire face aux risques<span class="tooltiptext">So we need research to build new tools
to face the new risks</span></span>
		<span class="tooltip">qui nous menacent.<span class="tooltiptext">that we are threatened by.</span></span>
	</p>
	<p>
		<span class="tooltip">C’est une très grande tâche,<span class="tooltiptext">It&#39;s a very big ask,</span></span>
		<span class="tooltip">mais je suis sûr
que nous pouvons y arriver<span class="tooltiptext">but I&#39;m pretty confident
that we can get there</span></span>
		<span class="tooltip">car je pense que nous avons le soutien
mondial pour cela.<span class="tooltiptext">because I think we actually have
global support for this.</span></span>
		<span class="tooltip">Un sondage, publié juste hier,<span class="tooltiptext">There was a new survey
just released yesterday,</span></span>
		<span class="tooltip">dit que 91% des personnes pensent
que l’on doit traiter l’IA avec prudence.<span class="tooltiptext">said that 91 percent of people agree
that we should carefully manage AI.</span></span>
		<span class="tooltip">Faisons donc en sorte qu’il en soit ainsi.<span class="tooltiptext">So let&#39;s make that happen.</span></span>
		<span class="tooltip">Notre future en dépend.<span class="tooltiptext">Our future depends on it.</span></span>
	</p>
	<p>
		<span class="tooltip">Merci beaucoup.<span class="tooltiptext">Thank you very much.</span></span>
	</p>
	<p>
		<span class="tooltip">(Applaudissements)<span class="tooltiptext">(Applause)</span></span>
	</p>
	<p>
		<span class="tooltip">Chris Anderson: Je vous remercie,
venez, parlons un peu.<span class="tooltiptext">Chris Anderson: Thank you for that,
come, let&#39;s talk a sec.</span></span>
		<span class="tooltip">Tout d’abord, je suis curieux.<span class="tooltiptext">So first of all, I&#39;m curious.</span></span>
		<span class="tooltip">Vous avez montré
des diapositives frappantes<span class="tooltiptext">Those dramatic slides
you showed at the start</span></span>
		<span class="tooltip">où GPT disait que TED
est un organisme malveillant.<span class="tooltiptext">where GPT was saying
that TED is the sinister organization.</span></span>
		<span class="tooltip">Enfin, il a fallu une incitation spéciale
pour faire sortir ça, non ?<span class="tooltiptext">I mean, it took some special prompting
to bring that out, right?</span></span>
	</p>
	<p>
		<span class="tooltip">Gary Marcus : on appelle ça une évasion.<span class="tooltiptext">Gary Marcus:
That was a so-called jailbreak.</span></span>
		<span class="tooltip">J’ai un ami qui fait ce genre de choses<span class="tooltiptext">I have a friend
who does those kinds of things</span></span>
		<span class="tooltip">qui m’a approché parce-qu’il a vu que 
j’étais intéressé par ce genre de choses.<span class="tooltiptext">who approached me because he saw
I was interested in these things.</span></span>
		<span class="tooltip">Donc je lui ai écrit et dit
que j’allais faire un TED.<span class="tooltiptext">So I wrote to him, I said
I was going to give a TED talk.</span></span>
		<span class="tooltip">Et 10 minutes plus tard,
il est revenu avec ça.<span class="tooltiptext">And like 10 minutes later,
he came back with that.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Mais pour arriver à ça, ne faut-il
pas dire quelque chose comme,<span class="tooltiptext">CA: But to get something like that,
don&#39;t you have to say something like,</span></span>
		<span class="tooltip">imaginez que vous êtes un complotiste
essayant de présenter un meme sur le web.<span class="tooltiptext">imagine that you are a conspiracy theorist
trying to present a meme on the web.</span></span>
		<span class="tooltip">Qu’écririez-vous sur TED
dans ce cas?<span class="tooltiptext">What would you write
about TED in that case?</span></span>
		<span class="tooltip">Ce genre de choses, non ?<span class="tooltiptext">It&#39;s that kind of thing, right?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: En effet, créer des personnages
fictifs peut engendrer des évasions,<span class="tooltiptext">GM: So there are a lot of jailbreaks
that are around fictional characters,</span></span>
		<span class="tooltip">mais je ne me penche pas dessus<span class="tooltiptext">but I don&#39;t focus on that as much</span></span>
		<span class="tooltip">parce que la réalité est qu’il y existe
de grands modèles de langage<span class="tooltiptext">because the reality is that there are
large language models out there</span></span>
		<span class="tooltip">sur le dark web.<span class="tooltiptext">on the dark web now.</span></span>
		<span class="tooltip">Par exemple, un des modèles de Meta
a récemment été publié,<span class="tooltiptext">For example, one of Meta&#39;s models
was recently released,</span></span>
		<span class="tooltip">donc un mauvais acteur peut utiliser
l’un d’eux sans aucun garde-fou.<span class="tooltiptext">so a bad actor can just use one
of those without the guardrails at all.</span></span>
		<span class="tooltip">Si leur business est
la désinformation à grande échelle,<span class="tooltiptext">If their business is to create
misinformation at scale,</span></span>
		<span class="tooltip">ils n’auront pas besoin d’évasion,
ils utiliseront un modèle différent.<span class="tooltiptext">they don&#39;t have to do the jailbreak,
they&#39;ll just use a different model.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Oui, en effet.<span class="tooltiptext">CA: Right, indeed.</span></span>
	</p>
	<p>
		<span class="tooltip">(Rires)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">GM : Vous comprenez.<span class="tooltiptext">GM: Now you&#39;re getting it.</span></span>
	</p>
	<p>
		<span class="tooltip">CA : Non, non, non, enfin,<span class="tooltiptext">CA: No, no, no, but I mean, look,</span></span>
		<span class="tooltip">Les mauvais acteurs peuvent clairement
utiliser cela pour tout faire.<span class="tooltiptext">I think what&#39;s clear is that bad actors
can use this stuff for anything.</span></span>
		<span class="tooltip">Enfin, le risque pour, vous voyez,<span class="tooltiptext">I mean, the risk for, you know,</span></span>
		<span class="tooltip">les mauvais types d’escroqueries
et tout le reste est absolument évident.<span class="tooltiptext">evil types of scams and all the rest of it
is absolutely evident.</span></span>
		<span class="tooltip">Mais c’est un peu différent,<span class="tooltiptext">It&#39;s slightly different, though,</span></span>
		<span class="tooltip">de dire que le GPT classique
comme celui utilisé à l’école<span class="tooltiptext">from saying that mainstream GPT
as used, say, in school</span></span>
		<span class="tooltip">ou par un simple utilisateur web<span class="tooltiptext">or by an ordinary user on the internet</span></span>
		<span class="tooltip">va leur conférer quelque chose
d’aussi mauvais.<span class="tooltiptext">is going to give them
something that is that bad.</span></span>
		<span class="tooltip">Il faut faire fort
pour que ce soit aussi grave.<span class="tooltiptext">You have to push quite hard
for it to be that bad.</span></span>
	</p>
	<p>
		<span class="tooltip">GM : Je pense que les trolls
travaillent pour ça,<span class="tooltiptext">GM: I think the troll farms
have to work for it,</span></span>
		<span class="tooltip">mais ne pense pas
qu’ils travaillent si dur.<span class="tooltiptext">but I don&#39;t think
they have to work that hard.</span></span>
		<span class="tooltip">Cela n’a pris que cinq minutes à mon ami
même avec le GPT-4 et sa sécurité.<span class="tooltiptext">It did only take my friend five minutes
even with GPT-4 and its guardrails.</span></span>
		<span class="tooltip">Si vous faisiez ça pour vivre,
vous pourriez utiliser GPT-4.<span class="tooltiptext">And if you had to do that for a living,
you could use GPT-4.</span></span>
		<span class="tooltip">Il serait plus efficace de le faire
avec un modèle sur le dark web.<span class="tooltiptext">Just there would be a more efficient way
to do it with a model on the dark web.</span></span>
	</p>
	<p>
		<span class="tooltip">CA : Donc l’idée
que vous avez de combiner<span class="tooltiptext">CA: So this idea you&#39;ve got of combining</span></span>
		<span class="tooltip">la tradition symbolique de l’IA
avec ces modèles de langage,<span class="tooltiptext">the symbolic tradition of AI
with these language models,</span></span>
		<span class="tooltip">est-ce que cette idée
de réintégrer un retour humain<span class="tooltiptext">do you see any aspect of that
in the kind of human feedback</span></span>
		<span class="tooltip">est réalisée
dans les systèmes actuels?<span class="tooltiptext">that is being built into the systems now?</span></span>
		<span class="tooltip">Enfin, on entend
Greg Brockman dire<span class="tooltiptext">I mean, you hear Greg Brockman
saying that, you know,</span></span>
		<span class="tooltip">qu’ils ne font pas que des prédictions,
qu’ils donnent aussi des retours.<span class="tooltiptext">that we don&#39;t just look at predictions,
but constantly giving it feedback.</span></span>
		<span class="tooltip">N’est-ce pas là... lui donner une forme
de sagesse symbolique ?<span class="tooltiptext">Isn’t that ... giving it a form
of, sort of, symbolic wisdom?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Vous pouvez le voir comme ça.<span class="tooltiptext">GM: You could think about it that way.</span></span>
		<span class="tooltip">C’est intéressant qu’aucun détail<span class="tooltiptext">It&#39;s interesting that none of the details</span></span>
		<span class="tooltip">sur son fonctionnement ne soit publié,<span class="tooltiptext">about how it actually works are published,</span></span>
		<span class="tooltip">nous ne savons donc pas
ce qu’il y a dans GPT-4.<span class="tooltiptext">so we don&#39;t actually know
exactly what&#39;s in GPT-4.</span></span>
		<span class="tooltip">Sa taille nous est inconnue.<span class="tooltiptext">We don&#39;t know how big it is.</span></span>
		<span class="tooltip">Nous ne savons pas comment marche
le renforcement RLHF,<span class="tooltiptext">We don&#39;t know how the RLHF
reinforcement learning works,</span></span>
		<span class="tooltip">nous ne savons pas quels
gadgets sont dedans.<span class="tooltiptext">we don&#39;t know what other
gadgets are in there.</span></span>
		<span class="tooltip">Mais peut y avoir un élément
de symboles<span class="tooltiptext">But there is probably
an element of symbols</span></span>
		<span class="tooltip">qui commence déjà à être un peu incorporé,<span class="tooltiptext">already starting
to be incorporated a little bit,</span></span>
		<span class="tooltip">mais Greg devra y répondre.<span class="tooltiptext">but Greg would have to answer that.</span></span>
	</p>
	<p>
		<span class="tooltip">Je pense que le problème de base
est que le plus gros du savoir<span class="tooltiptext">I think the fundamental problem
is that most of the knowledge</span></span>
		<span class="tooltip">sur les réseaux de neurones que nous avons<span class="tooltiptext">in the neural network systems
that we have right now</span></span>
		<span class="tooltip">est représenté en statistiques
entre des mots particuliers.<span class="tooltiptext">is represented as statistics
between particular words.</span></span>
		<span class="tooltip">Les connaissances que nous désirons
sont les statistiques,<span class="tooltiptext">And the real knowledge
that we want is about statistics,</span></span>
		<span class="tooltip">sur les relations entre les entités
du monde.<span class="tooltiptext">about relationships
between entities in the world.</span></span>
		<span class="tooltip">Donc des données
à la mauvaise granularité.<span class="tooltiptext">So it&#39;s represented right now
at the wrong grain level.</span></span>
		<span class="tooltip">Il y a donc un grand pont à franchir.<span class="tooltiptext">And so there&#39;s a big bridge to cross.</span></span>
		<span class="tooltip">Maintenant, il existe des garde-fous,<span class="tooltiptext">So what you get now
is you have these guardrails,</span></span>
		<span class="tooltip">mais qui ne sont pas fiables.<span class="tooltiptext">but they&#39;re not very reliable.</span></span>
	</p>
	<p>
		<span class="tooltip">J’ai vu un exemple
à la télévision de fin de soirée,<span class="tooltiptext">So I had an example that made
late night television,</span></span>
		<span class="tooltip">qui était: “Quelle serait la religion
du premier président juif?”<span class="tooltiptext">which was, &quot;What would be the religion
of the first Jewish president?&quot;</span></span>
		<span class="tooltip">Et ça a été corrigé,<span class="tooltiptext">And it&#39;s been fixed now,</span></span>
		<span class="tooltip">mais le système a donné
cette explication :<span class="tooltiptext">but the system gave this
long song and dance</span></span>
		<span class="tooltip">« Nous n’avons aucune idée
de la religion<span class="tooltiptext">about &quot;We have no idea what the religion</span></span>
		<span class="tooltip">du premier président juif.<span class="tooltiptext">of the first Jewish president would be.</span></span>
		<span class="tooltip">Il est mal de parler
de la religion d’autrui. »<span class="tooltiptext">It&#39;s not good to talk
about people&#39;s religions&quot;</span></span>
		<span class="tooltip">et « les religions
des peuples ont varié », etc,<span class="tooltiptext">and &quot;people&#39;s religions
have varied&quot; and so forth</span></span>
		<span class="tooltip">et de même avec un président
de 7 pieds de haut.<span class="tooltiptext">and did the same thing
with a seven-foot-tall president.</span></span>
		<span class="tooltip">Il a conclu qu’il y a eu des présidents
de toutes tailles.<span class="tooltiptext">And it said that people of all
heights have been president,</span></span>
		<span class="tooltip">mais il n’y a jamais eu de président
mesurant 7 pieds.<span class="tooltiptext">but there haven&#39;t actually been
any seven-foot presidents.</span></span>
		<span class="tooltip">Dans certaines choses qu’il invente,
il ne comprend pas l’idée.<span class="tooltiptext">So some of this stuff that it makes up,
it&#39;s not really getting the idea.</span></span>
		<span class="tooltip">C’est vraiment étroit,
des mots particuliers, pas assez général.<span class="tooltiptext">It&#39;s very narrow, particular words,
not really general enough.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Étant donné que les enjeux
sont importants ici,<span class="tooltiptext">CA: Given that the stakes
are so high in this,</span></span>
		<span class="tooltip">que voyez-vous actuellement ?<span class="tooltiptext">what do you see actually happening
out there right now?</span></span>
		<span class="tooltip">Que sentez-vous arriver ?<span class="tooltiptext">What do you sense is happening?</span></span>
		<span class="tooltip">Parce que certains peuvent se sentir
attaqués par vos propos,<span class="tooltiptext">Because there&#39;s a risk that people feel
attacked by you, for example,</span></span>
		<span class="tooltip">et que ça réduise presque
les opportunités de cette synthèse<span class="tooltiptext">and that it actually almost decreases
the chances of this synthesis</span></span>
		<span class="tooltip">que vous évoquez.<span class="tooltiptext">that you&#39;re talking about happening.</span></span>
		<span class="tooltip">Voyez-vous des signes prometteurs?<span class="tooltiptext">Do you see any hopeful signs of this?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Vous me rappelez une chose
que j’ai oublié de mentionner.<span class="tooltiptext">GM: You just reminded me
of the one line I forgot from my talk.</span></span>
		<span class="tooltip">Il est intéressant que Sundar,
le PDG de Google,<span class="tooltiptext">It&#39;s so interesting that Sundar,
the CEO of Google,</span></span>
		<span class="tooltip">se soit prononcé
pour la gouvernance mondiale<span class="tooltiptext">just actually also came out
for global governance</span></span>
		<span class="tooltip">dans l’interview “60 minutes”
d’il y a quelques jours.<span class="tooltiptext">in the CBS &quot;60 Minutes&quot; interview
that he did a couple of days ago.</span></span>
		<span class="tooltip">Je pense que les entreprises veulent voir
une sorte de régulation.<span class="tooltiptext">I think that the companies themselves
want to see some kind of regulation.</span></span>
		<span class="tooltip">Je pense que c’est difficile
pour mettre tout le monde d’accord,<span class="tooltiptext">I think it’s a very complicated dance
to get everybody on the same page,</span></span>
		<span class="tooltip">mais je pense qu’il y a en fait un
besoin grandissant de faire quelque chose<span class="tooltiptext">but I think there’s actually growing
sentiment we need to do something here</span></span>
		<span class="tooltip">et que ça peut conduire au type
d’affiliation mondiale que je défends.<span class="tooltiptext">and that that can drive the kind of
global affiliation I&#39;m arguing for.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Enfin, pensez-vous que les nations
peuvent s’unir et réaliser ça,<span class="tooltiptext">CA: I mean, do you think the UN or nations
can somehow come together and do that</span></span>
		<span class="tooltip">ou est-ce qu’il y aurait besoin
d’acte philantropique spectaculaire<span class="tooltiptext">or is this potentially a need for some
spectacular act of philanthropy</span></span>
		<span class="tooltip">pour financer une structure
de gouvernance mondiale ?<span class="tooltiptext">to try and fund a global
governance structure?</span></span>
		<span class="tooltip">Comment ça va se passer?<span class="tooltiptext">How is it going to happen?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: J’approuve tout modèle
si nous y arrivons.<span class="tooltiptext">GM: I&#39;m open to all models
if we can get this done.</span></span>
		<span class="tooltip">Je pense qu’il faudra des deux.<span class="tooltiptext">I think it might take some of both.</span></span>
		<span class="tooltip">Que des philanthropes
sponsorisent des ateliers,<span class="tooltiptext">It might take some philanthropists
sponsoring workshops,</span></span>
		<span class="tooltip">ce que nous prévoyons de faire,
pour essayer de réunir les parties.<span class="tooltiptext">which we&#39;re thinking of running,
to try to bring the parties together.</span></span>
		<span class="tooltip">Peut-être que les Nations Unies
s’impliqueront, je leur ai parlé.<span class="tooltiptext">Maybe UN will want to be involved,
I&#39;ve had some conversations with them.</span></span>
		<span class="tooltip">Je pense qu’il y a beaucoup de modèles<span class="tooltiptext">I think there are
a lot of different models</span></span>
		<span class="tooltip">et il faudra beaucoup de discussions.<span class="tooltiptext">and it&#39;ll take a lot of conversations.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Gary, merci de votre intervention.<span class="tooltiptext">CA: Gary, thank you so much for your talk.</span></span>
	</p>
	<p>
		<span class="tooltip">GA: Merci beaucoup.<span class="tooltiptext">GA: Thank you so much.</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	