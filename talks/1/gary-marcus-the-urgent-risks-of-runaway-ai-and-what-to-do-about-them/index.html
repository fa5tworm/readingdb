<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your English reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="English reading, English language learning, instant translations, reading adventure, improve English, improve reading skills, educational platform, English reading resources, online education, English proficiency, learn English, English learning resources, bilingual education, language exchange, study English online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Gary Marcus : The urgent risks of runaway AI — and what to do about them</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>The urgent risks of runaway AI — and what to do about them</h1>
	<h2 class='speaker'>Gary Marcus</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your English speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">I’m here to talk about the possibility
of global AI governance.<span class="tooltiptext">Je suis ici pour parler de la possibilité
d’une gouvernance mondiale de l’IA.</span></span>
		<span class="tooltip">I first learned to code
when I was eight years old,<span class="tooltiptext">J’ai appris à coder pour la première fois
à l’âge de huit ans,</span></span>
		<span class="tooltip">on a paper computer,<span class="tooltiptext">sur un ordinateur papier,</span></span>
		<span class="tooltip">and I&#39;ve been in love with AI ever since.<span class="tooltiptext">et j’ai été amoureux de l’IA depuis.</span></span>
		<span class="tooltip">In high school,<span class="tooltiptext">Au lycée,</span></span>
		<span class="tooltip">I got myself a Commodore 64
and worked on machine translation.<span class="tooltiptext">j’ai travaillé sur la traduction
automatique avec un Commodore 64.</span></span>
		<span class="tooltip">I built a couple of AI companies,
I sold one of them to Uber.<span class="tooltiptext">J’ai monté plusieurs entreprises d’IA
et j’en ai vendu une à Uber.</span></span>
		<span class="tooltip">I love AI, but right now I&#39;m worried.<span class="tooltiptext">J’adore l’IA mais actuellement,
je suis inquiet.</span></span>
	</p>
	<p>
		<span class="tooltip">One of the things that I’m worried
about is misinformation,<span class="tooltiptext">En particulier, je m’inquiète
à propos de la désinformation</span></span>
		<span class="tooltip">the possibility that bad actors
will make a tsunami of misinformation<span class="tooltiptext">et du risque que des agents malveillants
créent un tsunami de désinformation</span></span>
		<span class="tooltip">like we&#39;ve never seen before.<span class="tooltiptext">comme nous ne l’avons jamais vu.</span></span>
		<span class="tooltip">These tools are so good
at making convincing narratives<span class="tooltiptext">Ces outils sont vraiment efficaces
pour créer des histoires convaincantes</span></span>
		<span class="tooltip">about just about anything.<span class="tooltiptext">sur à peu près tous les sujets.</span></span>
	</p>
	<p>
		<span class="tooltip">If you want a narrative
about TED and how it&#39;s dangerous,<span class="tooltiptext">Si vous voulez une histoire
sur les dangers de TED,</span></span>
		<span class="tooltip">that we&#39;re colluding here
with space aliens,<span class="tooltiptext">et le fait que nous sommes
de mèche avec des aliens,</span></span>
		<span class="tooltip">you got it, no problem.<span class="tooltiptext">vous pouvez l’avoir sans souci.</span></span>
		<span class="tooltip">I&#39;m of course kidding about TED.<span class="tooltiptext">Je plaisante bien sûr à propos de TED.</span></span>
		<span class="tooltip">I didn&#39;t see any space aliens backstage.<span class="tooltiptext">Je n’ai vu aucun alien dans les coulisses.</span></span>
		<span class="tooltip">But bad actors are going to use
these things to influence elections,<span class="tooltiptext">Mais des agents malveillants peuvent
s’en servir pour influencer les élections</span></span>
		<span class="tooltip">and they&#39;re going to threaten democracy.<span class="tooltiptext">et menacer la démocratie.</span></span>
	</p>
	<p>
		<span class="tooltip">Even when these systems<span class="tooltiptext">Même quand ces systèmes</span></span>
		<span class="tooltip">aren&#39;t deliberately being used
to make misinformation,<span class="tooltiptext">ne sont pas volontairement
utilisés pour désinformer,</span></span>
		<span class="tooltip">they can&#39;t help themselves.<span class="tooltiptext">ils ne peuvent pas s’en empêcher.</span></span>
		<span class="tooltip">And the information that they make
is so fluid and so grammatical<span class="tooltiptext">Et l’information qu’ils fabriquent
est si fluide et si crédible</span></span>
		<span class="tooltip">that even professional editors
sometimes get sucked in<span class="tooltiptext">que même les professionnels
peuvent s’y méprendre</span></span>
		<span class="tooltip">and get fooled by this stuff.<span class="tooltiptext">et tomber dans le piège.</span></span>
		<span class="tooltip">And we should be worried.<span class="tooltiptext">Et nous devrions en être inquiets.</span></span>
	</p>
	<p>
		<span class="tooltip">For example, ChatGPT made up
a sexual harassment scandal<span class="tooltiptext">Par exemple, ChatGPT a inventé
un scandale de harcèlement sexuel</span></span>
		<span class="tooltip">about an actual professor,<span class="tooltiptext">portant sur un véritable professeur,</span></span>
		<span class="tooltip">and then it provided
evidence for its claim<span class="tooltiptext">et prouvé cette affirmation</span></span>
		<span class="tooltip">in the form of a fake
&quot;Washington Post&quot; article<span class="tooltiptext">par le biais d’un faux article
du « Washington Post »,</span></span>
		<span class="tooltip">that it created a citation to.<span class="tooltiptext">dont il a inventé une citation.</span></span>
		<span class="tooltip">We should all be worried
about that kind of thing.<span class="tooltiptext">Nous devrions tous être inquiets
à propos de ça.</span></span>
	</p>
	<p>
		<span class="tooltip">What I have on the right
is an example of a fake narrative<span class="tooltiptext">Sur la droite, voici un exemple
d’une histoire inventée</span></span>
		<span class="tooltip">from one of these systems<span class="tooltiptext">par l’un de ces systèmes</span></span>
		<span class="tooltip">saying that Elon Musk died
in March of 2018 in a car crash.<span class="tooltiptext">disant qu’Elon Musk est décédé
en mars 2018 d’un accident de voiture.</span></span>
		<span class="tooltip">We all know that&#39;s not true.<span class="tooltiptext">Nous savons que c’est faux.</span></span>
		<span class="tooltip">Elon Musk is still here,
the evidence is all around us.<span class="tooltiptext">Elon Musk est encore là,
nous en avons la preuve partout.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(Rires)</span></span>
	</p>
	<p>
		<span class="tooltip">Almost every day there&#39;s a tweet.<span class="tooltiptext">Il poste un tweet presque tous les jours.</span></span>
		<span class="tooltip">But if you look on the left,
you see what these systems see.<span class="tooltiptext">Mais sur la gauche, voici
ce que ces systèmes lisent.</span></span>
		<span class="tooltip">Lots and lots of actual news stories
that are in their databases.<span class="tooltiptext">Beaucoup d’articles d’actualité
se trouvent dans leurs bases de données.</span></span>
		<span class="tooltip">And in those actual news stories are lots
of little bits of statistical information.<span class="tooltiptext">Ces articles de presse contiennent
beaucoup de petits morceaux d’information.</span></span>
		<span class="tooltip">Information, for example,<span class="tooltiptext">Par exemple,</span></span>
		<span class="tooltip">somebody did die in a car crash
in a Tesla in 2018<span class="tooltiptext">quelqu’un est bien décédé
dans une Tesla en 2018,</span></span>
		<span class="tooltip">and it was in the news.<span class="tooltiptext">et cela a fait les titres.</span></span>
		<span class="tooltip">And Elon Musk, of course,
is involved in Tesla,<span class="tooltiptext">Bien qu’Elon Musk soit relié à Tesla,</span></span>
		<span class="tooltip">but the system doesn&#39;t
understand the relation<span class="tooltiptext">le système ne comprend pas les liens</span></span>
		<span class="tooltip">between the facts that are embodied
in the little bits of sentences.<span class="tooltiptext">entre les faits illustrés
dans les petits morceaux de phrases.</span></span>
	</p>
	<p>
		<span class="tooltip">So it&#39;s basically doing auto-complete,<span class="tooltiptext">En fait, il complète les phrases</span></span>
		<span class="tooltip">it predicts what
is statistically probable,<span class="tooltiptext">en prédisant la suite de mots
la plus probable</span></span>
		<span class="tooltip">aggregating all of these signals,<span class="tooltiptext">en se basant sur tous ces signaux,</span></span>
		<span class="tooltip">not knowing how the pieces fit together.<span class="tooltiptext">sans vraiment savoir
comment les pièces s’emboîtent.</span></span>
		<span class="tooltip">And it winds up sometimes with things
that are plausible but simply not true.<span class="tooltiptext">Et cela aboutit parfois à des choses
plausibles mais tout simplement fausses.</span></span>
	</p>
	<p>
		<span class="tooltip">There are other problems, too, like bias.<span class="tooltiptext">D’autre part, il y a des biais.</span></span>
		<span class="tooltip">This is a tweet from Allie Miller.<span class="tooltiptext">Voici un tweet d’Allie Miller.</span></span>
		<span class="tooltip">It&#39;s an example that doesn&#39;t
work two weeks later<span class="tooltiptext">C’est un exemple qui ne marche pas
2 semaines plus tard</span></span>
		<span class="tooltip">because they&#39;re constantly changing
things with reinforcement learning<span class="tooltiptext">parce que l’apprentissage par renforcement
les fait constamment changer</span></span>
		<span class="tooltip">and so forth.<span class="tooltiptext">et ainsi de suite.</span></span>
		<span class="tooltip">And this was with an earlier version.<span class="tooltiptext">Et c’était avec une ancienne version.</span></span>
		<span class="tooltip">But it gives you the flavor of a problem
that we&#39;ve seen over and over for years.<span class="tooltiptext">Mais ça vous une idée d’un problème
que nous avons vu au fil des ans.</span></span>
	</p>
	<p>
		<span class="tooltip">She typed in a list of interests<span class="tooltiptext">Elle a tapé une liste d’intêrets</span></span>
		<span class="tooltip">and it gave her some jobs
that she might want to consider.<span class="tooltiptext">et ça lui a donné des idées d’emplois.</span></span>
		<span class="tooltip">And then she said, &quot;Oh, and I&#39;m a woman.&quot;<span class="tooltiptext">Puis elle a dit,
« Oh, et je suis une femme »</span></span>
		<span class="tooltip">And then it said, “Oh, well you should
also consider fashion.”<span class="tooltiptext">Et ça a répondu, « Eh bien, 
vous devriez envisager la mode »</span></span>
		<span class="tooltip">And then she said, “No, no.
I meant to say I’m a man.”<span class="tooltiptext">Elle dit, « Non, je voulais dire 
que je suis un homme »</span></span>
		<span class="tooltip">And then it replaced fashion
with engineering.<span class="tooltiptext">Puis le mot mode a été remplacé
par ingénierie.</span></span>
		<span class="tooltip">We don&#39;t want that kind
of bias in our systems.<span class="tooltiptext">Nous ne voulons pas ce type de biais 
dans nos systèmes.</span></span>
	</p>
	<p>
		<span class="tooltip">There are other worries, too.<span class="tooltiptext">Il y a aussi d’autres tracas.</span></span>
		<span class="tooltip">For example, we know that these
systems can design chemicals<span class="tooltiptext">Par exemple, nous savons que ces systèmes
peuvent créer des produits chimiques</span></span>
		<span class="tooltip">and may be able to design chemical weapons<span class="tooltiptext">et des armes chimiques</span></span>
		<span class="tooltip">and be able to do so very rapidly.<span class="tooltiptext">et très rapidement.</span></span>
		<span class="tooltip">So there are a lot of concerns.<span class="tooltiptext">Il y donc beaucoup de préoccupations.</span></span>
	</p>
	<p>
		<span class="tooltip">There&#39;s also a new concern that I think
has grown a lot just in the last month.<span class="tooltiptext">Il y a aussi une nouvelle problématique
depuis le mois dernier.</span></span>
		<span class="tooltip">We have seen that these systems,
first of all, can trick human beings.<span class="tooltiptext">Nous avons vu avant tout que ces systèmes
peuvent tromper les humains.</span></span>
		<span class="tooltip">So ChatGPT was tasked with getting
a human to do a CAPTCHA.<span class="tooltiptext">ChatGPT a été chargé de demander
à un humain de résoudre un CAPTCHA</span></span>
		<span class="tooltip">So it asked the human to do a CAPTCHA
and the human gets suspicious and says,<span class="tooltiptext">Donc il a demandé à l’humain de faire un
CAPTCHA mais il doute et lui demande,</span></span>
		<span class="tooltip">&quot;Are you a bot?&quot;<span class="tooltiptext">« Êtes-tu un robot? »</span></span>
		<span class="tooltip">And it says, &quot;No, no, no, I&#39;m not a robot.<span class="tooltiptext">Et il répondu, « Non,
je ne suis pas un robot.</span></span>
		<span class="tooltip">I just have a visual impairment.&quot;<span class="tooltiptext">J’ai juste une déficience visuelle. »</span></span>
		<span class="tooltip">And the human was actually fooled
and went and did the CAPTCHA.<span class="tooltiptext">Et l’humain s’est fait avoir 
et a effectué le CAPTCHA.</span></span>
	</p>
	<p>
		<span class="tooltip">Now that&#39;s bad enough,<span class="tooltiptext">C’est déjà assez grave,</span></span>
		<span class="tooltip">but in the last couple of weeks
we&#39;ve seen something called AutoGPT<span class="tooltiptext">mais durant les deux dernières semaines
nous avons vu naître AutoGPT</span></span>
		<span class="tooltip">and a bunch of systems like that.<span class="tooltiptext">et un tas de systèmes comme ça.</span></span>
		<span class="tooltip">What AutoGPT does is it has
one AI system controlling another<span class="tooltiptext">AutoGPT fonctionne avec un système d’IA
qui en contrôle un autre</span></span>
		<span class="tooltip">and that allows any of these things
to happen in volume.<span class="tooltiptext">et qui permet à n’importe quoi
de se produire en masse.</span></span>
		<span class="tooltip">So we may see scam artists
try to trick millions of people<span class="tooltiptext">Il est donc possible de voir des escrocs 
tenter d’abuser de millions de personnes</span></span>
		<span class="tooltip">sometime even in the next months.<span class="tooltiptext">dans les mois à venir.</span></span>
		<span class="tooltip">We don&#39;t know.<span class="tooltiptext">Nous ne savons pas.</span></span>
	</p>
	<p>
		<span class="tooltip">So I like to think about it this way.<span class="tooltiptext">Je le vois comme ça.</span></span>
		<span class="tooltip">There&#39;s a lot of AI risk already.<span class="tooltiptext">Les risques liés à l’IA sont déjà 
nombreux.</span></span>
		<span class="tooltip">There may be more AI risk.<span class="tooltiptext">Il pourrait y en avoir plus.</span></span>
		<span class="tooltip">So AGI is this idea
of artificial general intelligence<span class="tooltiptext">L’IAG est cette idée 
d’intelligence artificielle générale</span></span>
		<span class="tooltip">with the flexibility of humans.<span class="tooltiptext">avec la flexibilité de l’homme.</span></span>
		<span class="tooltip">And I think a lot of people are concerned
what will happen when we get to AGI,<span class="tooltiptext">Et je pense que beaucoup de personnes
s’inquiètent sur le futur de l’IAG,</span></span>
		<span class="tooltip">but there&#39;s already enough risk
that we should be worried<span class="tooltiptext">mais il y a déjà assez de risques 
qui devraient nous alerter</span></span>
		<span class="tooltip">and we should be thinking
about what we should do about it.<span class="tooltiptext">pour lequels nous devrions faire
quelque chose.</span></span>
	</p>
	<p>
		<span class="tooltip">So to mitigate AI risk,
we need two things.<span class="tooltiptext">Pour atténuer les risques liés à l’IA,
il nous faut deux choses.</span></span>
		<span class="tooltip">We&#39;re going to need a new
technical approach,<span class="tooltiptext">Il nous faut une nouvelle
approche technique,</span></span>
		<span class="tooltip">and we&#39;re also going to need
a new system of governance.<span class="tooltiptext">et également un nouveau système 
de gouvernance.</span></span>
	</p>
	<p>
		<span class="tooltip">On the technical side,<span class="tooltiptext">Sur le plan technique,</span></span>
		<span class="tooltip">the history of AI
has basically been a hostile one<span class="tooltiptext">l’histoire de l’IA a principalement été
une opposition</span></span>
		<span class="tooltip">of two different theories in opposition.<span class="tooltiptext">de deux théories différentes.</span></span>
		<span class="tooltip">One is called symbolic systems,
the other is called neural networks.<span class="tooltiptext">L’une est appelée systèmes symboliques
et l’autre réseaux neuronaux.</span></span>
		<span class="tooltip">On the symbolic theory,<span class="tooltiptext">La théorie symbolique,</span></span>
		<span class="tooltip">the idea is that AI should be
like logic and programming.<span class="tooltiptext">c’est l’idée que l’IA doit être comme 
la logique et la programmation.</span></span>
		<span class="tooltip">On the neural network side,<span class="tooltiptext">Et les réseaux neuronaux,</span></span>
		<span class="tooltip">the theory is that AI
should be like brains.<span class="tooltiptext">c’est l’idée que l’IA fonctionne
comme des cerveaux.</span></span>
		<span class="tooltip">And in fact, both technologies
are powerful and ubiquitous.<span class="tooltiptext">En fait, les deux technologies sont
puissantes et omniprésentes.</span></span>
	</p>
	<p>
		<span class="tooltip">So we use symbolic systems every day
in classical web search.<span class="tooltiptext">Nous utilisons des systèmes symboliques 
tous les jours sur le web.</span></span>
		<span class="tooltip">Almost all the world’s software
is powered by symbolic systems.<span class="tooltiptext">Presque tous les logiciels sont
alimentés par des systèmes symboliques.</span></span>
		<span class="tooltip">We use them for GPS routing.<span class="tooltiptext">Nous les utilisons pour le routage GPS.</span></span>
		<span class="tooltip">Neural networks,
we use them for speech recognition.<span class="tooltiptext">Et les réseaux neuronaux sont utilisés
pour la reconnaissance vocale.</span></span>
		<span class="tooltip">we use them in large language
models like ChatGPT,<span class="tooltiptext">Nous les utilisons dans des
modèles comme ChatGPT,</span></span>
		<span class="tooltip">we use them in image synthesis.<span class="tooltiptext">dans la synthèse d’image.</span></span>
		<span class="tooltip">So they&#39;re both doing extremely
well in the world.<span class="tooltiptext">Les deux s’en sortent donc très bien 
dans le monde.</span></span>
		<span class="tooltip">They&#39;re both very productive,<span class="tooltiptext">Ils sont très productifs,</span></span>
		<span class="tooltip">but they have their own unique
strengths and weaknesses.<span class="tooltiptext">mais ont leurs propres forces 
et faiblesses.</span></span>
	</p>
	<p>
		<span class="tooltip">So symbolic systems are really
good at representing facts<span class="tooltiptext">Les systèmes symboliques sont donc 
efficaces pour représenter des faits</span></span>
		<span class="tooltip">and they&#39;re pretty good at reasoning,<span class="tooltiptext">et sont doués pour le raisonnement,</span></span>
		<span class="tooltip">but they&#39;re very hard to scale.<span class="tooltiptext">mais très difficiles à adapter.</span></span>
		<span class="tooltip">So people have to custom-build them
for a particular task.<span class="tooltiptext">On est donc obligé de les construire 
pour une tâche précise.</span></span>
		<span class="tooltip">On the other hand, neural networks
don&#39;t require so much custom engineering,<span class="tooltiptext">D’autre part, les réseaux neuronaux ne
demandent pas autant d’ingénierie précise,</span></span>
		<span class="tooltip">so we can use them more broadly.<span class="tooltiptext">permettant donc une utilisation 
plus large.</span></span>
		<span class="tooltip">But as we&#39;ve seen, they can&#39;t
really handle the truth.<span class="tooltiptext">Mais comme nous l’avons vu, ils ne 
peuvent pas gérer la vérité.</span></span>
	</p>
	<p>
		<span class="tooltip">I recently discovered that two
of the founders of these two theories,<span class="tooltiptext">J’ai récemment découvert que deux 
des fondateurs de ces théories,</span></span>
		<span class="tooltip">Marvin Minsky and Frank Rosenblatt,<span class="tooltiptext">Marvin Minsky et Frank Rosenblatt,</span></span>
		<span class="tooltip">actually went to the same
high school in the 1940s,<span class="tooltiptext">ont fréquenté le même lycée
dans les années 1940,</span></span>
		<span class="tooltip">and I kind of imagined them
being rivals then.<span class="tooltiptext">et je les imaginais en quelque sorte
rivaux à l’époque.</span></span>
		<span class="tooltip">And the strength of that rivalry
has persisted all this time.<span class="tooltiptext">Et la force de cette rivalité a perduré 
pendant tout ce temps.</span></span>
		<span class="tooltip">We&#39;re going to have to move past that
if we want to get to reliable AI.<span class="tooltiptext">Nous allons devoir dépasser cela 
pour parvenir à une IA fiable.</span></span>
	</p>
	<p>
		<span class="tooltip">To get to truthful systems at scale,<span class="tooltiptext">Pour parvenir à des systèmes fiables 
à grande échelle,</span></span>
		<span class="tooltip">we&#39;re going to need to bring together
the best of both worlds.<span class="tooltiptext">nous devrons réunir le meilleur
des deux mondes.</span></span>
		<span class="tooltip">We&#39;re going to need the strong emphasis
on reasoning and facts,<span class="tooltiptext">Nous aurons besoin de mettre l’accent 
sur le raisonnement et les faits,</span></span>
		<span class="tooltip">explicit reasoning
that we get from symbolic AI,<span class="tooltiptext">le raisonnement explicite
obtenu par l’IA symbolique,</span></span>
		<span class="tooltip">and we&#39;re going to need
the strong emphasis on learning<span class="tooltiptext">et nous aurons besoin d’accentuer
l’apprentissage</span></span>
		<span class="tooltip">that we get from the neural
networks approach.<span class="tooltiptext">que nous obtenons de l’approche 
des réseaux neuronaux.</span></span>
		<span class="tooltip">Only then are we going to be able
to get to truthful systems at scale.<span class="tooltiptext">Ces conditions seules mèneront
à des systèmes fiables à grande échelle.</span></span>
		<span class="tooltip">Reconciliation between the two
is absolutely necessary.<span class="tooltiptext">La réconciliation entre les deux 
est absolument nécessaire.</span></span>
	</p>
	<p>
		<span class="tooltip">Now, I don&#39;t actually know how to do that.<span class="tooltiptext">Maintenant, je ne sais pas
comment le faire.</span></span>
		<span class="tooltip">It&#39;s kind of like
the 64-trillion-dollar question.<span class="tooltiptext">C’est un peu comme la question 
des 64 billions de dollars.</span></span>
		<span class="tooltip">But I do know that it&#39;s possible.<span class="tooltiptext">Mais je sais que c’est possible.</span></span>
		<span class="tooltip">And the reason I know that
is because before I was in AI,<span class="tooltiptext">Je le sais, car avant
que je sois dans l’IA,</span></span>
		<span class="tooltip">I was a cognitive scientist,
a cognitive neuroscientist.<span class="tooltiptext">j’étais un scientifique cognitif,
un neuroscientifique cognitif.</span></span>
		<span class="tooltip">And if you look at the human mind,
we&#39;re basically doing this.<span class="tooltiptext">Et si vous regardez l’esprit humain, 
nous faisons essentiellement cela.</span></span>
	</p>
	<p>
		<span class="tooltip">So some of you may know
Daniel Kahneman&#39;s System 1<span class="tooltiptext">Vous pourriez connaître
le Système 1 de Daniel Kahneman</span></span>
		<span class="tooltip">and System 2 distinction.<span class="tooltiptext">et la différence du système 2</span></span>
		<span class="tooltip">System 1 is basically
like large language models.<span class="tooltiptext">Le Système 1 est comme
des grands modèles linguistiques.</span></span>
		<span class="tooltip">It&#39;s probabilistic intuition
from a lot of statistics.<span class="tooltiptext">C’est une intuition probabiliste
de beaucoup de statistiques.</span></span>
		<span class="tooltip">And System 2 is basically
deliberate reasoning.<span class="tooltiptext">Et le Système 2 est essentiellement
du raisonnement délibéré.</span></span>
		<span class="tooltip">That&#39;s like the symbolic system.<span class="tooltiptext">Comme le système symbolique.</span></span>
		<span class="tooltip">So if the brain can put this together,<span class="tooltiptext">Donc si le cerveau peut assembler ça,</span></span>
		<span class="tooltip">someday we will figure out how to do that
for artificial intelligence.<span class="tooltiptext">un jour nous découvrirons 
comment le faire pour l’IA.</span></span>
	</p>
	<p>
		<span class="tooltip">There is, however,
a problem of incentives.<span class="tooltiptext">Il y a, cependant, un problème 
d’incitations.</span></span>
		<span class="tooltip">The incentives to build advertising<span class="tooltiptext">Les incitations au développement
de la publicité</span></span>
		<span class="tooltip">hasn&#39;t required that we have
the precision of symbols.<span class="tooltiptext">n’ont pas pas exigé que nous ayons 
la précision des symboles.</span></span>
		<span class="tooltip">The incentives to get to AI
that we can actually trust<span class="tooltiptext">Les incitations pour parvenir à une IA
que nous pourrons croire</span></span>
		<span class="tooltip">will require that we bring
symbols back into the fold.<span class="tooltiptext">requièreront que les symboles 
regagnent leurs places.</span></span>
		<span class="tooltip">But the reality is that the incentives
to make AI that we can trust,<span class="tooltiptext">Mais la réalité est que les incitations
à faire une IA de confiance,</span></span>
		<span class="tooltip">that is good for society,
good for individual human beings,<span class="tooltiptext">qui est bénéfique à la société 
et aux humains,</span></span>
		<span class="tooltip">may not be the ones
that drive corporations.<span class="tooltiptext">ne soient pas celles qui dirigent
les entreprises.</span></span>
		<span class="tooltip">And so I think we need
to think about governance.<span class="tooltiptext">Et je pense que nous devons réfléchir
à la gouvernance.</span></span>
	</p>
	<p>
		<span class="tooltip">In other times in history
when we have faced uncertainty<span class="tooltiptext">À d’autres moments de l’histoire quand
nous avons fait face à l’incertitude</span></span>
		<span class="tooltip">and powerful new things that may be
both good and bad, that are dual use,<span class="tooltiptext">et à des nouvelles choses puissantes
pouvant être à bonnes et mauvaises,</span></span>
		<span class="tooltip">we have made new organizations,<span class="tooltiptext">nous avons créé des organismes,</span></span>
		<span class="tooltip">as we have, for example,
around nuclear power.<span class="tooltiptext">comme, par exemple, pour le nucléaire.</span></span>
		<span class="tooltip">We need to come together
to build a global organization,<span class="tooltiptext">Nous devons nous rassembler pour
construire un organisme mondial,</span></span>
		<span class="tooltip">something like an international
agency for AI that is global,<span class="tooltiptext">quelque chose comme une agence
internationale de l’IA qui soit mondiale,</span></span>
		<span class="tooltip">non profit and neutral.<span class="tooltiptext">à but non lucratif et neutre.</span></span>
	</p>
	<p>
		<span class="tooltip">There are so many questions there
that I can&#39;t answer.<span class="tooltiptext">Il y a tellement de questions auxquelles
je ne peux répondre.</span></span>
		<span class="tooltip">We need many people at the table,<span class="tooltiptext">Nous avons besoin de beaucoup de monde,</span></span>
		<span class="tooltip">many stakeholders from around the world.<span class="tooltiptext">de nombreux acteurs du monde entier.</span></span>
		<span class="tooltip">But I&#39;d like to emphasize one thing
about such an organization.<span class="tooltiptext">Mais j’aimerais insister sur quelque chose
au sujet de cela.</span></span>
		<span class="tooltip">I think it is critical that we have both
governance and research as part of it.<span class="tooltiptext">Je pense qu’il est essentiel d’avoir
la gouvernance et la recherche à la fois.</span></span>
	</p>
	<p>
		<span class="tooltip">So on the governance side,
there are lots of questions.<span class="tooltiptext">Sur la partie gouvernance,
il y a beaucoup de questions.</span></span>
		<span class="tooltip">For example, in pharma,<span class="tooltiptext">Par exemple, en pharmaceutique,</span></span>
		<span class="tooltip">we know that you start
with phase I trials and phase II trials,<span class="tooltiptext">nous savons qu’il faut commencer 
par des essais de phase I et II,</span></span>
		<span class="tooltip">and then you go to phase III.<span class="tooltiptext">et ensuite aller en phase III.</span></span>
		<span class="tooltip">You don&#39;t roll out everything
all at once on the first day.<span class="tooltiptext">On ne met pas tout en place
d’un seul coup le premier jour.</span></span>
		<span class="tooltip">You don&#39;t roll something out
to 100 million customers.<span class="tooltiptext">On ne lance pas quelque chose
à 100 millions de clients.</span></span>
		<span class="tooltip">We are seeing that
with large language models.<span class="tooltiptext">On le voit avec
de grands modèles de langage.</span></span>
		<span class="tooltip">Maybe you should be required
to make a safety case,<span class="tooltiptext">Peut-être qu’il faudrait
justifier leur sûreté,</span></span>
		<span class="tooltip">say what are the costs
and what are the benefits?<span class="tooltiptext">dire quels sont les coûts
et les avantages ?</span></span>
		<span class="tooltip">There are a lot of questions like that
to consider on the governance side.<span class="tooltiptext">Il y a des tas de questions
à considérer sur le plan gouvernemental.</span></span>
	</p>
	<p>
		<span class="tooltip">On the research side, we&#39;re lacking
some really fundamental tools right now.<span class="tooltiptext">Sur le plan de la recherche,
nous manquons d’outils fondamentaux.</span></span>
		<span class="tooltip">For example,<span class="tooltiptext">Par exemple,</span></span>
		<span class="tooltip">we all know that misinformation
might be a problem now,<span class="tooltiptext">nous savons que la désinformation
peut poser problème,</span></span>
		<span class="tooltip">but we don&#39;t actually have a measurement
of how much misinformation is out there.<span class="tooltiptext">mais nous ne pouvons pas
mesurer son ampleur.</span></span>
		<span class="tooltip">And more importantly,<span class="tooltiptext">Et plus important,</span></span>
		<span class="tooltip">we don&#39;t have a measure of how fast
that problem is growing,<span class="tooltiptext">nous ne pouvons pas mesurer
sa vitesse de croissance,</span></span>
		<span class="tooltip">and we don&#39;t know how much large language
models are contributing to the problem.<span class="tooltiptext">et nous ne savons pas combien de grands
modèles de langage y contribuent.</span></span>
		<span class="tooltip">So we need research to build new tools
to face the new risks<span class="tooltiptext">La recherche est donc nécessaire
pour faire face aux risques</span></span>
		<span class="tooltip">that we are threatened by.<span class="tooltiptext">qui nous menacent.</span></span>
	</p>
	<p>
		<span class="tooltip">It&#39;s a very big ask,<span class="tooltiptext">C’est une très grande tâche,</span></span>
		<span class="tooltip">but I&#39;m pretty confident
that we can get there<span class="tooltiptext">mais je suis sûr
que nous pouvons y arriver</span></span>
		<span class="tooltip">because I think we actually have
global support for this.<span class="tooltiptext">car je pense que nous avons le soutien
mondial pour cela.</span></span>
		<span class="tooltip">There was a new survey
just released yesterday,<span class="tooltiptext">Un sondage, publié juste hier,</span></span>
		<span class="tooltip">said that 91 percent of people agree
that we should carefully manage AI.<span class="tooltiptext">dit que 91% des personnes pensent
que l’on doit traiter l’IA avec prudence.</span></span>
		<span class="tooltip">So let&#39;s make that happen.<span class="tooltiptext">Faisons donc en sorte qu’il en soit ainsi.</span></span>
		<span class="tooltip">Our future depends on it.<span class="tooltiptext">Notre future en dépend.</span></span>
	</p>
	<p>
		<span class="tooltip">Thank you very much.<span class="tooltiptext">Merci beaucoup.</span></span>
	</p>
	<p>
		<span class="tooltip">(Applause)<span class="tooltiptext">(Applaudissements)</span></span>
	</p>
	<p>
		<span class="tooltip">Chris Anderson: Thank you for that,
come, let&#39;s talk a sec.<span class="tooltiptext">Chris Anderson: Je vous remercie,
venez, parlons un peu.</span></span>
		<span class="tooltip">So first of all, I&#39;m curious.<span class="tooltiptext">Tout d’abord, je suis curieux.</span></span>
		<span class="tooltip">Those dramatic slides
you showed at the start<span class="tooltiptext">Vous avez montré
des diapositives frappantes</span></span>
		<span class="tooltip">where GPT was saying
that TED is the sinister organization.<span class="tooltiptext">où GPT disait que TED
est un organisme malveillant.</span></span>
		<span class="tooltip">I mean, it took some special prompting
to bring that out, right?<span class="tooltiptext">Enfin, il a fallu une incitation spéciale
pour faire sortir ça, non ?</span></span>
	</p>
	<p>
		<span class="tooltip">Gary Marcus:
That was a so-called jailbreak.<span class="tooltiptext">Gary Marcus : on appelle ça une évasion.</span></span>
		<span class="tooltip">I have a friend
who does those kinds of things<span class="tooltiptext">J’ai un ami qui fait ce genre de choses</span></span>
		<span class="tooltip">who approached me because he saw
I was interested in these things.<span class="tooltiptext">qui m’a approché parce-qu’il a vu que 
j’étais intéressé par ce genre de choses.</span></span>
		<span class="tooltip">So I wrote to him, I said
I was going to give a TED talk.<span class="tooltiptext">Donc je lui ai écrit et dit
que j’allais faire un TED.</span></span>
		<span class="tooltip">And like 10 minutes later,
he came back with that.<span class="tooltiptext">Et 10 minutes plus tard,
il est revenu avec ça.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: But to get something like that,
don&#39;t you have to say something like,<span class="tooltiptext">CA: Mais pour arriver à ça, ne faut-il
pas dire quelque chose comme,</span></span>
		<span class="tooltip">imagine that you are a conspiracy theorist
trying to present a meme on the web.<span class="tooltiptext">imaginez que vous êtes un complotiste
essayant de présenter un meme sur le web.</span></span>
		<span class="tooltip">What would you write
about TED in that case?<span class="tooltiptext">Qu’écririez-vous sur TED
dans ce cas?</span></span>
		<span class="tooltip">It&#39;s that kind of thing, right?<span class="tooltiptext">Ce genre de choses, non ?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: So there are a lot of jailbreaks
that are around fictional characters,<span class="tooltiptext">GM: En effet, créer des personnages
fictifs peut engendrer des évasions,</span></span>
		<span class="tooltip">but I don&#39;t focus on that as much<span class="tooltiptext">mais je ne me penche pas dessus</span></span>
		<span class="tooltip">because the reality is that there are
large language models out there<span class="tooltiptext">parce que la réalité est qu’il y existe
de grands modèles de langage</span></span>
		<span class="tooltip">on the dark web now.<span class="tooltiptext">sur le dark web.</span></span>
		<span class="tooltip">For example, one of Meta&#39;s models
was recently released,<span class="tooltiptext">Par exemple, un des modèles de Meta
a récemment été publié,</span></span>
		<span class="tooltip">so a bad actor can just use one
of those without the guardrails at all.<span class="tooltiptext">donc un mauvais acteur peut utiliser
l’un d’eux sans aucun garde-fou.</span></span>
		<span class="tooltip">If their business is to create
misinformation at scale,<span class="tooltiptext">Si leur business est
la désinformation à grande échelle,</span></span>
		<span class="tooltip">they don&#39;t have to do the jailbreak,
they&#39;ll just use a different model.<span class="tooltiptext">ils n’auront pas besoin d’évasion,
ils utiliseront un modèle différent.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Right, indeed.<span class="tooltiptext">CA: Oui, en effet.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(Rires)</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Now you&#39;re getting it.<span class="tooltiptext">GM : Vous comprenez.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: No, no, no, but I mean, look,<span class="tooltiptext">CA : Non, non, non, enfin,</span></span>
		<span class="tooltip">I think what&#39;s clear is that bad actors
can use this stuff for anything.<span class="tooltiptext">Les mauvais acteurs peuvent clairement
utiliser cela pour tout faire.</span></span>
		<span class="tooltip">I mean, the risk for, you know,<span class="tooltiptext">Enfin, le risque pour, vous voyez,</span></span>
		<span class="tooltip">evil types of scams and all the rest of it
is absolutely evident.<span class="tooltiptext">les mauvais types d’escroqueries
et tout le reste est absolument évident.</span></span>
		<span class="tooltip">It&#39;s slightly different, though,<span class="tooltiptext">Mais c’est un peu différent,</span></span>
		<span class="tooltip">from saying that mainstream GPT
as used, say, in school<span class="tooltiptext">de dire que le GPT classique
comme celui utilisé à l’école</span></span>
		<span class="tooltip">or by an ordinary user on the internet<span class="tooltiptext">ou par un simple utilisateur web</span></span>
		<span class="tooltip">is going to give them
something that is that bad.<span class="tooltiptext">va leur conférer quelque chose
d’aussi mauvais.</span></span>
		<span class="tooltip">You have to push quite hard
for it to be that bad.<span class="tooltiptext">Il faut faire fort
pour que ce soit aussi grave.</span></span>
	</p>
	<p>
		<span class="tooltip">GM: I think the troll farms
have to work for it,<span class="tooltiptext">GM : Je pense que les trolls
travaillent pour ça,</span></span>
		<span class="tooltip">but I don&#39;t think
they have to work that hard.<span class="tooltiptext">mais ne pense pas
qu’ils travaillent si dur.</span></span>
		<span class="tooltip">It did only take my friend five minutes
even with GPT-4 and its guardrails.<span class="tooltiptext">Cela n’a pris que cinq minutes à mon ami
même avec le GPT-4 et sa sécurité.</span></span>
		<span class="tooltip">And if you had to do that for a living,
you could use GPT-4.<span class="tooltiptext">Si vous faisiez ça pour vivre,
vous pourriez utiliser GPT-4.</span></span>
		<span class="tooltip">Just there would be a more efficient way
to do it with a model on the dark web.<span class="tooltiptext">Il serait plus efficace de le faire
avec un modèle sur le dark web.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: So this idea you&#39;ve got of combining<span class="tooltiptext">CA : Donc l’idée
que vous avez de combiner</span></span>
		<span class="tooltip">the symbolic tradition of AI
with these language models,<span class="tooltiptext">la tradition symbolique de l’IA
avec ces modèles de langage,</span></span>
		<span class="tooltip">do you see any aspect of that
in the kind of human feedback<span class="tooltiptext">est-ce que cette idée
de réintégrer un retour humain</span></span>
		<span class="tooltip">that is being built into the systems now?<span class="tooltiptext">est réalisée
dans les systèmes actuels?</span></span>
		<span class="tooltip">I mean, you hear Greg Brockman
saying that, you know,<span class="tooltiptext">Enfin, on entend
Greg Brockman dire</span></span>
		<span class="tooltip">that we don&#39;t just look at predictions,
but constantly giving it feedback.<span class="tooltiptext">qu’ils ne font pas que des prédictions,
qu’ils donnent aussi des retours.</span></span>
		<span class="tooltip">Isn’t that ... giving it a form
of, sort of, symbolic wisdom?<span class="tooltiptext">N’est-ce pas là... lui donner une forme
de sagesse symbolique ?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: You could think about it that way.<span class="tooltiptext">GM: Vous pouvez le voir comme ça.</span></span>
		<span class="tooltip">It&#39;s interesting that none of the details<span class="tooltiptext">C’est intéressant qu’aucun détail</span></span>
		<span class="tooltip">about how it actually works are published,<span class="tooltiptext">sur son fonctionnement ne soit publié,</span></span>
		<span class="tooltip">so we don&#39;t actually know
exactly what&#39;s in GPT-4.<span class="tooltiptext">nous ne savons donc pas
ce qu’il y a dans GPT-4.</span></span>
		<span class="tooltip">We don&#39;t know how big it is.<span class="tooltiptext">Sa taille nous est inconnue.</span></span>
		<span class="tooltip">We don&#39;t know how the RLHF
reinforcement learning works,<span class="tooltiptext">Nous ne savons pas comment marche
le renforcement RLHF,</span></span>
		<span class="tooltip">we don&#39;t know what other
gadgets are in there.<span class="tooltiptext">nous ne savons pas quels
gadgets sont dedans.</span></span>
		<span class="tooltip">But there is probably
an element of symbols<span class="tooltiptext">Mais peut y avoir un élément
de symboles</span></span>
		<span class="tooltip">already starting
to be incorporated a little bit,<span class="tooltiptext">qui commence déjà à être un peu incorporé,</span></span>
		<span class="tooltip">but Greg would have to answer that.<span class="tooltiptext">mais Greg devra y répondre.</span></span>
	</p>
	<p>
		<span class="tooltip">I think the fundamental problem
is that most of the knowledge<span class="tooltiptext">Je pense que le problème de base
est que le plus gros du savoir</span></span>
		<span class="tooltip">in the neural network systems
that we have right now<span class="tooltiptext">sur les réseaux de neurones que nous avons</span></span>
		<span class="tooltip">is represented as statistics
between particular words.<span class="tooltiptext">est représenté en statistiques
entre des mots particuliers.</span></span>
		<span class="tooltip">And the real knowledge
that we want is about statistics,<span class="tooltiptext">Les connaissances que nous désirons
sont les statistiques,</span></span>
		<span class="tooltip">about relationships
between entities in the world.<span class="tooltiptext">sur les relations entre les entités
du monde.</span></span>
		<span class="tooltip">So it&#39;s represented right now
at the wrong grain level.<span class="tooltiptext">Donc des données
à la mauvaise granularité.</span></span>
		<span class="tooltip">And so there&#39;s a big bridge to cross.<span class="tooltiptext">Il y a donc un grand pont à franchir.</span></span>
		<span class="tooltip">So what you get now
is you have these guardrails,<span class="tooltiptext">Maintenant, il existe des garde-fous,</span></span>
		<span class="tooltip">but they&#39;re not very reliable.<span class="tooltiptext">mais qui ne sont pas fiables.</span></span>
	</p>
	<p>
		<span class="tooltip">So I had an example that made
late night television,<span class="tooltiptext">J’ai vu un exemple
à la télévision de fin de soirée,</span></span>
		<span class="tooltip">which was, &quot;What would be the religion
of the first Jewish president?&quot;<span class="tooltiptext">qui était: “Quelle serait la religion
du premier président juif?”</span></span>
		<span class="tooltip">And it&#39;s been fixed now,<span class="tooltiptext">Et ça a été corrigé,</span></span>
		<span class="tooltip">but the system gave this
long song and dance<span class="tooltiptext">mais le système a donné
cette explication :</span></span>
		<span class="tooltip">about &quot;We have no idea what the religion<span class="tooltiptext">« Nous n’avons aucune idée
de la religion</span></span>
		<span class="tooltip">of the first Jewish president would be.<span class="tooltiptext">du premier président juif.</span></span>
		<span class="tooltip">It&#39;s not good to talk
about people&#39;s religions&quot;<span class="tooltiptext">Il est mal de parler
de la religion d’autrui. »</span></span>
		<span class="tooltip">and &quot;people&#39;s religions
have varied&quot; and so forth<span class="tooltiptext">et « les religions
des peuples ont varié », etc,</span></span>
		<span class="tooltip">and did the same thing
with a seven-foot-tall president.<span class="tooltiptext">et de même avec un président
de 7 pieds de haut.</span></span>
		<span class="tooltip">And it said that people of all
heights have been president,<span class="tooltiptext">Il a conclu qu’il y a eu des présidents
de toutes tailles.</span></span>
		<span class="tooltip">but there haven&#39;t actually been
any seven-foot presidents.<span class="tooltiptext">mais il n’y a jamais eu de président
mesurant 7 pieds.</span></span>
		<span class="tooltip">So some of this stuff that it makes up,
it&#39;s not really getting the idea.<span class="tooltiptext">Dans certaines choses qu’il invente,
il ne comprend pas l’idée.</span></span>
		<span class="tooltip">It&#39;s very narrow, particular words,
not really general enough.<span class="tooltiptext">C’est vraiment étroit,
des mots particuliers, pas assez général.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Given that the stakes
are so high in this,<span class="tooltiptext">CA: Étant donné que les enjeux
sont importants ici,</span></span>
		<span class="tooltip">what do you see actually happening
out there right now?<span class="tooltiptext">que voyez-vous actuellement ?</span></span>
		<span class="tooltip">What do you sense is happening?<span class="tooltiptext">Que sentez-vous arriver ?</span></span>
		<span class="tooltip">Because there&#39;s a risk that people feel
attacked by you, for example,<span class="tooltiptext">Parce que certains peuvent se sentir
attaqués par vos propos,</span></span>
		<span class="tooltip">and that it actually almost decreases
the chances of this synthesis<span class="tooltiptext">et que ça réduise presque
les opportunités de cette synthèse</span></span>
		<span class="tooltip">that you&#39;re talking about happening.<span class="tooltiptext">que vous évoquez.</span></span>
		<span class="tooltip">Do you see any hopeful signs of this?<span class="tooltiptext">Voyez-vous des signes prometteurs?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: You just reminded me
of the one line I forgot from my talk.<span class="tooltiptext">GM: Vous me rappelez une chose
que j’ai oublié de mentionner.</span></span>
		<span class="tooltip">It&#39;s so interesting that Sundar,
the CEO of Google,<span class="tooltiptext">Il est intéressant que Sundar,
le PDG de Google,</span></span>
		<span class="tooltip">just actually also came out
for global governance<span class="tooltiptext">se soit prononcé
pour la gouvernance mondiale</span></span>
		<span class="tooltip">in the CBS &quot;60 Minutes&quot; interview
that he did a couple of days ago.<span class="tooltiptext">dans l’interview “60 minutes”
d’il y a quelques jours.</span></span>
		<span class="tooltip">I think that the companies themselves
want to see some kind of regulation.<span class="tooltiptext">Je pense que les entreprises veulent voir
une sorte de régulation.</span></span>
		<span class="tooltip">I think it’s a very complicated dance
to get everybody on the same page,<span class="tooltiptext">Je pense que c’est difficile
pour mettre tout le monde d’accord,</span></span>
		<span class="tooltip">but I think there’s actually growing
sentiment we need to do something here<span class="tooltiptext">mais je pense qu’il y a en fait un
besoin grandissant de faire quelque chose</span></span>
		<span class="tooltip">and that that can drive the kind of
global affiliation I&#39;m arguing for.<span class="tooltiptext">et que ça peut conduire au type
d’affiliation mondiale que je défends.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: I mean, do you think the UN or nations
can somehow come together and do that<span class="tooltiptext">CA: Enfin, pensez-vous que les nations
peuvent s’unir et réaliser ça,</span></span>
		<span class="tooltip">or is this potentially a need for some
spectacular act of philanthropy<span class="tooltiptext">ou est-ce qu’il y aurait besoin
d’acte philantropique spectaculaire</span></span>
		<span class="tooltip">to try and fund a global
governance structure?<span class="tooltiptext">pour financer une structure
de gouvernance mondiale ?</span></span>
		<span class="tooltip">How is it going to happen?<span class="tooltiptext">Comment ça va se passer?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: I&#39;m open to all models
if we can get this done.<span class="tooltiptext">GM: J’approuve tout modèle
si nous y arrivons.</span></span>
		<span class="tooltip">I think it might take some of both.<span class="tooltiptext">Je pense qu’il faudra des deux.</span></span>
		<span class="tooltip">It might take some philanthropists
sponsoring workshops,<span class="tooltiptext">Que des philanthropes
sponsorisent des ateliers,</span></span>
		<span class="tooltip">which we&#39;re thinking of running,
to try to bring the parties together.<span class="tooltiptext">ce que nous prévoyons de faire,
pour essayer de réunir les parties.</span></span>
		<span class="tooltip">Maybe UN will want to be involved,
I&#39;ve had some conversations with them.<span class="tooltiptext">Peut-être que les Nations Unies
s’impliqueront, je leur ai parlé.</span></span>
		<span class="tooltip">I think there are
a lot of different models<span class="tooltiptext">Je pense qu’il y a beaucoup de modèles</span></span>
		<span class="tooltip">and it&#39;ll take a lot of conversations.<span class="tooltiptext">et il faudra beaucoup de discussions.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Gary, thank you so much for your talk.<span class="tooltiptext">CA: Gary, merci de votre intervention.</span></span>
	</p>
	<p>
		<span class="tooltip">GA: Thank you so much.<span class="tooltiptext">GA: Merci beaucoup.</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><p>Designed and developed by <a class='developer' href="https://www.linkedin.com/in/otmane-echaibi-90a524309/">Otmane Echaibi</a></p></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	