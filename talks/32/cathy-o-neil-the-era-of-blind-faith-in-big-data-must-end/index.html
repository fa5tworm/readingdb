<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your English reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="English reading, English language learning, instant translations, reading adventure, improve English, improve reading skills, educational platform, English reading resources, online education, English proficiency, learn English, English learning resources, bilingual education, language exchange, study English online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Cathy O'Neil : The era of blind faith in big data must end</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>The era of blind faith in big data must end</h1>
	<h2 class='speaker'>Cathy O'Neil</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your Spanish speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">Hay algoritmos por todos lados.<span class="tooltiptext">Algorithms are everywhere.</span></span>
		<span class="tooltip">Ordenan y separan a los ganadores 
de los perdedores.<span class="tooltiptext">They sort and separate
the winners from the losers.</span></span>
		<span class="tooltip">Los ganadores consiguen el trabajo<span class="tooltiptext">The winners get the job</span></span>
		<span class="tooltip">o buenas condiciones de crédito.<span class="tooltiptext">or a good credit card offer.</span></span>
		<span class="tooltip">A los perdedores ni siquiera 
se les invita a una entrevista<span class="tooltiptext">The losers don&#39;t even get an interview</span></span>
		<span class="tooltip">o tienen que pagar más por el seguro.<span class="tooltiptext">or they pay more for insurance.</span></span>
		<span class="tooltip">Se nos califica mediante fórmulas
secretas que no entendemos<span class="tooltiptext">We&#39;re being scored with secret formulas
that we don&#39;t understand</span></span>
		<span class="tooltip">y a las que no se puede apelar.<span class="tooltiptext">that often don&#39;t have systems of appeal.</span></span>
		<span class="tooltip">Eso plantea una pregunta:<span class="tooltiptext">That begs the question:</span></span>
		<span class="tooltip">¿Qué pasa si los algoritmos se equivocan?<span class="tooltiptext">What if the algorithms are wrong?</span></span>
	</p>
	<p>
		<span class="tooltip">Un algoritmo necesita dos cosas:<span class="tooltiptext">To build an algorithm you need two things:</span></span>
		<span class="tooltip">datos ocurridos en el pasado<span class="tooltiptext">you need data, what happened in the past,</span></span>
		<span class="tooltip">y una definición del éxito;<span class="tooltiptext">and a definition of success,</span></span>
		<span class="tooltip">esto es, lo que uno quiere y lo que desea.<span class="tooltiptext">the thing you&#39;re looking for
and often hoping for.</span></span>
		<span class="tooltip">Los algoritmos se entrenan
mirando, descubriendo.<span class="tooltiptext">You train an algorithm
by looking, figuring out.</span></span>
		<span class="tooltip">El algoritmo calcula a qué
se asocia el éxito,<span class="tooltiptext">The algorithm figures out
what is associated with success.</span></span>
		<span class="tooltip">qué situaciones llevan al éxito.<span class="tooltiptext">What situation leads to success?</span></span>
	</p>
	<p>
		<span class="tooltip">En general todos usamos algoritmos<span class="tooltiptext">Actually, everyone uses algorithms.</span></span>
		<span class="tooltip">pero no los formalizamos 
mediante un código escrito.<span class="tooltiptext">They just don&#39;t formalize them
in written code.</span></span>
		<span class="tooltip">Les doy un ejemplo.<span class="tooltiptext">Let me give you an example.</span></span>
		<span class="tooltip">Yo uso un algoritmo todos los días
para preparar la comida en casa.<span class="tooltiptext">I use an algorithm every day
to make a meal for my family.</span></span>
		<span class="tooltip">Los datos que uso<span class="tooltiptext">The data I use</span></span>
		<span class="tooltip">son los ingredientes de la cocina,<span class="tooltiptext">is the ingredients in my kitchen,</span></span>
		<span class="tooltip">el tiempo que tengo<span class="tooltiptext">the time I have,</span></span>
		<span class="tooltip">y lo ambiciosa que estoy.<span class="tooltiptext">the ambition I have,</span></span>
		<span class="tooltip">Y así organizo los datos.<span class="tooltiptext">and I curate that data.</span></span>
		<span class="tooltip">No incluyo esos paquetitos
de fideos como comida.<span class="tooltiptext">I don&#39;t count those little packages
of ramen noodles as food.</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">Mi definición del éxito es:<span class="tooltiptext">My definition of success is:</span></span>
		<span class="tooltip">la comida tiene éxito, 
si mis hijos comen verdura.<span class="tooltiptext">a meal is successful
if my kids eat vegetables.</span></span>
		<span class="tooltip">Lo que sería muy distinto, 
si mi hijito tuviera el control.<span class="tooltiptext">It&#39;s very different
from if my youngest son were in charge.</span></span>
		<span class="tooltip">Para él el éxito es comer
mucha Nutella.<span class="tooltiptext">He&#39;d say success is if
he gets to eat lots of Nutella.</span></span>
		<span class="tooltip">Pero yo soy quien elige el éxito.<span class="tooltiptext">But I get to choose success.</span></span>
		<span class="tooltip">Estoy al mando. Mi opinión cuenta.<span class="tooltiptext">I am in charge. My opinion matters.</span></span>
		<span class="tooltip">Esa es la primera regla de los algoritmos.<span class="tooltiptext">That&#39;s the first rule of algorithms.</span></span>
	</p>
	<p>
		<span class="tooltip">Los algoritmos son opiniones 
que se embeben en código.<span class="tooltiptext">Algorithms are opinions embedded in code.</span></span>
		<span class="tooltip">Es muy diferente a cómo la gente 
se imagina los algoritmos.<span class="tooltiptext">It&#39;s really different from what you think
most people think of algorithms.</span></span>
		<span class="tooltip">Se creen que los algoritmos son
objetivos, verdaderos y científicos.<span class="tooltiptext">They think algorithms are objective
and true and scientific.</span></span>
		<span class="tooltip">Ese en un truco del marketing.<span class="tooltiptext">That&#39;s a marketing trick.</span></span>
		<span class="tooltip">Tambien es un truco del marketing<span class="tooltiptext">It&#39;s also a marketing trick</span></span>
		<span class="tooltip">la intimidación con algoritmos,<span class="tooltiptext">to intimidate you with algorithms,</span></span>
		<span class="tooltip">que nos hacer confiar 
y temer los algoritmos<span class="tooltiptext">to make you trust and fear algorithms</span></span>
		<span class="tooltip">porque confiamos y tememos 
las matemáticas.<span class="tooltiptext">because you trust and fear mathematics.</span></span>
		<span class="tooltip">Muchas cosas pueden salir mal si
confiamos a ciegas en datos masivos.<span class="tooltiptext">A lot can go wrong when we put
blind faith in big data.</span></span>
	</p>
	<p>
		<span class="tooltip">Esta es Kiri Soares. Es la directora 
de una escuela de Brooklyn.<span class="tooltiptext">This is Kiri Soares.
She&#39;s a high school principal in Brooklyn.</span></span>
		<span class="tooltip">En 2011 me contó que 
sus maestros se clasificaban<span class="tooltiptext">In 2011, she told me
her teachers were being scored</span></span>
		<span class="tooltip">mediante un algoritmo complejo y secreto<span class="tooltiptext">with a complex, secret algorithm</span></span>
		<span class="tooltip">llamado &quot;modelo del valor añadido&quot;.<span class="tooltiptext">called the &quot;value-added model.&quot;</span></span>
		<span class="tooltip">Le dije, &quot;Intente saber 
cuál es la fórmula, muéstremela.<span class="tooltiptext">I told her, &quot;Well, figure out
what the formula is, show it to me.</span></span>
		<span class="tooltip">Se la voy a explicar&quot;.<span class="tooltiptext">I&#39;m going to explain it to you.&quot;</span></span>
		<span class="tooltip">Me respondió, 
&quot;Trate de conseguir la fórmula,<span class="tooltiptext">She said, &quot;Well, I tried
to get the formula,</span></span>
		<span class="tooltip">pero un conocido del Departamento 
de Educación me dijo<span class="tooltiptext">but my Department of Education contact
told me it was math</span></span>
		<span class="tooltip">que era matemática y 
que no la entendería&quot;.<span class="tooltiptext">and I wouldn&#39;t understand it.&quot;</span></span>
	</p>
	<p>
		<span class="tooltip">Esto se pone peor.<span class="tooltiptext">It gets worse.</span></span>
		<span class="tooltip">El New York Post la solicitó bajo la 
Ley de Libertad a la Información.<span class="tooltiptext">The New York Post filed
a Freedom of Information Act request,</span></span>
		<span class="tooltip">Obtuvo los nombres de los maestros
y su puntuación<span class="tooltiptext">got all the teachers&#39; names
and all their scores</span></span>
		<span class="tooltip">y los publicó como un acto para
avergonzar a los maestros.<span class="tooltiptext">and they published them
as an act of teacher-shaming.</span></span>
		<span class="tooltip">Cuando intenté conseguir las fórmulas en 
código base, usando el mismo mecanismo,<span class="tooltiptext">When I tried to get the formulas,
the source code, through the same means,</span></span>
		<span class="tooltip">me dijeron que no se podía.<span class="tooltiptext">I was told I couldn&#39;t.</span></span>
		<span class="tooltip">Me lo negaron.<span class="tooltiptext">I was denied.</span></span>
		<span class="tooltip">Más tarde descubrí<span class="tooltiptext">I later found out</span></span>
		<span class="tooltip">que nadie tenía derecho 
a la fórmula en Nueva York.<span class="tooltiptext">that nobody in New York City
had access to that formula.</span></span>
		<span class="tooltip">Nadie lo podía entender.<span class="tooltiptext">No one understood it.</span></span>
		<span class="tooltip">Entonces apareció un tipo muy 
inteligente, Gary Rubenstein.<span class="tooltiptext">Then someone really smart
got involved, Gary Rubinstein.</span></span>
		<span class="tooltip">Localizó a 665 maestros por
los datos del New York Post<span class="tooltiptext">He found 665 teachers
from that New York Post data</span></span>
		<span class="tooltip">que tenían dos puntuaciones.<span class="tooltiptext">that actually had two scores.</span></span>
		<span class="tooltip">Eso podía ocurrir si enseñaban<span class="tooltiptext">That could happen if they were teaching</span></span>
		<span class="tooltip">matemática en 7º y 8º grado.<span class="tooltiptext">seventh grade math and eighth grade math.</span></span>
		<span class="tooltip">Decidió hacer un gráfico.<span class="tooltiptext">He decided to plot them.</span></span>
		<span class="tooltip">Donde cada punto representa 
a un maestro.<span class="tooltiptext">Each dot represents a teacher.</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">Y eso ¿qué es?<span class="tooltiptext">What is that?</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">Eso no debiera haberse usado nunca
para evaluar a una persona.<span class="tooltiptext">That should never have been used
for individual assessment.</span></span>
		<span class="tooltip">Es casi un generador de números al azar.<span class="tooltiptext">It&#39;s almost a random number generator.</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">(Applause)</span></span>
	</p>
	<p>
		<span class="tooltip">Pero lo fue.<span class="tooltiptext">But it was.</span></span>
		<span class="tooltip">Esta es Sarah Wysocki.<span class="tooltiptext">This is Sarah Wysocki.</span></span>
		<span class="tooltip">La echaron junto a otros 205 maestros<span class="tooltiptext">She got fired, along
with 205 other teachers,</span></span>
		<span class="tooltip">de una escuela en Washington DC,<span class="tooltiptext">from the Washington, DC school district,</span></span>
		<span class="tooltip">a pesar de tener muy buena recomendación 
de la directora<span class="tooltiptext">even though she had great
recommendations from her principal</span></span>
		<span class="tooltip">y de los padres de sus alumnos.<span class="tooltiptext">and the parents of her kids.</span></span>
	</p>
	<p>
		<span class="tooltip">Me imagino lo que estarán pensando,<span class="tooltiptext">I know what a lot
of you guys are thinking,</span></span>
		<span class="tooltip">especialmente los cientificos de 
datos, los expertos en IA<span class="tooltiptext">especially the data scientists,
the AI experts here.</span></span>
		<span class="tooltip">Pensarán &quot;Nosotros nunca produciríamos
un algoritmo tan inconsistente.&quot;<span class="tooltiptext">You&#39;re thinking, &quot;Well, I would never make
an algorithm that inconsistent.&quot;</span></span>
		<span class="tooltip">Pero los algoritmos a veces fallan,
<span class="tooltiptext">But algorithms can go wrong,</span></span>
		<span class="tooltip">y tambien provocar mucha destrucción
sin querer.<span class="tooltiptext">even have deeply destructive effects
with good intentions.</span></span>
		<span class="tooltip">Y mientras un avión mal diseñado<span class="tooltiptext">And whereas an airplane
that&#39;s designed badly</span></span>
		<span class="tooltip">se estrella y todos lo ven,<span class="tooltiptext">crashes to the earth and everyone sees it,</span></span>
		<span class="tooltip">un algoritmo mal diseñado<span class="tooltiptext">an algorithm designed badly</span></span>
		<span class="tooltip">puede funcionar mucho tiempo
provocando un desastre silenciosamente.<span class="tooltiptext">can go on for a long time,
silently wreaking havoc.</span></span>
	</p>
	<p>
		<span class="tooltip">Este es Roger Ailes.<span class="tooltiptext">This is Roger Ailes.</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">Fundador de Fox News en el 1996.<span class="tooltiptext">He founded Fox News in 1996.</span></span>
		<span class="tooltip">Mas de 20 mujeres se quejaron de
acoso sexual.<span class="tooltiptext">More than 20 women complained
about sexual harassment.</span></span>
		<span class="tooltip">Dijeron que no pudieron 
tener éxito en Fox News.<span class="tooltiptext">They said they weren&#39;t allowed
to succeed at Fox News.</span></span>
		<span class="tooltip">Lo echaron el año pasado,
pero hemos visto que hace poco<span class="tooltiptext">He was ousted last year,
but we&#39;ve seen recently</span></span>
		<span class="tooltip">los problemas han continuado.<span class="tooltiptext">that the problems have persisted.</span></span>
		<span class="tooltip">Esto plantea una pregunta:<span class="tooltiptext">That begs the question:</span></span>
		<span class="tooltip">¿Qué debe hacer Fox News para cambiar?<span class="tooltiptext">What should Fox News do
to turn over another leaf?</span></span>
	</p>
	<p>
		<span class="tooltip">Y si substituyeran su mecanismo
de contratación<span class="tooltiptext">Well, what if they replaced
their hiring process</span></span>
		<span class="tooltip">con un algoritmo de auto-
aprendizaje automatizado?<span class="tooltiptext">with a machine-learning algorithm?</span></span>
		<span class="tooltip">¿Suena bien?<span class="tooltiptext">That sounds good, right?</span></span>
		<span class="tooltip">Piénsenlo,<span class="tooltiptext">Think about it.</span></span>
		<span class="tooltip">Los datos, ¿qué datos serían?<span class="tooltiptext">The data, what would the data be?</span></span>
		<span class="tooltip">Una eleccion razonable serian las últimas
21 solicitudes recibidas por Fox News<span class="tooltiptext">A reasonable choice would be the last
21 years of applications to Fox News.</span></span>
		<span class="tooltip">Razonable.<span class="tooltiptext">Reasonable.</span></span>
		<span class="tooltip">Y ¿cuál sería la definición del éxito?<span class="tooltiptext">What about the definition of success?</span></span>
		<span class="tooltip">Algo razonable sería<span class="tooltiptext">Reasonable choice would be,</span></span>
		<span class="tooltip">preguntar, quién es exitoso en Fox News.<span class="tooltiptext">well, who is successful at Fox News?</span></span>
		<span class="tooltip">Me imagino que alguien que
hubiera estado alli unos 4 años<span class="tooltiptext">I guess someone who, say,
stayed there for four years</span></span>
		<span class="tooltip">y subido de puesto por lo menosuna vez.<span class="tooltiptext">and was promoted at least once.</span></span>
		<span class="tooltip">¿Suena razonable?<span class="tooltiptext">Sounds reasonable.</span></span>
		<span class="tooltip">Y así se adiestraría el algoritmo.<span class="tooltiptext">And then the algorithm would be trained.</span></span>
		<span class="tooltip">Se adiestraría para buscar a gente 
que logra el éxito.<span class="tooltiptext">It would be trained to look for people
to learn what led to success,</span></span>
		<span class="tooltip">Y qué solicitudes antiguas 
llegaron al éxito<span class="tooltiptext">what kind of applications
historically led to success</span></span>
		<span class="tooltip">según esa definición.<span class="tooltiptext">by that definition.</span></span>
		<span class="tooltip">Ahora piensen que ocurriría<span class="tooltiptext">Now think about what would happen</span></span>
		<span class="tooltip">si lo usáramos con los candidatos de hoy.<span class="tooltiptext">if we applied that
to a current pool of applicants.</span></span>
		<span class="tooltip">Filtraría a las mujeres<span class="tooltiptext">It would filter out women</span></span>
		<span class="tooltip">ya que no parecen ser personas que
hayan tenido éxito en el pasado.<span class="tooltiptext">because they do not look like people
who were successful in the past.</span></span>
	</p>
	<p>
		<span class="tooltip">Los algoritmos no son justos<span class="tooltiptext">Algorithms don&#39;t make things fair</span></span>
		<span class="tooltip">si uno usa algoritmos a ciegas.<span class="tooltiptext">if you just blithely,
blindly apply algorithms.</span></span>
		<span class="tooltip">No son justos.<span class="tooltiptext">They don&#39;t make things fair.</span></span>
		<span class="tooltip">Repiten prácticas anteriores,<span class="tooltiptext">They repeat our past practices,</span></span>
		<span class="tooltip">nuestros patrones.<span class="tooltiptext">our patterns.</span></span>
		<span class="tooltip">Automatizan al status quo.<span class="tooltiptext">They automate the status quo.</span></span>
		<span class="tooltip">Sería genial en un mundo perfecto,<span class="tooltiptext">That would be great
if we had a perfect world,</span></span>
		<span class="tooltip">pero no lo tenemos.<span class="tooltiptext">but we don&#39;t.</span></span>
		<span class="tooltip">Y aclaro que la mayoria de las empresas
no estan involucradas en litigios,<span class="tooltiptext">And I&#39;ll add that most companies
don&#39;t have embarrassing lawsuits,</span></span>
		<span class="tooltip">pero los cientificos de datos 
de esas empresas<span class="tooltiptext">but the data scientists in those companies</span></span>
		<span class="tooltip">emplean esos datos<span class="tooltiptext">are told to follow the data,</span></span>
		<span class="tooltip">para lograr la precisión.<span class="tooltiptext">to focus on accuracy.</span></span>
		<span class="tooltip">Piensen qué significa esto.<span class="tooltiptext">Think about what that means.</span></span>
		<span class="tooltip">Porque todos tenemos prejuicios,
y así podríamos codificar sexismo<span class="tooltiptext">Because we all have bias,
it means they could be codifying sexism</span></span>
		<span class="tooltip">u otro tipo de fanatismo.<span class="tooltiptext">or any other kind of bigotry.</span></span>
	</p>
	<p>
		<span class="tooltip">Un experimento de pensamiento,<span class="tooltiptext">Thought experiment,</span></span>
		<span class="tooltip">porque me gusta,<span class="tooltiptext">because I like them:</span></span>
		<span class="tooltip">una sociedad totalmente segregada.<span class="tooltiptext">an entirely segregated society --</span></span>
		<span class="tooltip">segregada racialmente, 
todas las ciudades y los barrios<span class="tooltiptext">racially segregated, all towns,
all neighborhoods</span></span>
		<span class="tooltip">y donde enviamos a la policia
solo a barrios minoritarios<span class="tooltiptext">and where we send the police
only to the minority neighborhoods</span></span>
		<span class="tooltip">para detectar delitos.<span class="tooltiptext">to look for crime.</span></span>
		<span class="tooltip">Los arrestos serían sesgados.<span class="tooltiptext">The arrest data would be very biased.</span></span>
		<span class="tooltip">Y, además, elegimos a los
cientificos de datos<span class="tooltiptext">What if, on top of that,
we found the data scientists</span></span>
		<span class="tooltip">y pagamos por los datos para predecir
dónde ocurrirán los próximos delitos.<span class="tooltiptext">and paid the data scientists to predict
where the next crime would occur?</span></span>
		<span class="tooltip">El barrio de una minoría.<span class="tooltiptext">Minority neighborhood.</span></span>
		<span class="tooltip">O a predecir quien será 
el próximo criminal.<span class="tooltiptext">Or to predict who the next
criminal would be?</span></span>
		<span class="tooltip">Una minoría.<span class="tooltiptext">A minority.</span></span>
		<span class="tooltip">Los cientificos de datos se jactarían
de su grandeza y de la precisión<span class="tooltiptext">The data scientists would brag
about how great and how accurate</span></span>
		<span class="tooltip">de su modelo,<span class="tooltiptext">their model would be,</span></span>
		<span class="tooltip">y tendrían razón.<span class="tooltiptext">and they&#39;d be right.</span></span>
	</p>
	<p>
		<span class="tooltip">La realidad no es tan drástica,
pero tenemos grandes segregaciones<span class="tooltiptext">Now, reality isn&#39;t that drastic,
but we do have severe segregations</span></span>
		<span class="tooltip">en muchas ciudades<span class="tooltiptext">in many cities and towns,</span></span>
		<span class="tooltip">y tenemos muchas pruebas<span class="tooltiptext">and we have plenty of evidence</span></span>
		<span class="tooltip">de datos políticos y 
legislativos sesgados.<span class="tooltiptext">of biased policing
and justice system data.</span></span>
		<span class="tooltip">Y podemos predecir puntos calientes,<span class="tooltiptext">And we actually do predict hotspots,</span></span>
		<span class="tooltip">lugares donde podrá ocurrir un delito<span class="tooltiptext">places where crimes will occur.</span></span>
		<span class="tooltip">Y así predecir un crimen individual<span class="tooltiptext">And we do predict, in fact,
the individual criminality,</span></span>
		<span class="tooltip">y la criminalidad de los individuos.<span class="tooltiptext">the criminality of individuals.</span></span>
		<span class="tooltip">El organismo de noticias ProPublica 
lo estudió hace poco.<span class="tooltiptext">The news organization ProPublica
recently looked into</span></span>
		<span class="tooltip">un algoritmo de &quot;riesgo recidivista&quot;<span class="tooltiptext">one of those &quot;recidivism risk&quot; algorithms,</span></span>
		<span class="tooltip">según los llaman<span class="tooltiptext">as they&#39;re called,</span></span>
		<span class="tooltip">usado en Florida
al hacer sentencias judiciales.<span class="tooltiptext">being used in Florida
during sentencing by judges.</span></span>
		<span class="tooltip">Bernardo, a la izquierda, un hombre negro
sacó una puntuación de 10 de 10.<span class="tooltiptext">Bernard, on the left, the black man,
was scored a 10 out of 10.</span></span>
		<span class="tooltip">Dylan, a la derecha, 3 de 10.<span class="tooltiptext">Dylan, on the right, 3 out of 10.</span></span>
		<span class="tooltip">10 de 10, alto riesgo
3 de 10, bajo riesgo.<span class="tooltiptext">10 out of 10, high risk.
3 out of 10, low risk.</span></span>
		<span class="tooltip">Los sentenciaron por tener drogas.<span class="tooltiptext">They were both brought in
for drug possession.</span></span>
		<span class="tooltip">Ambos con antecedentes penales<span class="tooltiptext">They both had records,</span></span>
		<span class="tooltip">pero Dylan habia cometido un delito<span class="tooltiptext">but Dylan had a felony</span></span>
		<span class="tooltip">Bernard, no.<span class="tooltiptext">but Bernard didn&#39;t.</span></span>
		<span class="tooltip">Esto importa porque
a mayor puntuación<span class="tooltiptext">This matters, because
the higher score you are,</span></span>
		<span class="tooltip">mayor probabilidad de 
una sentencia más larga.<span class="tooltiptext">the more likely you&#39;re being given
a longer sentence.</span></span>
	</p>
	<p>
		<span class="tooltip">¿Que sucede?<span class="tooltiptext">What&#39;s going on?</span></span>
		<span class="tooltip">Lavado de datos.<span class="tooltiptext">Data laundering.</span></span>
		<span class="tooltip">El proceso que se usa para
ocultar verdades feas<span class="tooltiptext">It&#39;s a process by which
technologists hide ugly truths</span></span>
		<span class="tooltip">dentro de una caja negra
de algoritmos<span class="tooltiptext">inside black box algorithms</span></span>
		<span class="tooltip">y llamarlos objetivos;<span class="tooltiptext">and call them objective;</span></span>
		<span class="tooltip">llamándolos meritocráticos<span class="tooltiptext">call them meritocratic.</span></span>
		<span class="tooltip">cuando son secretos,
importantes y destructivos<span class="tooltiptext">When they&#39;re secret,
important and destructive,</span></span>
		<span class="tooltip">Les puse un nombre a estos algoritmos:<span class="tooltiptext">I&#39;ve coined a term for these algorithms:</span></span>
		<span class="tooltip">&quot;armas matemáticas de destrucción&quot;<span class="tooltiptext">&quot;weapons of math destruction.&quot;</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">(Applause)</span></span>
	</p>
	<p>
		<span class="tooltip">Estan en todos sitios<span class="tooltiptext">They&#39;re everywhere,
and it&#39;s not a mistake.</span></span>
		<span class="tooltip">Son empresas privadas
que construyen algoritmos privados<span class="tooltiptext">These are private companies
building private algorithms</span></span>
		<span class="tooltip">para fines privados.<span class="tooltiptext">for private ends.</span></span>
		<span class="tooltip">Incluso los mencionados
de los maestros y la policía pública<span class="tooltiptext">Even the ones I talked about
for teachers and the public police,</span></span>
		<span class="tooltip">fueron diseñados por empresas privadas<span class="tooltiptext">those were built by private companies</span></span>
		<span class="tooltip">y vendidos a 
instituciones gubernamentales.<span class="tooltiptext">and sold to the government institutions.</span></span>
		<span class="tooltip">Lo llaman su &quot;salsa secreta&quot;<span class="tooltiptext">They call it their &quot;secret sauce&quot; --</span></span>
		<span class="tooltip">por eso no nos pueden hablar de ello.<span class="tooltiptext">that&#39;s why they can&#39;t tell us about it.</span></span>
		<span class="tooltip">Es un poder privado<span class="tooltiptext">It&#39;s also private power.</span></span>
		<span class="tooltip">que saca provecho por su
autoridad inescrutable.<span class="tooltiptext">They are profiting for wielding
the authority of the inscrutable.</span></span>
		<span class="tooltip">Entonces uno ha de pensar,
ya que todo esto es privado<span class="tooltiptext">Now you might think,
since all this stuff is private</span></span>
		<span class="tooltip">y hay competición,<span class="tooltiptext">and there&#39;s competition,</span></span>
		<span class="tooltip">tal vez un mercado libre
podrá solucionarlo<span class="tooltiptext">maybe the free market
will solve this problem.</span></span>
		<span class="tooltip">Pero no.<span class="tooltiptext">It won&#39;t.</span></span>
		<span class="tooltip">Se puede ganar mucho dinero
con la injusticia.<span class="tooltiptext">There&#39;s a lot of money
to be made in unfairness.</span></span>
	</p>
	<p>
		<span class="tooltip">Tampoco somos agentes 
económicos racionales.<span class="tooltiptext">Also, we&#39;re not economic rational agents.</span></span>
		<span class="tooltip">Todos tenemos prejuicios<span class="tooltiptext">We all are biased.</span></span>
		<span class="tooltip">Somos racistas y fanáticos
de una forma que no quisiéramos,<span class="tooltiptext">We&#39;re all racist and bigoted
in ways that we wish we weren&#39;t,</span></span>
		<span class="tooltip">de maneras que desconocemos.<span class="tooltiptext">in ways that we don&#39;t even know.</span></span>
		<span class="tooltip">Lo sabemos al sumarlo<span class="tooltiptext">We know this, though, in aggregate,</span></span>
		<span class="tooltip">porque los sociólogos
lo han demostrado consistentemente<span class="tooltiptext">because sociologists
have consistently demonstrated this</span></span>
		<span class="tooltip">con experimentos que construyeron<span class="tooltiptext">with these experiments they build,</span></span>
		<span class="tooltip">donde mandan una cantidad de solicitudes
de empleo<span class="tooltiptext">where they send a bunch
of applications to jobs out,</span></span>
		<span class="tooltip">de personas de calificaciones iguales
pero algunas con apellidos blancos<span class="tooltiptext">equally qualified but some
have white-sounding names</span></span>
		<span class="tooltip">y otras con apellidos negros,<span class="tooltiptext">and some have black-sounding names,</span></span>
		<span class="tooltip">y los resultados siempre los 
decepcionan, siempre.<span class="tooltiptext">and it&#39;s always disappointing,
the results -- always.</span></span>
	</p>
	<p>
		<span class="tooltip">Nosotros somos los prejuiciosos<span class="tooltiptext">So we are the ones that are biased,</span></span>
		<span class="tooltip">que inyectamos prejuicios
a nuestros algoritmos<span class="tooltiptext">and we are injecting those biases
into the algorithms</span></span>
		<span class="tooltip">al elegir qué datos recoger,<span class="tooltiptext">by choosing what data to collect,</span></span>
		<span class="tooltip">así como yo elegí no pensar 
en los fideos--<span class="tooltiptext">like I chose not to think
about ramen noodles --</span></span>
		<span class="tooltip">Y decidi que no era importante.<span class="tooltiptext">I decided it was irrelevant.</span></span>
		<span class="tooltip">Pero tenerle confianza a los datos
basados en prácticas pasadas<span class="tooltiptext">But by trusting the data that&#39;s actually
picking up on past practices</span></span>
		<span class="tooltip">y eligiendo la definición del éxito,<span class="tooltiptext">and by choosing the definition of success,</span></span>
		<span class="tooltip">¿cómo pretendemos que los
algoritmos emerjan intactos?<span class="tooltiptext">how can we expect the algorithms
to emerge unscathed?</span></span>
		<span class="tooltip">No podemos. Tenemos que verificarlos.<span class="tooltiptext">We can&#39;t. We have to check them.</span></span>
		<span class="tooltip">Hay que revisarlos por equidad.<span class="tooltiptext">We have to check them for fairness.</span></span>
	</p>
	<p>
		<span class="tooltip">Y las buenas noticias son<span class="tooltiptext">The good news is,
we can check them for fairness.</span></span>
		<span class="tooltip">que los algoritmos pueden ser 
interrogados,<span class="tooltiptext">Algorithms can be interrogated,</span></span>
		<span class="tooltip">y nos dirán la verdad todas las veces.<span class="tooltiptext">and they will tell us
the truth every time.</span></span>
		<span class="tooltip">Y los podemos arreglar.
Y mejorarlos.<span class="tooltiptext">And we can fix them.
We can make them better.</span></span>
		<span class="tooltip">Lo explico. Esto se llama revisión 
del algoritmo,<span class="tooltiptext">I call this an algorithmic audit,</span></span>
		<span class="tooltip">lo explico.<span class="tooltiptext">and I&#39;ll walk you through it.</span></span>
	</p>
	<p>
		<span class="tooltip">Primero, verificación de 
integridad de datos.<span class="tooltiptext">First, data integrity check.</span></span>
		<span class="tooltip">por el riesgo recidivista.<span class="tooltiptext">For the recidivism risk
algorithm I talked about,</span></span>
		<span class="tooltip">La verificación de la integridad de datos 
implicaría una conciliación<span class="tooltiptext">a data integrity check would mean
we&#39;d have to come to terms with the fact</span></span>
		<span class="tooltip">que en EE. UU. los blancos y los 
negros fuman marihuana<span class="tooltiptext">that in the US, whites and blacks
smoke pot at the same rate</span></span>
		<span class="tooltip">pero a los negros es mas fácil que 
los arresten<span class="tooltiptext">but blacks are far more likely
to be arrested --</span></span>
		<span class="tooltip">más probablemente cuatro o cinco 
veces más dependiendo de la zona.<span class="tooltiptext">four or five times more likely,
depending on the area.</span></span>
		<span class="tooltip">Y ¿cómo son los prejuicios en 
otras categorías criminales,<span class="tooltiptext">What is that bias looking like
in other crime categories,</span></span>
		<span class="tooltip">y cómo lo justificamos?<span class="tooltiptext">and how do we account for it?</span></span>
	</p>
	<p>
		<span class="tooltip">Segundo, debemos pensar 
en la definición del éxito,<span class="tooltiptext">Second, we should think about
the definition of success,</span></span>
		<span class="tooltip">revisarla.<span class="tooltiptext">audit that.</span></span>
		<span class="tooltip">¿Recuerdan el algoritmo
de la contratación?<span class="tooltiptext">Remember -- with the hiring
algorithm? We talked about it.</span></span>
		<span class="tooltip">alguien que se queda cuatro años 
y asciende de cargo una vez?<span class="tooltiptext">Someone who stays for four years
and is promoted once?</span></span>
		<span class="tooltip">Ese es el empleado exitoso,<span class="tooltiptext">Well, that is a successful employee,</span></span>
		<span class="tooltip">pero tambien es el empleado
apoyado por la cultura.<span class="tooltiptext">but it&#39;s also an employee
that is supported by their culture.</span></span>
		<span class="tooltip">Esto puede ser bastante injusto.<span class="tooltiptext">That said, also it can be quite biased.</span></span>
		<span class="tooltip">Tenemos que separar dos cosas.<span class="tooltiptext">We need to separate those two things.</span></span>
		<span class="tooltip">Mirar a la audicion de una 
orquesta de ciegos<span class="tooltiptext">We should look to
the blind orchestra audition</span></span>
		<span class="tooltip">por ejemplo.<span class="tooltiptext">as an example.</span></span>
		<span class="tooltip">Los que dan la audición están 
detrás de la partitura.<span class="tooltiptext">That&#39;s where the people auditioning
are behind a sheet.</span></span>
		<span class="tooltip">Lo que quiero que piensen<span class="tooltiptext">What I want to think about there</span></span>
		<span class="tooltip">es que la gente que escucha
decide lo que es importante<span class="tooltiptext">is the people who are listening
have decided what&#39;s important</span></span>
		<span class="tooltip">y lo que no lo es,<span class="tooltiptext">and they&#39;ve decided what&#39;s not important,</span></span>
		<span class="tooltip">sin que eso nos distraiga.<span class="tooltiptext">and they&#39;re not getting
distracted by that.</span></span>
		<span class="tooltip">Cuando empezaron las audiciones 
de orquesta de ciegos<span class="tooltiptext">When the blind orchestra
auditions started,</span></span>
		<span class="tooltip">la cantidad de mujeres aumentó
un factor de cinco veces.<span class="tooltiptext">the number of women in orchestras
went up by a factor of five.</span></span>
	</p>
	<p>
		<span class="tooltip">Tambien hay que pensar en la precisión<span class="tooltiptext">Next, we have to consider accuracy.</span></span>
		<span class="tooltip">y así el modelo 
del valor añadido fallaría.<span class="tooltiptext">This is where the value-added model
for teachers would fail immediately.</span></span>
		<span class="tooltip">Por supuesto ningún algoritmo es perfecto,<span class="tooltiptext">No algorithm is perfect, of course,</span></span>
		<span class="tooltip">asi que hay que considerar los 
errores de cada algoritmo.<span class="tooltiptext">so we have to consider
the errors of every algorithm.</span></span>
		<span class="tooltip">¿Qué frecuencia tienen los errores
y con quiénes falla?<span class="tooltiptext">How often are there errors,
and for whom does this model fail?</span></span>
		<span class="tooltip">Y ¿cuál es el costo de dicha falla?<span class="tooltiptext">What is the cost of that failure?</span></span>
	</p>
	<p>
		<span class="tooltip">Y por último, tenemos que considerar<span class="tooltiptext">And finally, we have to consider</span></span>
		<span class="tooltip">los efectos a largo plazo 
de los algoritmos,<span class="tooltiptext">the long-term effects of algorithms,</span></span>
		<span class="tooltip">los bucles de retroalimentación 
que engendran.<span class="tooltiptext">the feedback loops that are engendering.</span></span>
		<span class="tooltip">Eso suena a abstracto.<span class="tooltiptext">That sounds abstract,</span></span>
		<span class="tooltip">Pero imagínese si los ingenieros 
de Facebook lo hubieran considerado<span class="tooltiptext">but imagine if Facebook engineers
had considered that</span></span>
		<span class="tooltip">antes de mostrarnos cosas
publicadas por nuestros amigos.<span class="tooltiptext">before they decided to show us
only things that our friends had posted.</span></span>
	</p>
	<p>
		<span class="tooltip">Tengo dos mensajes,
uno para los científicos de datos.<span class="tooltiptext">I have two more messages,
one for the data scientists out there.</span></span>
		<span class="tooltip">Cientificos de datos: no debemos
ser los árbitros de la verdad.<span class="tooltiptext">Data scientists: we should
not be the arbiters of truth.</span></span>
		<span class="tooltip">Debemos ser tradutores de las
discusiones éticas que ocurren<span class="tooltiptext">We should be translators
of ethical discussions that happen</span></span>
		<span class="tooltip">en toda la sociedad.<span class="tooltiptext">in larger society.</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">(Applause)</span></span>
	</p>
	<p>
		<span class="tooltip">Y para el resto de Uds.<span class="tooltiptext">And the rest of you,</span></span>
		<span class="tooltip">los que no son científicos de datos:<span class="tooltiptext">the non-data scientists:</span></span>
		<span class="tooltip">esta no es un examen de matemáticas.<span class="tooltiptext">this is not a math test.</span></span>
		<span class="tooltip">Es una lucha politica.<span class="tooltiptext">This is a political fight.</span></span>
		<span class="tooltip">Tenemos que exigir responsabilidad
a los lores de los algoritmos.<span class="tooltiptext">We need to demand accountability
for our algorithmic overlords.</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">(Applause)</span></span>
	</p>
	<p>
		<span class="tooltip">La era de la fe ciega en los
datos masivos debe terminar.<span class="tooltiptext">The era of blind faith
in big data must end.</span></span>
	</p>
	<p>
		<span class="tooltip">Muchas gracias.<span class="tooltiptext">Thank you very much.</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplauso)<span class="tooltiptext">(Applause)</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	