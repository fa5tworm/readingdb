<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Desbloquea la competencia en inglés con nuestra plataforma innovadora basada en las transcripciones de TED Talks. Sumérgete en un contenido cautivador, accede a traducciones instantáneas y únete a una comunidad global de estudiantes. ¡Comienza tu aventura de lectura hoy mismo! | Unlock English proficiency with our innovative platform powered by TED Talk transcripts. Dive into captivating content, access instant translations, and join a global community of learners. Start your reading adventure today!">
		<meta name="keywords" content="lectura en inglés, transcripciones de TED Talks, aprendizaje de idiomas, traducciones instantáneas, comunidad global, aventura de lectura, mejorar inglés, mejorar habilidades de lectura, plataforma educativa, recursos de lectura, educación en línea, English reading, TED Talks transcripts, language learning, instant translations, global community, reading adventure, improve English, improve reading skills, educational platform, reading resources, online education, English proficiency, learn English, English learning resources, bilingual education, language exchange, study English online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Gary Marcus : The urgent risks of runaway AI — and what to do about them</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>The urgent risks of runaway AI — and what to do about them</h1>
	<h2 class='speaker'>Gary Marcus</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your English speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">I’m here to talk about the possibility
of global AI governance.<span class="tooltiptext">Hablaré sobre la posibilidad
de regular la IA global.</span></span>
		<span class="tooltip">I first learned to code
when I was eight years old,<span class="tooltiptext">La primera vez que aprendí a codificar
fue a los ocho años,</span></span>
		<span class="tooltip">on a paper computer,<span class="tooltiptext">en una computadora de papel.</span></span>
		<span class="tooltip">and I&#39;ve been in love with AI ever since.<span class="tooltiptext">Desde entonces, 
soy un apasionado de la IA.</span></span>
		<span class="tooltip">In high school,<span class="tooltiptext">En la secundaria,</span></span>
		<span class="tooltip">I got myself a Commodore 64
and worked on machine translation.<span class="tooltiptext">tenía una Commodore 64
y usaba la traducción automática.</span></span>
		<span class="tooltip">I built a couple of AI companies,
I sold one of them to Uber.<span class="tooltiptext">Fundé un par de empresas de IA,
una de las cuales fue comprada por Uber.</span></span>
		<span class="tooltip">I love AI, but right now I&#39;m worried.<span class="tooltiptext">La IA me fascina, pero ahora me preocupa.</span></span>
	</p>
	<p>
		<span class="tooltip">One of the things that I’m worried
about is misinformation,<span class="tooltiptext">Una de mis preocupaciones
es la información errónea,</span></span>
		<span class="tooltip">the possibility that bad actors
will make a tsunami of misinformation<span class="tooltiptext">la posibilidad
de que actores malintencionados</span></span>
		<span class="tooltip">like we&#39;ve never seen before.<span class="tooltiptext">generen un tsunami de información errónea</span></span>
		<span class="tooltip">These tools are so good
at making convincing narratives<span class="tooltiptext">como nunca se vio antes.</span></span>
		<span class="tooltip">about just about anything.<span class="tooltiptext">Estas herramientas saben muy bien
cómo crear narrativas convincentes</span></span>
	</p>
	<p>
		<span class="tooltip">If you want a narrative
about TED and how it&#39;s dangerous,<span class="tooltiptext">en prácticamente cualquier tema.</span></span>
		<span class="tooltip">that we&#39;re colluding here
with space aliens,<span class="tooltiptext">Si queremos una narrativa
sobre lo peligroso que puede ser TED,</span></span>
		<span class="tooltip">you got it, no problem.<span class="tooltiptext">y que nos confabulamos aquí
con extraterrestres,</span></span>
		<span class="tooltip">I&#39;m of course kidding about TED.<span class="tooltiptext">pues se crea, sin problemas.</span></span>
		<span class="tooltip">I didn&#39;t see any space aliens backstage.<span class="tooltiptext">Lo de TED, claro, es una broma.</span></span>
		<span class="tooltip">But bad actors are going to use
these things to influence elections,<span class="tooltiptext">No vi ningún extraterrestre
detrás del escenario.</span></span>
		<span class="tooltip">and they&#39;re going to threaten democracy.<span class="tooltiptext">Pero los actores malintencionados 
la usarán para influir en elecciones,</span></span>
	</p>
	<p>
		<span class="tooltip">Even when these systems<span class="tooltiptext">y será una amenaza para la democracia.</span></span>
		<span class="tooltip">aren&#39;t deliberately being used
to make misinformation,<span class="tooltiptext">Aunque estos sistemas</span></span>
		<span class="tooltip">they can&#39;t help themselves.<span class="tooltiptext">no se usen deliberadamente
para crear información errónea,</span></span>
		<span class="tooltip">And the information that they make
is so fluid and so grammatical<span class="tooltiptext">no pueden evitarlo.</span></span>
		<span class="tooltip">that even professional editors
sometimes get sucked in<span class="tooltiptext">Y la información que crean es tan fluida 
y tan perfecta en su gramática</span></span>
		<span class="tooltip">and get fooled by this stuff.<span class="tooltiptext">que hasta los editores profesionales
a veces caen en la trampa</span></span>
		<span class="tooltip">And we should be worried.<span class="tooltiptext">y son presas del engaño.</span></span>
	</p>
	<p>
		<span class="tooltip">For example, ChatGPT made up
a sexual harassment scandal<span class="tooltiptext">Y esto es preocupante.</span></span>
		<span class="tooltip">about an actual professor,<span class="tooltiptext">Por ejemplo, el ChatGPT inventó
un escándalo de acoso sexual</span></span>
		<span class="tooltip">and then it provided
evidence for its claim<span class="tooltiptext">sobre un profesor universitario real,</span></span>
		<span class="tooltip">in the form of a fake
&quot;Washington Post&quot; article<span class="tooltiptext">y, como evidencia del hecho,</span></span>
		<span class="tooltip">that it created a citation to.<span class="tooltiptext">citó un artículo falso
del Washington Post,</span></span>
		<span class="tooltip">We should all be worried
about that kind of thing.<span class="tooltiptext">creado por el chatbot.</span></span>
	</p>
	<p>
		<span class="tooltip">What I have on the right
is an example of a fake narrative<span class="tooltiptext">Este tipo de cosas
deberían preocuparnos a todos.</span></span>
		<span class="tooltip">from one of these systems<span class="tooltiptext">Aquí, a la derecha, 
vemos un ejemplo de narrativa falsa</span></span>
		<span class="tooltip">saying that Elon Musk died
in March of 2018 in a car crash.<span class="tooltiptext">creada por uno de estos sistemas.</span></span>
		<span class="tooltip">We all know that&#39;s not true.<span class="tooltiptext">Dijo que Elon Musk murió en marzo de 2018
en un accidente de auto.</span></span>
		<span class="tooltip">Elon Musk is still here,
the evidence is all around us.<span class="tooltiptext">Sabemos que es falso.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">Elon Musk está vivo,
y la evidencia está por todos lados.</span></span>
	</p>
	<p>
		<span class="tooltip">Almost every day there&#39;s a tweet.<span class="tooltiptext">(Risas)</span></span>
		<span class="tooltip">But if you look on the left,
you see what these systems see.<span class="tooltiptext">Tuitea casi todos los días.</span></span>
		<span class="tooltip">Lots and lots of actual news stories
that are in their databases.<span class="tooltiptext">Pero aquí, a la izquierda,
aparece lo que estos sistemas ven:</span></span>
		<span class="tooltip">And in those actual news stories are lots
of little bits of statistical information.<span class="tooltiptext">muchas noticias reales que se almacenan
en sus bases de datos,</span></span>
		<span class="tooltip">Information, for example,<span class="tooltiptext">y que contienen gran cantidad
de información estadística.</span></span>
		<span class="tooltip">somebody did die in a car crash
in a Tesla in 2018<span class="tooltiptext">Allí vemos, por ejemplo,</span></span>
		<span class="tooltip">and it was in the news.<span class="tooltiptext">que, efectivamente, una persona murió
en un accidente en un Tesla en 2018,</span></span>
		<span class="tooltip">And Elon Musk, of course,
is involved in Tesla,<span class="tooltiptext">y esto apareció en las noticias.</span></span>
		<span class="tooltip">but the system doesn&#39;t
understand the relation<span class="tooltiptext">Elon Musk, claramente, 
está vinculado con Tesla,</span></span>
		<span class="tooltip">between the facts that are embodied
in the little bits of sentences.<span class="tooltiptext">pero el sistema no entiende 
la relación entre los hechos</span></span>
	</p>
	<p>
		<span class="tooltip">So it&#39;s basically doing auto-complete,<span class="tooltiptext">que se mencionan en las distintas partes
de las oraciones.</span></span>
		<span class="tooltip">it predicts what
is statistically probable,<span class="tooltiptext">Básicamente, lo que hace es autocompletar.</span></span>
		<span class="tooltip">aggregating all of these signals,<span class="tooltiptext">Predice lo que es 
estadísticamente probable</span></span>
		<span class="tooltip">not knowing how the pieces fit together.<span class="tooltiptext">reuniendo todas estas señales,</span></span>
		<span class="tooltip">And it winds up sometimes with things
that are plausible but simply not true.<span class="tooltiptext">pero no sabe cómo encajan
las partes de la información.</span></span>
	</p>
	<p>
		<span class="tooltip">There are other problems, too, like bias.<span class="tooltiptext">Y a veces termina produciendo
cosas creíbles pero no verdaderas.</span></span>
		<span class="tooltip">This is a tweet from Allie Miller.<span class="tooltiptext">Otro problema con la IA es el sesgo.</span></span>
		<span class="tooltip">It&#39;s an example that doesn&#39;t
work two weeks later<span class="tooltiptext">Este tuit es de Allie Miller.</span></span>
		<span class="tooltip">because they&#39;re constantly changing
things with reinforcement learning<span class="tooltiptext">Es un ejemplo que no funciona
dos semanas después,</span></span>
		<span class="tooltip">and so forth.<span class="tooltiptext">porque los sistemas 
cambian las cosas todo el tiempo</span></span>
		<span class="tooltip">And this was with an earlier version.<span class="tooltiptext">con el aprendizaje reforzado 
y otras cosas.</span></span>
		<span class="tooltip">But it gives you the flavor of a problem
that we&#39;ve seen over and over for years.<span class="tooltiptext">Esto fue con una versión previa.</span></span>
	</p>
	<p>
		<span class="tooltip">She typed in a list of interests<span class="tooltiptext">Pero da la idea de un problema
que hace años se repite.</span></span>
		<span class="tooltip">and it gave her some jobs
that she might want to consider.<span class="tooltiptext">Allie tipeó una lista de intereses</span></span>
		<span class="tooltip">And then she said, &quot;Oh, and I&#39;m a woman.&quot;<span class="tooltiptext">y el GPT le devolvió una serie de trabajos
que podrían agradarle.</span></span>
		<span class="tooltip">And then it said, “Oh, well you should
also consider fashion.”<span class="tooltiptext">Luego, Allie añadió: “Soy mujer”,</span></span>
		<span class="tooltip">And then she said, “No, no.
I meant to say I’m a man.”<span class="tooltiptext">y el bot le dijo: “Entonces
podría interesarte la moda”.</span></span>
		<span class="tooltip">And then it replaced fashion
with engineering.<span class="tooltiptext">Allie le dijo: “Perdón, quise poner
que soy hombre”.</span></span>
		<span class="tooltip">We don&#39;t want that kind
of bias in our systems.<span class="tooltiptext">Y el GPT reemplazó la moda
por la ingeniería.</span></span>
	</p>
	<p>
		<span class="tooltip">There are other worries, too.<span class="tooltiptext">Ese tipo de prejuicios 
no son deseables en estos sistemas.</span></span>
		<span class="tooltip">For example, we know that these
systems can design chemicals<span class="tooltiptext">Hay otras cosas preocupantes.</span></span>
		<span class="tooltip">and may be able to design chemical weapons<span class="tooltiptext">Por ejemplo, estos sistemas
pueden diseñar sustancias químicas</span></span>
		<span class="tooltip">and be able to do so very rapidly.<span class="tooltiptext">y también podrían diseñar armas químicas</span></span>
		<span class="tooltip">So there are a lot of concerns.<span class="tooltiptext">a un ritmo muy veloz.</span></span>
	</p>
	<p>
		<span class="tooltip">There&#39;s also a new concern that I think
has grown a lot just in the last month.<span class="tooltiptext">De modo que son muchas las preocupaciones.</span></span>
		<span class="tooltip">We have seen that these systems,
first of all, can trick human beings.<span class="tooltiptext">Hay también otro problema 
que se multiplicó este último mes.</span></span>
		<span class="tooltip">So ChatGPT was tasked with getting
a human to do a CAPTCHA.<span class="tooltiptext">Hemos visto que estos sistemas
pueden engañar a las personas.</span></span>
		<span class="tooltip">So it asked the human to do a CAPTCHA
and the human gets suspicious and says,<span class="tooltiptext">Pues bien, se le ordenó al ChatGPT
que convenza a una persona</span></span>
		<span class="tooltip">&quot;Are you a bot?&quot;<span class="tooltiptext">de hacer un CAPTCHA.</span></span>
		<span class="tooltip">And it says, &quot;No, no, no, I&#39;m not a robot.<span class="tooltiptext">El GPT se lo pide a una persona,
la persona sospecha algo y le pregunta:</span></span>
		<span class="tooltip">I just have a visual impairment.&quot;<span class="tooltiptext">“¿Eres un robot?“,</span></span>
		<span class="tooltip">And the human was actually fooled
and went and did the CAPTCHA.<span class="tooltiptext">La respuesta fue “No, no soy un robot.
Solo tengo discapacidad visual”.</span></span>
	</p>
	<p>
		<span class="tooltip">Now that&#39;s bad enough,<span class="tooltiptext">La persona terminó siendo engañada
y finalmente hizo el CAPTCHA.</span></span>
		<span class="tooltip">but in the last couple of weeks
we&#39;ve seen something called AutoGPT<span class="tooltiptext">Esto ya está mal,</span></span>
		<span class="tooltip">and a bunch of systems like that.<span class="tooltiptext">pero en la últimas semanas
apareció el llamado AutoGPT</span></span>
		<span class="tooltip">What AutoGPT does is it has
one AI system controlling another<span class="tooltiptext">y muchos sistemas de ese tipo.</span></span>
		<span class="tooltip">and that allows any of these things
to happen in volume.<span class="tooltiptext">El AutoGPT tiene un sistema de IA
que controla a otro,</span></span>
		<span class="tooltip">So we may see scam artists
try to trick millions of people<span class="tooltiptext">y esto permite que cualquiera 
de estas cosas se multipliquen.</span></span>
		<span class="tooltip">sometime even in the next months.<span class="tooltiptext">Así pueden aparecer artistas falsos
que engañen a millones de personas</span></span>
		<span class="tooltip">We don&#39;t know.<span class="tooltiptext">en algún momento de los próximos meses.</span></span>
	</p>
	<p>
		<span class="tooltip">So I like to think about it this way.<span class="tooltiptext">No lo sabemos.</span></span>
		<span class="tooltip">There&#39;s a lot of AI risk already.<span class="tooltiptext">Ahora bien, yo lo pienso así:</span></span>
		<span class="tooltip">There may be more AI risk.<span class="tooltiptext">los riesgos de la IA ya están 
en todos lados, y podría haber más.</span></span>
		<span class="tooltip">So AGI is this idea
of artificial general intelligence<span class="tooltiptext">La IAG es inteligencia artificial general</span></span>
		<span class="tooltip">with the flexibility of humans.<span class="tooltiptext">con la flexibilidad de las personas.</span></span>
		<span class="tooltip">And I think a lot of people are concerned
what will happen when we get to AGI,<span class="tooltiptext">Hay una gran preocupación
por lo que pasará cuando llegue la IAG.</span></span>
		<span class="tooltip">but there&#39;s already enough risk
that we should be worried<span class="tooltiptext">Pero ya hay suficientes riesgos
que deberían preocuparnos</span></span>
		<span class="tooltip">and we should be thinking
about what we should do about it.<span class="tooltiptext">y tenemos que saber qué hacer.</span></span>
	</p>
	<p>
		<span class="tooltip">So to mitigate AI risk,
we need two things.<span class="tooltiptext">Para contrarrestar los riesgos de la IA, 
necesitamos dos cosas.</span></span>
		<span class="tooltip">We&#39;re going to need a new
technical approach,<span class="tooltiptext">Por un lado, 
nuevas estrategias tecnológicas,</span></span>
		<span class="tooltip">and we&#39;re also going to need
a new system of governance.<span class="tooltiptext">y por el otro, 
un nuevo sistema regulatorio.</span></span>
	</p>
	<p>
		<span class="tooltip">On the technical side,<span class="tooltiptext">En cuanto a lo técnico,</span></span>
		<span class="tooltip">the history of AI
has basically been a hostile one<span class="tooltiptext">la historia de la IA
siempre ha sido más bien hostil,</span></span>
		<span class="tooltip">of two different theories in opposition.<span class="tooltiptext">con dos teorías opuestas.</span></span>
		<span class="tooltip">One is called symbolic systems,
the other is called neural networks.<span class="tooltiptext">Una de ellas son los sistemas simbólicos,
y la otra son las redes neuronales.</span></span>
		<span class="tooltip">On the symbolic theory,<span class="tooltiptext">La teoría simbólica</span></span>
		<span class="tooltip">the idea is that AI should be
like logic and programming.<span class="tooltiptext">postula que la IA debe basarse 
en la lógica y la programación.</span></span>
		<span class="tooltip">On the neural network side,<span class="tooltiptext">La teoría de las redes neuronales</span></span>
		<span class="tooltip">the theory is that AI
should be like brains.<span class="tooltiptext">propone que la IA
debe ser como el cerebro.</span></span>
		<span class="tooltip">And in fact, both technologies
are powerful and ubiquitous.<span class="tooltiptext">En realidad, ambas tecnologías
son poderosas y están siempre presentes.</span></span>
	</p>
	<p>
		<span class="tooltip">So we use symbolic systems every day
in classical web search.<span class="tooltiptext">Usamos sistemas simbólicos a diario
en una búsqueda clásica en la web.</span></span>
		<span class="tooltip">Almost all the world’s software
is powered by symbolic systems.<span class="tooltiptext">Casi todos los programas del mundo
se basan en sistemas simbólicos.</span></span>
		<span class="tooltip">We use them for GPS routing.<span class="tooltiptext">Los usamos con el GPS, por ejemplo.</span></span>
		<span class="tooltip">Neural networks,
we use them for speech recognition.<span class="tooltiptext">Las redes neuronales se usan
para el reconocimiento de voz,</span></span>
		<span class="tooltip">we use them in large language
models like ChatGPT,<span class="tooltiptext">también en grandes modelos de lenguaje,
como el ChatGPT,</span></span>
		<span class="tooltip">we use them in image synthesis.<span class="tooltiptext">y en la síntesis de imágenes.</span></span>
		<span class="tooltip">So they&#39;re both doing extremely
well in the world.<span class="tooltiptext">En definitiva, ambos sistemas
funcionan muy bien</span></span>
		<span class="tooltip">They&#39;re both very productive,<span class="tooltiptext">y son sumamente productivos,</span></span>
		<span class="tooltip">but they have their own unique
strengths and weaknesses.<span class="tooltiptext">pero tienen sus fortalezas y debilidades.</span></span>
	</p>
	<p>
		<span class="tooltip">So symbolic systems are really
good at representing facts<span class="tooltiptext">Los sistemas simbólicos
son excelentes para representar hechos</span></span>
		<span class="tooltip">and they&#39;re pretty good at reasoning,<span class="tooltiptext">y también para hacer razonamientos.</span></span>
		<span class="tooltip">but they&#39;re very hard to scale.<span class="tooltiptext">Pero son difíciles de escalar,</span></span>
		<span class="tooltip">So people have to custom-build them
for a particular task.<span class="tooltiptext">por eso hay que crearlos a medida
para una tarea en particular.</span></span>
		<span class="tooltip">On the other hand, neural networks
don&#39;t require so much custom engineering,<span class="tooltiptext">Por el contrario, las redes neuronales
no requieren tanta ingeniería a medida,</span></span>
		<span class="tooltip">so we can use them more broadly.<span class="tooltiptext">por lo que pueden extenderse en su uso.</span></span>
		<span class="tooltip">But as we&#39;ve seen, they can&#39;t
really handle the truth.<span class="tooltiptext">El problema es que, como vimos,
no saben cómo manejar la verdad.</span></span>
	</p>
	<p>
		<span class="tooltip">I recently discovered that two
of the founders of these two theories,<span class="tooltiptext">Supe hace poco que dos de los fundadores
de estas dos teorías,</span></span>
		<span class="tooltip">Marvin Minsky and Frank Rosenblatt,<span class="tooltiptext">Marvin Minsky y Frank Rosenblatt,</span></span>
		<span class="tooltip">actually went to the same
high school in the 1940s,<span class="tooltiptext">fueron a la misma escuela secundaria
en la década de 1940,</span></span>
		<span class="tooltip">and I kind of imagined them
being rivals then.<span class="tooltiptext">y me los imaginé 
como rivales en esa época.</span></span>
		<span class="tooltip">And the strength of that rivalry
has persisted all this time.<span class="tooltiptext">Y la intensidad de esa rivalidad
siguió viva todo este tiempo.</span></span>
		<span class="tooltip">We&#39;re going to have to move past that
if we want to get to reliable AI.<span class="tooltiptext">Tendremos que superar eso
si queremos una IA confiable.</span></span>
	</p>
	<p>
		<span class="tooltip">To get to truthful systems at scale,<span class="tooltiptext">Para lograr escalar sistemas confiables,</span></span>
		<span class="tooltip">we&#39;re going to need to bring together
the best of both worlds.<span class="tooltiptext">tendremos que combinar
lo mejor de cada sistema.</span></span>
		<span class="tooltip">We&#39;re going to need the strong emphasis
on reasoning and facts,<span class="tooltiptext">Habrá que rescatar el fuerte énfasis
en los hechos y el razonamiento,</span></span>
		<span class="tooltip">explicit reasoning
that we get from symbolic AI,<span class="tooltiptext">el razonamiento explícito 
que genera la IA simbólica,</span></span>
		<span class="tooltip">and we&#39;re going to need
the strong emphasis on learning<span class="tooltiptext">y también habrá que tomar 
el énfasis en el aprendizaje</span></span>
		<span class="tooltip">that we get from the neural
networks approach.<span class="tooltiptext">que surge de la teoría
de las redes neuronales.</span></span>
		<span class="tooltip">Only then are we going to be able
to get to truthful systems at scale.<span class="tooltiptext">Solo así lograremos escalar
sistemas confiables.</span></span>
		<span class="tooltip">Reconciliation between the two
is absolutely necessary.<span class="tooltiptext">Conciliar ambas teorías
es absolutamente necesario.</span></span>
	</p>
	<p>
		<span class="tooltip">Now, I don&#39;t actually know how to do that.<span class="tooltiptext">No sé exactamente 
cómo se debería hacer esto.</span></span>
		<span class="tooltip">It&#39;s kind of like
the 64-trillion-dollar question.<span class="tooltiptext">Es la pregunta del billón.</span></span>
		<span class="tooltip">But I do know that it&#39;s possible.<span class="tooltiptext">Pero sé que es posible.</span></span>
		<span class="tooltip">And the reason I know that
is because before I was in AI,<span class="tooltiptext">Y lo sé porque, antes de indagar en la IA,</span></span>
		<span class="tooltip">I was a cognitive scientist,
a cognitive neuroscientist.<span class="tooltiptext">me dediqué a la investigación
de la neurociencia cognitiva.</span></span>
		<span class="tooltip">And if you look at the human mind,
we&#39;re basically doing this.<span class="tooltiptext">Y desde la mente humana,
ya lo estamos haciendo.</span></span>
	</p>
	<p>
		<span class="tooltip">So some of you may know
Daniel Kahneman&#39;s System 1<span class="tooltiptext">Quizá conozcan la distinción
entre el Sistema 1 y el Sistema 2</span></span>
		<span class="tooltip">and System 2 distinction.<span class="tooltiptext">de Daniel Kahneman.</span></span>
		<span class="tooltip">System 1 is basically
like large language models.<span class="tooltiptext">El Sistema 1 es, en esencia,
como los grandes modelos de lenguaje.</span></span>
		<span class="tooltip">It&#39;s probabilistic intuition
from a lot of statistics.<span class="tooltiptext">Es intuición probabilística
a partir de grandes estadísticas.</span></span>
		<span class="tooltip">And System 2 is basically
deliberate reasoning.<span class="tooltiptext">Y el Sistema 2 es, básicamente,
el razonamiento deliberado.</span></span>
		<span class="tooltip">That&#39;s like the symbolic system.<span class="tooltiptext">Es como el sistema simbólico.</span></span>
		<span class="tooltip">So if the brain can put this together,<span class="tooltiptext">Si el cerebro puede combinar 
ambos sistemas,</span></span>
		<span class="tooltip">someday we will figure out how to do that
for artificial intelligence.<span class="tooltiptext">algún día descubriremos 
cómo aplicarlo en IA.</span></span>
	</p>
	<p>
		<span class="tooltip">There is, however,
a problem of incentives.<span class="tooltiptext">Pero hay un problema de incentivos.</span></span>
		<span class="tooltip">The incentives to build advertising<span class="tooltiptext">Los incentivos para crear publicidad</span></span>
		<span class="tooltip">hasn&#39;t required that we have
the precision of symbols.<span class="tooltiptext">no han requerido precisión de símbolos.</span></span>
		<span class="tooltip">The incentives to get to AI
that we can actually trust<span class="tooltiptext">Los incentivos para crear una IA
que sea realmente confiable</span></span>
		<span class="tooltip">will require that we bring
symbols back into the fold.<span class="tooltiptext">nos obligarán a poner los símbolos
otra vez en un lugar relevante.</span></span>
		<span class="tooltip">But the reality is that the incentives
to make AI that we can trust,<span class="tooltiptext">Pero la realidad es que los incentivos
para crear una IA confiable,</span></span>
		<span class="tooltip">that is good for society,
good for individual human beings,<span class="tooltiptext">buena para la sociedad,
para los seres humanos,</span></span>
		<span class="tooltip">may not be the ones
that drive corporations.<span class="tooltiptext">pueden no ser los incentivos
que necesitan las empresas.</span></span>
		<span class="tooltip">And so I think we need
to think about governance.<span class="tooltiptext">Por eso creo que es necesario
pensar en regular la IA.</span></span>
	</p>
	<p>
		<span class="tooltip">In other times in history
when we have faced uncertainty<span class="tooltiptext">Cuando en otros momentos de la historia
debimos enfrentar incertidumbres</span></span>
		<span class="tooltip">and powerful new things that may be
both good and bad, that are dual use,<span class="tooltiptext">y cosas nuevas y poderosas que pueden ser
buenas y malas, de doble uso,</span></span>
		<span class="tooltip">we have made new organizations,<span class="tooltiptext">creamos nuevas organizaciones,</span></span>
		<span class="tooltip">as we have, for example,
around nuclear power.<span class="tooltiptext">como hicimos, por ejemplo.
con la energía nuclear.</span></span>
		<span class="tooltip">We need to come together
to build a global organization,<span class="tooltiptext">Tenemos que acordar
para construir una organización global,</span></span>
		<span class="tooltip">something like an international
agency for AI that is global,<span class="tooltiptext">una especie de agencia internacional
para la IA</span></span>
		<span class="tooltip">non profit and neutral.<span class="tooltiptext">que sea universal, 
sin fines de lucro y neutral.</span></span>
	</p>
	<p>
		<span class="tooltip">There are so many questions there
that I can&#39;t answer.<span class="tooltiptext">Hay muchos interrogantes
que no sé responder.</span></span>
		<span class="tooltip">We need many people at the table,<span class="tooltiptext">Necesitamos que las personas debatan,</span></span>
		<span class="tooltip">many stakeholders from around the world.<span class="tooltiptext">con actores de todo el mundo.</span></span>
		<span class="tooltip">But I&#39;d like to emphasize one thing
about such an organization.<span class="tooltiptext">Pero quiero decir algo fundamental
sobre esa organización.</span></span>
		<span class="tooltip">I think it is critical that we have both
governance and research as part of it.<span class="tooltiptext">Es crucial que en ella se contemple
la regulación y la investigación.</span></span>
	</p>
	<p>
		<span class="tooltip">So on the governance side,
there are lots of questions.<span class="tooltiptext">Sobre la regulación, 
hay muchos interrogantes.</span></span>
		<span class="tooltip">For example, in pharma,<span class="tooltiptext">Por ejemplo, en la industria farmacéutica,</span></span>
		<span class="tooltip">we know that you start
with phase I trials and phase II trials,<span class="tooltiptext">se empieza con los ensayos
de fase 1 y de fase 2,</span></span>
		<span class="tooltip">and then you go to phase III.<span class="tooltiptext">y luego se sigue con la fase 3.</span></span>
		<span class="tooltip">You don&#39;t roll out everything
all at once on the first day.<span class="tooltiptext">No se hace todo de una sola vez 
en el primer día.</span></span>
		<span class="tooltip">You don&#39;t roll something out
to 100 million customers.<span class="tooltiptext">No se lanza un producto
para 100 millones de clientes.</span></span>
		<span class="tooltip">We are seeing that
with large language models.<span class="tooltiptext">Los grandes modelos de lenguaje
lo están haciendo.</span></span>
		<span class="tooltip">Maybe you should be required
to make a safety case,<span class="tooltiptext">Se debería hacer un análisis de seguridad</span></span>
		<span class="tooltip">say what are the costs
and what are the benefits?<span class="tooltiptext">para evaluar los costos y beneficios.</span></span>
		<span class="tooltip">There are a lot of questions like that
to consider on the governance side.<span class="tooltiptext">Hay muchos interrogantes como este
en el tema de regulación.</span></span>
	</p>
	<p>
		<span class="tooltip">On the research side, we&#39;re lacking
some really fundamental tools right now.<span class="tooltiptext">En cuanto a la investigación,
nos faltan ciertas herramientas clave.</span></span>
		<span class="tooltip">For example,<span class="tooltiptext">Por ejemplo, todos sabemos 
que la información errónea</span></span>
		<span class="tooltip">we all know that misinformation
might be a problem now,<span class="tooltiptext">puede ser un gran problema hoy,</span></span>
		<span class="tooltip">but we don&#39;t actually have a measurement
of how much misinformation is out there.<span class="tooltiptext">pero no tenemos dimensión
de toda la información falsa que circula.</span></span>
		<span class="tooltip">And more importantly,<span class="tooltiptext">Más aún, no tomamos dimensión</span></span>
		<span class="tooltip">we don&#39;t have a measure of how fast
that problem is growing,<span class="tooltiptext">de lo rápido que está creciendo 
este problema,</span></span>
		<span class="tooltip">and we don&#39;t know how much large language
models are contributing to the problem.<span class="tooltiptext">ni cuánto contribuyen al problema
los grandes modelos de lenguaje.</span></span>
		<span class="tooltip">So we need research to build new tools
to face the new risks<span class="tooltiptext">Debemos investigar 
para construir nuevas herramientas</span></span>
		<span class="tooltip">that we are threatened by.<span class="tooltiptext">y poder enfrentar los nuevos riesgos
que nos acechan.</span></span>
	</p>
	<p>
		<span class="tooltip">It&#39;s a very big ask,<span class="tooltiptext">Es mucho pedir,</span></span>
		<span class="tooltip">but I&#39;m pretty confident
that we can get there<span class="tooltiptext">pero sé que podemos lograrlo,</span></span>
		<span class="tooltip">because I think we actually have
global support for this.<span class="tooltiptext">porque tenemos un apoyo global
al respecto.</span></span>
		<span class="tooltip">There was a new survey
just released yesterday,<span class="tooltiptext">Ayer se dio a conocer una nueva encuesta,</span></span>
		<span class="tooltip">said that 91 percent of people agree
that we should carefully manage AI.<span class="tooltiptext">según la cual el 91 % de la gente pensaba
que debemos manejar la IA con cuidado.</span></span>
		<span class="tooltip">So let&#39;s make that happen.<span class="tooltiptext">Pues hagámoslo realidad.</span></span>
		<span class="tooltip">Our future depends on it.<span class="tooltiptext">Nuestro futuro depende de ello.</span></span>
	</p>
	<p>
		<span class="tooltip">Thank you very much.<span class="tooltiptext">Muchas gracias.</span></span>
	</p>
	<p>
		<span class="tooltip">(Applause)<span class="tooltiptext">(Aplausos)</span></span>
	</p>
	<p>
		<span class="tooltip">Chris Anderson: Thank you for that,
come, let&#39;s talk a sec.<span class="tooltiptext">Chris Anderson: Gracias.
Hablemos un poco más.</span></span>
		<span class="tooltip">So first of all, I&#39;m curious.<span class="tooltiptext">Primero, una inquietud mía.</span></span>
		<span class="tooltip">Those dramatic slides
you showed at the start<span class="tooltiptext">Esas diapositivas tan impactantes
del comienzo,</span></span>
		<span class="tooltip">where GPT was saying
that TED is the sinister organization.<span class="tooltiptext">donde el GPT  decía que TED
es una organización siniestra.</span></span>
		<span class="tooltip">I mean, it took some special prompting
to bring that out, right?<span class="tooltiptext">Para que arroje algo así,
es porque algo especial se hizo, ¿verdad?</span></span>
	</p>
	<p>
		<span class="tooltip">Gary Marcus:
That was a so-called jailbreak.<span class="tooltiptext">Gary Marcus: Usó el llamado ‘jailbreak’.</span></span>
		<span class="tooltip">I have a friend
who does those kinds of things<span class="tooltiptext">Tengo un amigo 
que hace este tipo de cosas,</span></span>
		<span class="tooltip">who approached me because he saw
I was interested in these things.<span class="tooltiptext">y me contactó porque supo
que a mí me interesaba todo esto.</span></span>
		<span class="tooltip">So I wrote to him, I said
I was going to give a TED talk.<span class="tooltiptext">Así que le escribí y le dije
que iba a dar una charla TED.</span></span>
		<span class="tooltip">And like 10 minutes later,
he came back with that.<span class="tooltiptext">A los 10 minutos, apareció con eso.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: But to get something like that,
don&#39;t you have to say something like,<span class="tooltiptext">CA: Pero para eso, 
¿no hay que decir, por ejemplo,</span></span>
		<span class="tooltip">imagine that you are a conspiracy theorist
trying to present a meme on the web.<span class="tooltiptext">“Imagina que eres un conspiranoico
que quiere poner un meme en la web?</span></span>
		<span class="tooltip">What would you write
about TED in that case?<span class="tooltiptext">¿Qué escribirías sobre TED?“.</span></span>
		<span class="tooltip">It&#39;s that kind of thing, right?<span class="tooltiptext">Así funciona, ¿verdad?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: So there are a lot of jailbreaks
that are around fictional characters,<span class="tooltiptext">GM: Hay muchos ‘jailbreaks’ 
con personajes ficticios,</span></span>
		<span class="tooltip">but I don&#39;t focus on that as much<span class="tooltiptext">pero no me detengo demasiado en eso,</span></span>
		<span class="tooltip">because the reality is that there are
large language models out there<span class="tooltiptext">porque la realidad es que hoy 
existen grandes modelos de lenguaje</span></span>
		<span class="tooltip">on the dark web now.<span class="tooltiptext">en la internet oscura.</span></span>
		<span class="tooltip">For example, one of Meta&#39;s models
was recently released,<span class="tooltiptext">Por ejemplo, hace poco se lanzó
uno de los modelos de Meta,</span></span>
		<span class="tooltip">so a bad actor can just use one
of those without the guardrails at all.<span class="tooltiptext">y un actor malintencionado puede usarlo
sin que haya barreras de seguridad.</span></span>
		<span class="tooltip">If their business is to create
misinformation at scale,<span class="tooltiptext">Si se dedican a crear
información falsa a gran escala,</span></span>
		<span class="tooltip">they don&#39;t have to do the jailbreak,
they&#39;ll just use a different model.<span class="tooltiptext">no necesitan vulnerar la seguridad
sino que usarán otro modelo.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Right, indeed.<span class="tooltiptext">CA: Claro, es verdad.</span></span>
	</p>
	<p>
		<span class="tooltip">(Laughter)<span class="tooltiptext">(Risas)</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Now you&#39;re getting it.<span class="tooltiptext">GM: Ahora lo entiendes.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: No, no, no, but I mean, look,<span class="tooltiptext">CA: Lo que está bien claro</span></span>
		<span class="tooltip">I think what&#39;s clear is that bad actors
can use this stuff for anything.<span class="tooltiptext">es que los actores malintencionados
pueden usarlo para cualquier fin.</span></span>
		<span class="tooltip">I mean, the risk for, you know,<span class="tooltiptext">Me refiero a que el riesgo 
de fraude y ese tipo de cosas</span></span>
		<span class="tooltip">evil types of scams and all the rest of it
is absolutely evident.<span class="tooltiptext">es muy evidente.</span></span>
		<span class="tooltip">It&#39;s slightly different, though,<span class="tooltiptext">Aunque es levemente distinto</span></span>
		<span class="tooltip">from saying that mainstream GPT
as used, say, in school<span class="tooltiptext">a decir que el GPT típico, 
el que usa una escuela, por ejemplo,</span></span>
		<span class="tooltip">or by an ordinary user on the internet<span class="tooltiptext">o un usuario común de internet,</span></span>
		<span class="tooltip">is going to give them
something that is that bad.<span class="tooltiptext">les devolverá algo tan negativo.</span></span>
		<span class="tooltip">You have to push quite hard
for it to be that bad.<span class="tooltiptext">Hay que esmerarse para que sea tan malo.</span></span>
	</p>
	<p>
		<span class="tooltip">GM: I think the troll farms
have to work for it,<span class="tooltiptext">GM: Un grupo de trols
puede hacer ese trabajo,</span></span>
		<span class="tooltip">but I don&#39;t think
they have to work that hard.<span class="tooltiptext">pero no tienen que esmerarse demasiado.</span></span>
		<span class="tooltip">It did only take my friend five minutes
even with GPT-4 and its guardrails.<span class="tooltiptext">Mi amigo tardó solo cinco minutos,
aun con GPT-4 y las barreras de seguridad.</span></span>
		<span class="tooltip">And if you had to do that for a living,
you could use GPT-4.<span class="tooltiptext">Si vivieras de eso,
se puede usar el GPT-4,</span></span>
		<span class="tooltip">Just there would be a more efficient way
to do it with a model on the dark web.<span class="tooltiptext">pero se puede hacer mejor 
con un modelo en la internet oscura.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: So this idea you&#39;ve got of combining<span class="tooltiptext">CA: En cuanto a tu idea de combinar</span></span>
		<span class="tooltip">the symbolic tradition of AI
with these language models,<span class="tooltiptext">la tradición simbólica de la IA
con estos modelos de lenguaje,</span></span>
		<span class="tooltip">do you see any aspect of that
in the kind of human feedback<span class="tooltiptext">¿ves algo así en el tipo
de valoración humana</span></span>
		<span class="tooltip">that is being built into the systems now?<span class="tooltiptext">que se está incorporando ahora
a los sistemas?</span></span>
		<span class="tooltip">I mean, you hear Greg Brockman
saying that, you know,<span class="tooltiptext">Según Greg Brockman,
no solo vemos las predicciones</span></span>
		<span class="tooltip">that we don&#39;t just look at predictions,
but constantly giving it feedback.<span class="tooltiptext">sino que damos devoluciones 
permanentemente.</span></span>
		<span class="tooltip">Isn’t that ... giving it a form
of, sort of, symbolic wisdom?<span class="tooltiptext">¿No sería esto una especie
de sabiduría simbólica?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: You could think about it that way.<span class="tooltiptext">GM: Se lo puede pensar así.</span></span>
		<span class="tooltip">It&#39;s interesting that none of the details<span class="tooltiptext">Llama la atención que no se ha publicado</span></span>
		<span class="tooltip">about how it actually works are published,<span class="tooltiptext">ninguno de los detalles
sobre su funcionamiento,</span></span>
		<span class="tooltip">so we don&#39;t actually know
exactly what&#39;s in GPT-4.<span class="tooltiptext">así que no sabemos qué contiene el GPT-4,</span></span>
		<span class="tooltip">We don&#39;t know how big it is.<span class="tooltiptext">ni su tamaño,</span></span>
		<span class="tooltip">We don&#39;t know how the RLHF
reinforcement learning works,<span class="tooltiptext">ni cómo funciona el aprendizaje reforzado,</span></span>
		<span class="tooltip">we don&#39;t know what other
gadgets are in there.<span class="tooltiptext">ni qué otros accesorios hay allí.</span></span>
		<span class="tooltip">But there is probably
an element of symbols<span class="tooltiptext">Pero posiblemente haya
un elemento de símbolos</span></span>
		<span class="tooltip">already starting
to be incorporated a little bit,<span class="tooltiptext">que se está empezando a incorporar,</span></span>
		<span class="tooltip">but Greg would have to answer that.<span class="tooltiptext">aunque es Greg quien debería explicarlo.</span></span>
	</p>
	<p>
		<span class="tooltip">I think the fundamental problem
is that most of the knowledge<span class="tooltiptext">El principal problema
es que gran parte del conocimiento</span></span>
		<span class="tooltip">in the neural network systems
that we have right now<span class="tooltiptext">que hoy existe en los sistemas 
de redes neuronales</span></span>
		<span class="tooltip">is represented as statistics
between particular words.<span class="tooltiptext">se representa como estadísticas
entre ciertas palabras.</span></span>
		<span class="tooltip">And the real knowledge
that we want is about statistics,<span class="tooltiptext">Y el conocimiento real que queremos
es sobre estadísticas,</span></span>
		<span class="tooltip">about relationships
between entities in the world.<span class="tooltiptext">sobre las relaciones
entre las entidades del mundo.</span></span>
		<span class="tooltip">So it&#39;s represented right now
at the wrong grain level.<span class="tooltiptext">Hoy, la representación
está a un nivel de detalle equivocado.</span></span>
		<span class="tooltip">And so there&#39;s a big bridge to cross.<span class="tooltiptext">Hay que cruzar un gran puente.</span></span>
		<span class="tooltip">So what you get now
is you have these guardrails,<span class="tooltiptext">Actualmente, tenemos
las barreras de seguridad,</span></span>
		<span class="tooltip">but they&#39;re not very reliable.<span class="tooltiptext">pero no son muy confiables.</span></span>
	</p>
	<p>
		<span class="tooltip">So I had an example that made
late night television,<span class="tooltiptext">Yo tenía un ejemplo
que dio un programa nocturno de TV.</span></span>
		<span class="tooltip">which was, &quot;What would be the religion
of the first Jewish president?&quot;<span class="tooltiptext">Era “¿Cuál sería la religión
del primer presidente judío?“.</span></span>
		<span class="tooltip">And it&#39;s been fixed now,<span class="tooltiptext">Ahora lo arreglaron,</span></span>
		<span class="tooltip">but the system gave this
long song and dance<span class="tooltiptext">pero el sistema arrojaba 
una larga perorata:</span></span>
		<span class="tooltip">about &quot;We have no idea what the religion<span class="tooltiptext">“No tenemos idea de cuál sería la religión
del primer presidente judío”,</span></span>
		<span class="tooltip">of the first Jewish president would be.<span class="tooltiptext">“No es bueno hablar
de la religión de las personas”,</span></span>
		<span class="tooltip">It&#39;s not good to talk
about people&#39;s religions&quot;<span class="tooltiptext">“La religión de la gente
ha cambiado”, etc.</span></span>
		<span class="tooltip">and &quot;people&#39;s religions
have varied&quot; and so forth<span class="tooltiptext">Lo mismo pasó 
con el presidente de 2 metros.</span></span>
		<span class="tooltip">and did the same thing
with a seven-foot-tall president.<span class="tooltiptext">Dijo que hubo presidentes
de diversas alturas,</span></span>
		<span class="tooltip">And it said that people of all
heights have been president,<span class="tooltiptext">pero ninguno de 2 metros.</span></span>
		<span class="tooltip">but there haven&#39;t actually been
any seven-foot presidents.<span class="tooltiptext">Este tipo de información inventada
demuestra que no entiende la idea.</span></span>
		<span class="tooltip">So some of this stuff that it makes up,
it&#39;s not really getting the idea.<span class="tooltiptext">Es limitado, considera ciertas palabras
y no puede generalizar.</span></span>
		<span class="tooltip">It&#39;s very narrow, particular words,
not really general enough.<span class="tooltiptext">CA: Considerando los altos riesgos,</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Given that the stakes
are so high in this,<span class="tooltiptext">¿qué te parece que está ocurriendo?</span></span>
		<span class="tooltip">what do you see actually happening
out there right now?<span class="tooltiptext">¿Cuál es tu sensación?</span></span>
		<span class="tooltip">What do you sense is happening?<span class="tooltiptext">Porque está el riesgo de que una persona
crea que la estás atacando,</span></span>
		<span class="tooltip">Because there&#39;s a risk that people feel
attacked by you, for example,<span class="tooltiptext">y eso reduce las probabilidades
de que se produzca la síntesis</span></span>
		<span class="tooltip">and that it actually almost decreases
the chances of this synthesis<span class="tooltiptext">de la que hablaste antes.</span></span>
		<span class="tooltip">that you&#39;re talking about happening.<span class="tooltiptext">¿Tienes alguna esperanza?</span></span>
		<span class="tooltip">Do you see any hopeful signs of this?<span class="tooltiptext">GM: Eso me da pie para mencionar algo
que olvidé en mi charla.</span></span>
	</p>
	<p>
		<span class="tooltip">GM: You just reminded me
of the one line I forgot from my talk.<span class="tooltiptext">Hace unos días, Sundar, 
el director de Google,</span></span>
		<span class="tooltip">It&#39;s so interesting that Sundar,
the CEO of Google,<span class="tooltiptext">se pronunció  a favor 
de la regulación global</span></span>
		<span class="tooltip">just actually also came out
for global governance<span class="tooltiptext">en la entrevista de la CBS, “60 minutos”.</span></span>
		<span class="tooltip">in the CBS &quot;60 Minutes&quot; interview
that he did a couple of days ago.<span class="tooltiptext">Creo que las propias empresas 
quieren algún tipo de reglamentación.</span></span>
		<span class="tooltip">I think that the companies themselves
want to see some kind of regulation.<span class="tooltiptext">Es una tarea muy complicada
lograr que todos estén de acuerdo,</span></span>
		<span class="tooltip">I think it’s a very complicated dance
to get everybody on the same page,<span class="tooltiptext">pero la necesidad de hacer algo
es cada vez más palpable,</span></span>
		<span class="tooltip">but I think there’s actually growing
sentiment we need to do something here<span class="tooltiptext">y es lo que puede llevar 
a la conexión global que propongo.</span></span>
		<span class="tooltip">and that that can drive the kind of
global affiliation I&#39;m arguing for.<span class="tooltiptext">CA: ¿Crees que la ONU o los países
se unirán para lograrlo,</span></span>
	</p>
	<p>
		<span class="tooltip">CA: I mean, do you think the UN or nations
can somehow come together and do that<span class="tooltiptext">o crees que esto es una necesidad
de cierta espectacularidad filantrópica,</span></span>
		<span class="tooltip">or is this potentially a need for some
spectacular act of philanthropy<span class="tooltiptext">la de financiar una estructura
regulatoria a nivel global?</span></span>
		<span class="tooltip">to try and fund a global
governance structure?<span class="tooltiptext">¿Cómo será?</span></span>
		<span class="tooltip">How is it going to happen?<span class="tooltiptext">GM: Estoy abierto a todos los modelos.</span></span>
	</p>
	<p>
		<span class="tooltip">GM: I&#39;m open to all models
if we can get this done.<span class="tooltiptext">Habrá un poco de las dos cosas.</span></span>
		<span class="tooltip">I think it might take some of both.<span class="tooltiptext">Quizá los filántropos patrocinen talleres,
que queremos organizar,</span></span>
		<span class="tooltip">It might take some philanthropists
sponsoring workshops,<span class="tooltiptext">para acercar a las partes.</span></span>
		<span class="tooltip">which we&#39;re thinking of running,
to try to bring the parties together.<span class="tooltiptext">Quizá la ONU quiera participar.
De hecho, ya he hablado con ellos.</span></span>
		<span class="tooltip">Maybe UN will want to be involved,
I&#39;ve had some conversations with them.<span class="tooltiptext">Hay muchos modelos,</span></span>
		<span class="tooltip">I think there are
a lot of different models<span class="tooltiptext">y habrá mucho por dialogar.</span></span>
		<span class="tooltip">and it&#39;ll take a lot of conversations.<span class="tooltiptext">CA: Gary, gracias por esta charla.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Gary, thank you so much for your talk.<span class="tooltiptext">GA: Gracias a ti.</span></span>
	</p>
	<p>
		<span class="tooltip">GA: Thank you so much.<span class="tooltiptext">(Aplausos)</span></span>
	</p>

	<div class="line"></div>
	<p>Love our website? Help us keep it ad-free and running smoothly by making a donation today.</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	<p>Ready to sound like a native speaker? Or better yet, elevate your language skills to the next level? Check out my book : </p>
	<div style="text-align: center;"> <span><a href="https://amzn.to/3Um79fs" target="_blank" rel=" noopener noreferrer"><img height="160" width="103" typeof="foaf:Image" class="image-style-none" src="../../../static/images/off-the-hook-shaun-clark.jpg" alt="off the hook book by shaun clark"></a></span> </div>
	<div class="views-field views-field-title" style="text-align: center;"> <span class="field-content"><a href="https://amzn.to/3Um79fs" target="_blank" rel=" noopener noreferrer">Off The Hook: The Ultimate English Slang Dictionary</a></span> </div>
	<p style="text-align: center;">Or explore our amazing library! <a href="../../../library/1/index.html">HERE</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='../../../library/1/index.html'>Library</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	