<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your Spanish reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="Spanish reading, Spanish language learning, instant translations, reading adventure, improve Spanish, improve reading skills, educational platform, Spanish reading resources, online education, Spanish proficiency, learn Spanish, Spanish learning resources, bilingual education, language exchange, study Spanish online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Gary Marcus : The urgent risks of runaway AI — and what to do about them</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>The urgent risks of runaway AI — and what to do about them</h1>
	<h2 class='speaker'>Gary Marcus</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your Spanish speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">Hablaré sobre la posibilidad
de regular la IA global.<span class="tooltiptext">I’m here to talk about the possibility
of global AI governance.</span></span>
		<span class="tooltip">La primera vez que aprendí a codificar
fue a los ocho años,<span class="tooltiptext">I first learned to code
when I was eight years old,</span></span>
		<span class="tooltip">en una computadora de papel.<span class="tooltiptext">on a paper computer,</span></span>
		<span class="tooltip">Desde entonces, 
soy un apasionado de la IA.<span class="tooltiptext">and I&#39;ve been in love with AI ever since.</span></span>
		<span class="tooltip">En la secundaria,<span class="tooltiptext">In high school,</span></span>
		<span class="tooltip">tenía una Commodore 64
y usaba la traducción automática.<span class="tooltiptext">I got myself a Commodore 64
and worked on machine translation.</span></span>
		<span class="tooltip">Fundé un par de empresas de IA,
una de las cuales fue comprada por Uber.<span class="tooltiptext">I built a couple of AI companies,
I sold one of them to Uber.</span></span>
		<span class="tooltip">La IA me fascina, pero ahora me preocupa.<span class="tooltiptext">I love AI, but right now I&#39;m worried.</span></span>
	</p>
	<p>
		<span class="tooltip">Una de mis preocupaciones
es la información errónea,<span class="tooltiptext">One of the things that I’m worried
about is misinformation,</span></span>
		<span class="tooltip">la posibilidad
de que actores malintencionados<span class="tooltiptext">the possibility that bad actors
will make a tsunami of misinformation</span></span>
		<span class="tooltip">generen un tsunami de información errónea<span class="tooltiptext">like we&#39;ve never seen before.</span></span>
		<span class="tooltip">como nunca se vio antes.<span class="tooltiptext">These tools are so good
at making convincing narratives</span></span>
		<span class="tooltip">Estas herramientas saben muy bien
cómo crear narrativas convincentes<span class="tooltiptext">about just about anything.</span></span>
		<span class="tooltip">en prácticamente cualquier tema.<span class="tooltiptext">If you want a narrative
about TED and how it&#39;s dangerous,</span></span>
	</p>
	<p>
		<span class="tooltip">Si queremos una narrativa
sobre lo peligroso que puede ser TED,<span class="tooltiptext">that we&#39;re colluding here
with space aliens,</span></span>
		<span class="tooltip">y que nos confabulamos aquí
con extraterrestres,<span class="tooltiptext">you got it, no problem.</span></span>
		<span class="tooltip">pues se crea, sin problemas.<span class="tooltiptext">I&#39;m of course kidding about TED.</span></span>
		<span class="tooltip">Lo de TED, claro, es una broma.<span class="tooltiptext">I didn&#39;t see any space aliens backstage.</span></span>
		<span class="tooltip">No vi ningún extraterrestre
detrás del escenario.<span class="tooltiptext">But bad actors are going to use
these things to influence elections,</span></span>
		<span class="tooltip">Pero los actores malintencionados 
la usarán para influir en elecciones,<span class="tooltiptext">and they&#39;re going to threaten democracy.</span></span>
		<span class="tooltip">y será una amenaza para la democracia.<span class="tooltiptext">Even when these systems</span></span>
	</p>
	<p>
		<span class="tooltip">Aunque estos sistemas<span class="tooltiptext">aren&#39;t deliberately being used
to make misinformation,</span></span>
		<span class="tooltip">no se usen deliberadamente
para crear información errónea,<span class="tooltiptext">they can&#39;t help themselves.</span></span>
		<span class="tooltip">no pueden evitarlo.<span class="tooltiptext">And the information that they make
is so fluid and so grammatical</span></span>
		<span class="tooltip">Y la información que crean es tan fluida 
y tan perfecta en su gramática<span class="tooltiptext">that even professional editors
sometimes get sucked in</span></span>
		<span class="tooltip">que hasta los editores profesionales
a veces caen en la trampa<span class="tooltiptext">and get fooled by this stuff.</span></span>
		<span class="tooltip">y son presas del engaño.<span class="tooltiptext">And we should be worried.</span></span>
		<span class="tooltip">Y esto es preocupante.<span class="tooltiptext">For example, ChatGPT made up
a sexual harassment scandal</span></span>
	</p>
	<p>
		<span class="tooltip">Por ejemplo, el ChatGPT inventó
un escándalo de acoso sexual<span class="tooltiptext">about an actual professor,</span></span>
		<span class="tooltip">sobre un profesor universitario real,<span class="tooltiptext">and then it provided
evidence for its claim</span></span>
		<span class="tooltip">y, como evidencia del hecho,<span class="tooltiptext">in the form of a fake
&quot;Washington Post&quot; article</span></span>
		<span class="tooltip">citó un artículo falso
del Washington Post,<span class="tooltiptext">that it created a citation to.</span></span>
		<span class="tooltip">creado por el chatbot.<span class="tooltiptext">We should all be worried
about that kind of thing.</span></span>
		<span class="tooltip">Este tipo de cosas
deberían preocuparnos a todos.<span class="tooltiptext">What I have on the right
is an example of a fake narrative</span></span>
	</p>
	<p>
		<span class="tooltip">Aquí, a la derecha, 
vemos un ejemplo de narrativa falsa<span class="tooltiptext">from one of these systems</span></span>
		<span class="tooltip">creada por uno de estos sistemas.<span class="tooltiptext">saying that Elon Musk died
in March of 2018 in a car crash.</span></span>
		<span class="tooltip">Dijo que Elon Musk murió en marzo de 2018
en un accidente de auto.<span class="tooltiptext">We all know that&#39;s not true.</span></span>
		<span class="tooltip">Sabemos que es falso.<span class="tooltiptext">Elon Musk is still here,
the evidence is all around us.</span></span>
		<span class="tooltip">Elon Musk está vivo,
y la evidencia está por todos lados.<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">Almost every day there&#39;s a tweet.</span></span>
	</p>
	<p>
		<span class="tooltip">Tuitea casi todos los días.<span class="tooltiptext">But if you look on the left,
you see what these systems see.</span></span>
		<span class="tooltip">Pero aquí, a la izquierda,
aparece lo que estos sistemas ven:<span class="tooltiptext">Lots and lots of actual news stories
that are in their databases.</span></span>
		<span class="tooltip">muchas noticias reales que se almacenan
en sus bases de datos,<span class="tooltiptext">And in those actual news stories are lots
of little bits of statistical information.</span></span>
		<span class="tooltip">y que contienen gran cantidad
de información estadística.<span class="tooltiptext">Information, for example,</span></span>
		<span class="tooltip">Allí vemos, por ejemplo,<span class="tooltiptext">somebody did die in a car crash
in a Tesla in 2018</span></span>
		<span class="tooltip">que, efectivamente, una persona murió
en un accidente en un Tesla en 2018,<span class="tooltiptext">and it was in the news.</span></span>
		<span class="tooltip">y esto apareció en las noticias.<span class="tooltiptext">And Elon Musk, of course,
is involved in Tesla,</span></span>
		<span class="tooltip">Elon Musk, claramente, 
está vinculado con Tesla,<span class="tooltiptext">but the system doesn&#39;t
understand the relation</span></span>
		<span class="tooltip">pero el sistema no entiende 
la relación entre los hechos<span class="tooltiptext">between the facts that are embodied
in the little bits of sentences.</span></span>
		<span class="tooltip">que se mencionan en las distintas partes
de las oraciones.<span class="tooltiptext">So it&#39;s basically doing auto-complete,</span></span>
	</p>
	<p>
		<span class="tooltip">Básicamente, lo que hace es autocompletar.<span class="tooltiptext">it predicts what
is statistically probable,</span></span>
		<span class="tooltip">Predice lo que es 
estadísticamente probable<span class="tooltiptext">aggregating all of these signals,</span></span>
		<span class="tooltip">reuniendo todas estas señales,<span class="tooltiptext">not knowing how the pieces fit together.</span></span>
		<span class="tooltip">pero no sabe cómo encajan
las partes de la información.<span class="tooltiptext">And it winds up sometimes with things
that are plausible but simply not true.</span></span>
		<span class="tooltip">Y a veces termina produciendo
cosas creíbles pero no verdaderas.<span class="tooltiptext">There are other problems, too, like bias.</span></span>
	</p>
	<p>
		<span class="tooltip">Otro problema con la IA es el sesgo.<span class="tooltiptext">This is a tweet from Allie Miller.</span></span>
		<span class="tooltip">Este tuit es de Allie Miller.<span class="tooltiptext">It&#39;s an example that doesn&#39;t
work two weeks later</span></span>
		<span class="tooltip">Es un ejemplo que no funciona
dos semanas después,<span class="tooltiptext">because they&#39;re constantly changing
things with reinforcement learning</span></span>
		<span class="tooltip">porque los sistemas 
cambian las cosas todo el tiempo<span class="tooltiptext">and so forth.</span></span>
		<span class="tooltip">con el aprendizaje reforzado 
y otras cosas.<span class="tooltiptext">And this was with an earlier version.</span></span>
		<span class="tooltip">Esto fue con una versión previa.<span class="tooltiptext">But it gives you the flavor of a problem
that we&#39;ve seen over and over for years.</span></span>
		<span class="tooltip">Pero da la idea de un problema
que hace años se repite.<span class="tooltiptext">She typed in a list of interests</span></span>
	</p>
	<p>
		<span class="tooltip">Allie tipeó una lista de intereses<span class="tooltiptext">and it gave her some jobs
that she might want to consider.</span></span>
		<span class="tooltip">y el GPT le devolvió una serie de trabajos
que podrían agradarle.<span class="tooltiptext">And then she said, &quot;Oh, and I&#39;m a woman.&quot;</span></span>
		<span class="tooltip">Luego, Allie añadió: “Soy mujer”,<span class="tooltiptext">And then it said, “Oh, well you should
also consider fashion.”</span></span>
		<span class="tooltip">y el bot le dijo: “Entonces
podría interesarte la moda”.<span class="tooltiptext">And then she said, “No, no.
I meant to say I’m a man.”</span></span>
		<span class="tooltip">Allie le dijo: “Perdón, quise poner
que soy hombre”.<span class="tooltiptext">And then it replaced fashion
with engineering.</span></span>
		<span class="tooltip">Y el GPT reemplazó la moda
por la ingeniería.<span class="tooltiptext">We don&#39;t want that kind
of bias in our systems.</span></span>
		<span class="tooltip">Ese tipo de prejuicios 
no son deseables en estos sistemas.<span class="tooltiptext">There are other worries, too.</span></span>
	</p>
	<p>
		<span class="tooltip">Hay otras cosas preocupantes.<span class="tooltiptext">For example, we know that these
systems can design chemicals</span></span>
		<span class="tooltip">Por ejemplo, estos sistemas
pueden diseñar sustancias químicas<span class="tooltiptext">and may be able to design chemical weapons</span></span>
		<span class="tooltip">y también podrían diseñar armas químicas<span class="tooltiptext">and be able to do so very rapidly.</span></span>
		<span class="tooltip">a un ritmo muy veloz.<span class="tooltiptext">So there are a lot of concerns.</span></span>
		<span class="tooltip">De modo que son muchas las preocupaciones.<span class="tooltiptext">There&#39;s also a new concern that I think
has grown a lot just in the last month.</span></span>
	</p>
	<p>
		<span class="tooltip">Hay también otro problema 
que se multiplicó este último mes.<span class="tooltiptext">We have seen that these systems,
first of all, can trick human beings.</span></span>
		<span class="tooltip">Hemos visto que estos sistemas
pueden engañar a las personas.<span class="tooltiptext">So ChatGPT was tasked with getting
a human to do a CAPTCHA.</span></span>
		<span class="tooltip">Pues bien, se le ordenó al ChatGPT
que convenza a una persona<span class="tooltiptext">So it asked the human to do a CAPTCHA
and the human gets suspicious and says,</span></span>
		<span class="tooltip">de hacer un CAPTCHA.<span class="tooltiptext">&quot;Are you a bot?&quot;</span></span>
		<span class="tooltip">El GPT se lo pide a una persona,
la persona sospecha algo y le pregunta:<span class="tooltiptext">And it says, &quot;No, no, no, I&#39;m not a robot.</span></span>
		<span class="tooltip">“¿Eres un robot?“,<span class="tooltiptext">I just have a visual impairment.&quot;</span></span>
		<span class="tooltip">La respuesta fue “No, no soy un robot.
Solo tengo discapacidad visual”.<span class="tooltiptext">And the human was actually fooled
and went and did the CAPTCHA.</span></span>
		<span class="tooltip">La persona terminó siendo engañada
y finalmente hizo el CAPTCHA.<span class="tooltiptext">Now that&#39;s bad enough,</span></span>
	</p>
	<p>
		<span class="tooltip">Esto ya está mal,<span class="tooltiptext">but in the last couple of weeks
we&#39;ve seen something called AutoGPT</span></span>
		<span class="tooltip">pero en la últimas semanas
apareció el llamado AutoGPT<span class="tooltiptext">and a bunch of systems like that.</span></span>
		<span class="tooltip">y muchos sistemas de ese tipo.<span class="tooltiptext">What AutoGPT does is it has
one AI system controlling another</span></span>
		<span class="tooltip">El AutoGPT tiene un sistema de IA
que controla a otro,<span class="tooltiptext">and that allows any of these things
to happen in volume.</span></span>
		<span class="tooltip">y esto permite que cualquiera 
de estas cosas se multipliquen.<span class="tooltiptext">So we may see scam artists
try to trick millions of people</span></span>
		<span class="tooltip">Así pueden aparecer artistas falsos
que engañen a millones de personas<span class="tooltiptext">sometime even in the next months.</span></span>
		<span class="tooltip">en algún momento de los próximos meses.<span class="tooltiptext">We don&#39;t know.</span></span>
		<span class="tooltip">No lo sabemos.<span class="tooltiptext">So I like to think about it this way.</span></span>
	</p>
	<p>
		<span class="tooltip">Ahora bien, yo lo pienso así:<span class="tooltiptext">There&#39;s a lot of AI risk already.</span></span>
		<span class="tooltip">los riesgos de la IA ya están 
en todos lados, y podría haber más.<span class="tooltiptext">There may be more AI risk.</span></span>
		<span class="tooltip">La IAG es inteligencia artificial general<span class="tooltiptext">So AGI is this idea
of artificial general intelligence</span></span>
		<span class="tooltip">con la flexibilidad de las personas.<span class="tooltiptext">with the flexibility of humans.</span></span>
		<span class="tooltip">Hay una gran preocupación
por lo que pasará cuando llegue la IAG.<span class="tooltiptext">And I think a lot of people are concerned
what will happen when we get to AGI,</span></span>
		<span class="tooltip">Pero ya hay suficientes riesgos
que deberían preocuparnos<span class="tooltiptext">but there&#39;s already enough risk
that we should be worried</span></span>
		<span class="tooltip">y tenemos que saber qué hacer.<span class="tooltiptext">and we should be thinking
about what we should do about it.</span></span>
	</p>
	<p>
		<span class="tooltip">Para contrarrestar los riesgos de la IA, 
necesitamos dos cosas.<span class="tooltiptext">So to mitigate AI risk,
we need two things.</span></span>
		<span class="tooltip">Por un lado, 
nuevas estrategias tecnológicas,<span class="tooltiptext">We&#39;re going to need a new
technical approach,</span></span>
		<span class="tooltip">y por el otro, 
un nuevo sistema regulatorio.<span class="tooltiptext">and we&#39;re also going to need
a new system of governance.</span></span>
	</p>
	<p>
		<span class="tooltip">En cuanto a lo técnico,<span class="tooltiptext">On the technical side,</span></span>
		<span class="tooltip">la historia de la IA
siempre ha sido más bien hostil,<span class="tooltiptext">the history of AI
has basically been a hostile one</span></span>
		<span class="tooltip">con dos teorías opuestas.<span class="tooltiptext">of two different theories in opposition.</span></span>
		<span class="tooltip">Una de ellas son los sistemas simbólicos,
y la otra son las redes neuronales.<span class="tooltiptext">One is called symbolic systems,
the other is called neural networks.</span></span>
		<span class="tooltip">La teoría simbólica<span class="tooltiptext">On the symbolic theory,</span></span>
		<span class="tooltip">postula que la IA debe basarse 
en la lógica y la programación.<span class="tooltiptext">the idea is that AI should be
like logic and programming.</span></span>
		<span class="tooltip">La teoría de las redes neuronales<span class="tooltiptext">On the neural network side,</span></span>
		<span class="tooltip">propone que la IA
debe ser como el cerebro.<span class="tooltiptext">the theory is that AI
should be like brains.</span></span>
		<span class="tooltip">En realidad, ambas tecnologías
son poderosas y están siempre presentes.<span class="tooltiptext">And in fact, both technologies
are powerful and ubiquitous.</span></span>
	</p>
	<p>
		<span class="tooltip">Usamos sistemas simbólicos a diario
en una búsqueda clásica en la web.<span class="tooltiptext">So we use symbolic systems every day
in classical web search.</span></span>
		<span class="tooltip">Casi todos los programas del mundo
se basan en sistemas simbólicos.<span class="tooltiptext">Almost all the world’s software
is powered by symbolic systems.</span></span>
		<span class="tooltip">Los usamos con el GPS, por ejemplo.<span class="tooltiptext">We use them for GPS routing.</span></span>
		<span class="tooltip">Las redes neuronales se usan
para el reconocimiento de voz,<span class="tooltiptext">Neural networks,
we use them for speech recognition.</span></span>
		<span class="tooltip">también en grandes modelos de lenguaje,
como el ChatGPT,<span class="tooltiptext">we use them in large language
models like ChatGPT,</span></span>
		<span class="tooltip">y en la síntesis de imágenes.<span class="tooltiptext">we use them in image synthesis.</span></span>
		<span class="tooltip">En definitiva, ambos sistemas
funcionan muy bien<span class="tooltiptext">So they&#39;re both doing extremely
well in the world.</span></span>
		<span class="tooltip">y son sumamente productivos,<span class="tooltiptext">They&#39;re both very productive,</span></span>
		<span class="tooltip">pero tienen sus fortalezas y debilidades.<span class="tooltiptext">but they have their own unique
strengths and weaknesses.</span></span>
	</p>
	<p>
		<span class="tooltip">Los sistemas simbólicos
son excelentes para representar hechos<span class="tooltiptext">So symbolic systems are really
good at representing facts</span></span>
		<span class="tooltip">y también para hacer razonamientos.<span class="tooltiptext">and they&#39;re pretty good at reasoning,</span></span>
		<span class="tooltip">Pero son difíciles de escalar,<span class="tooltiptext">but they&#39;re very hard to scale.</span></span>
		<span class="tooltip">por eso hay que crearlos a medida
para una tarea en particular.<span class="tooltiptext">So people have to custom-build them
for a particular task.</span></span>
		<span class="tooltip">Por el contrario, las redes neuronales
no requieren tanta ingeniería a medida,<span class="tooltiptext">On the other hand, neural networks
don&#39;t require so much custom engineering,</span></span>
		<span class="tooltip">por lo que pueden extenderse en su uso.<span class="tooltiptext">so we can use them more broadly.</span></span>
		<span class="tooltip">El problema es que, como vimos,
no saben cómo manejar la verdad.<span class="tooltiptext">But as we&#39;ve seen, they can&#39;t
really handle the truth.</span></span>
	</p>
	<p>
		<span class="tooltip">Supe hace poco que dos de los fundadores
de estas dos teorías,<span class="tooltiptext">I recently discovered that two
of the founders of these two theories,</span></span>
		<span class="tooltip">Marvin Minsky y Frank Rosenblatt,<span class="tooltiptext">Marvin Minsky and Frank Rosenblatt,</span></span>
		<span class="tooltip">fueron a la misma escuela secundaria
en la década de 1940,<span class="tooltiptext">actually went to the same
high school in the 1940s,</span></span>
		<span class="tooltip">y me los imaginé 
como rivales en esa época.<span class="tooltiptext">and I kind of imagined them
being rivals then.</span></span>
		<span class="tooltip">Y la intensidad de esa rivalidad
siguió viva todo este tiempo.<span class="tooltiptext">And the strength of that rivalry
has persisted all this time.</span></span>
		<span class="tooltip">Tendremos que superar eso
si queremos una IA confiable.<span class="tooltiptext">We&#39;re going to have to move past that
if we want to get to reliable AI.</span></span>
	</p>
	<p>
		<span class="tooltip">Para lograr escalar sistemas confiables,<span class="tooltiptext">To get to truthful systems at scale,</span></span>
		<span class="tooltip">tendremos que combinar
lo mejor de cada sistema.<span class="tooltiptext">we&#39;re going to need to bring together
the best of both worlds.</span></span>
		<span class="tooltip">Habrá que rescatar el fuerte énfasis
en los hechos y el razonamiento,<span class="tooltiptext">We&#39;re going to need the strong emphasis
on reasoning and facts,</span></span>
		<span class="tooltip">el razonamiento explícito 
que genera la IA simbólica,<span class="tooltiptext">explicit reasoning
that we get from symbolic AI,</span></span>
		<span class="tooltip">y también habrá que tomar 
el énfasis en el aprendizaje<span class="tooltiptext">and we&#39;re going to need
the strong emphasis on learning</span></span>
		<span class="tooltip">que surge de la teoría
de las redes neuronales.<span class="tooltiptext">that we get from the neural
networks approach.</span></span>
		<span class="tooltip">Solo así lograremos escalar
sistemas confiables.<span class="tooltiptext">Only then are we going to be able
to get to truthful systems at scale.</span></span>
		<span class="tooltip">Conciliar ambas teorías
es absolutamente necesario.<span class="tooltiptext">Reconciliation between the two
is absolutely necessary.</span></span>
	</p>
	<p>
		<span class="tooltip">No sé exactamente 
cómo se debería hacer esto.<span class="tooltiptext">Now, I don&#39;t actually know how to do that.</span></span>
		<span class="tooltip">Es la pregunta del billón.<span class="tooltiptext">It&#39;s kind of like
the 64-trillion-dollar question.</span></span>
		<span class="tooltip">Pero sé que es posible.<span class="tooltiptext">But I do know that it&#39;s possible.</span></span>
		<span class="tooltip">Y lo sé porque, antes de indagar en la IA,<span class="tooltiptext">And the reason I know that
is because before I was in AI,</span></span>
		<span class="tooltip">me dediqué a la investigación
de la neurociencia cognitiva.<span class="tooltiptext">I was a cognitive scientist,
a cognitive neuroscientist.</span></span>
		<span class="tooltip">Y desde la mente humana,
ya lo estamos haciendo.<span class="tooltiptext">And if you look at the human mind,
we&#39;re basically doing this.</span></span>
	</p>
	<p>
		<span class="tooltip">Quizá conozcan la distinción
entre el Sistema 1 y el Sistema 2<span class="tooltiptext">So some of you may know
Daniel Kahneman&#39;s System 1</span></span>
		<span class="tooltip">de Daniel Kahneman.<span class="tooltiptext">and System 2 distinction.</span></span>
		<span class="tooltip">El Sistema 1 es, en esencia,
como los grandes modelos de lenguaje.<span class="tooltiptext">System 1 is basically
like large language models.</span></span>
		<span class="tooltip">Es intuición probabilística
a partir de grandes estadísticas.<span class="tooltiptext">It&#39;s probabilistic intuition
from a lot of statistics.</span></span>
		<span class="tooltip">Y el Sistema 2 es, básicamente,
el razonamiento deliberado.<span class="tooltiptext">And System 2 is basically
deliberate reasoning.</span></span>
		<span class="tooltip">Es como el sistema simbólico.<span class="tooltiptext">That&#39;s like the symbolic system.</span></span>
		<span class="tooltip">Si el cerebro puede combinar 
ambos sistemas,<span class="tooltiptext">So if the brain can put this together,</span></span>
		<span class="tooltip">algún día descubriremos 
cómo aplicarlo en IA.<span class="tooltiptext">someday we will figure out how to do that
for artificial intelligence.</span></span>
	</p>
	<p>
		<span class="tooltip">Pero hay un problema de incentivos.<span class="tooltiptext">There is, however,
a problem of incentives.</span></span>
		<span class="tooltip">Los incentivos para crear publicidad<span class="tooltiptext">The incentives to build advertising</span></span>
		<span class="tooltip">no han requerido precisión de símbolos.<span class="tooltiptext">hasn&#39;t required that we have
the precision of symbols.</span></span>
		<span class="tooltip">Los incentivos para crear una IA
que sea realmente confiable<span class="tooltiptext">The incentives to get to AI
that we can actually trust</span></span>
		<span class="tooltip">nos obligarán a poner los símbolos
otra vez en un lugar relevante.<span class="tooltiptext">will require that we bring
symbols back into the fold.</span></span>
		<span class="tooltip">Pero la realidad es que los incentivos
para crear una IA confiable,<span class="tooltiptext">But the reality is that the incentives
to make AI that we can trust,</span></span>
		<span class="tooltip">buena para la sociedad,
para los seres humanos,<span class="tooltiptext">that is good for society,
good for individual human beings,</span></span>
		<span class="tooltip">pueden no ser los incentivos
que necesitan las empresas.<span class="tooltiptext">may not be the ones
that drive corporations.</span></span>
		<span class="tooltip">Por eso creo que es necesario
pensar en regular la IA.<span class="tooltiptext">And so I think we need
to think about governance.</span></span>
	</p>
	<p>
		<span class="tooltip">Cuando en otros momentos de la historia
debimos enfrentar incertidumbres<span class="tooltiptext">In other times in history
when we have faced uncertainty</span></span>
		<span class="tooltip">y cosas nuevas y poderosas que pueden ser
buenas y malas, de doble uso,<span class="tooltiptext">and powerful new things that may be
both good and bad, that are dual use,</span></span>
		<span class="tooltip">creamos nuevas organizaciones,<span class="tooltiptext">we have made new organizations,</span></span>
		<span class="tooltip">como hicimos, por ejemplo.
con la energía nuclear.<span class="tooltiptext">as we have, for example,
around nuclear power.</span></span>
		<span class="tooltip">Tenemos que acordar
para construir una organización global,<span class="tooltiptext">We need to come together
to build a global organization,</span></span>
		<span class="tooltip">una especie de agencia internacional
para la IA<span class="tooltiptext">something like an international
agency for AI that is global,</span></span>
		<span class="tooltip">que sea universal, 
sin fines de lucro y neutral.<span class="tooltiptext">non profit and neutral.</span></span>
	</p>
	<p>
		<span class="tooltip">Hay muchos interrogantes
que no sé responder.<span class="tooltiptext">There are so many questions there
that I can&#39;t answer.</span></span>
		<span class="tooltip">Necesitamos que las personas debatan,<span class="tooltiptext">We need many people at the table,</span></span>
		<span class="tooltip">con actores de todo el mundo.<span class="tooltiptext">many stakeholders from around the world.</span></span>
		<span class="tooltip">Pero quiero decir algo fundamental
sobre esa organización.<span class="tooltiptext">But I&#39;d like to emphasize one thing
about such an organization.</span></span>
		<span class="tooltip">Es crucial que en ella se contemple
la regulación y la investigación.<span class="tooltiptext">I think it is critical that we have both
governance and research as part of it.</span></span>
	</p>
	<p>
		<span class="tooltip">Sobre la regulación, 
hay muchos interrogantes.<span class="tooltiptext">So on the governance side,
there are lots of questions.</span></span>
		<span class="tooltip">Por ejemplo, en la industria farmacéutica,<span class="tooltiptext">For example, in pharma,</span></span>
		<span class="tooltip">se empieza con los ensayos
de fase 1 y de fase 2,<span class="tooltiptext">we know that you start
with phase I trials and phase II trials,</span></span>
		<span class="tooltip">y luego se sigue con la fase 3.<span class="tooltiptext">and then you go to phase III.</span></span>
		<span class="tooltip">No se hace todo de una sola vez 
en el primer día.<span class="tooltiptext">You don&#39;t roll out everything
all at once on the first day.</span></span>
		<span class="tooltip">No se lanza un producto
para 100 millones de clientes.<span class="tooltiptext">You don&#39;t roll something out
to 100 million customers.</span></span>
		<span class="tooltip">Los grandes modelos de lenguaje
lo están haciendo.<span class="tooltiptext">We are seeing that
with large language models.</span></span>
		<span class="tooltip">Se debería hacer un análisis de seguridad<span class="tooltiptext">Maybe you should be required
to make a safety case,</span></span>
		<span class="tooltip">para evaluar los costos y beneficios.<span class="tooltiptext">say what are the costs
and what are the benefits?</span></span>
		<span class="tooltip">Hay muchos interrogantes como este
en el tema de regulación.<span class="tooltiptext">There are a lot of questions like that
to consider on the governance side.</span></span>
	</p>
	<p>
		<span class="tooltip">En cuanto a la investigación,
nos faltan ciertas herramientas clave.<span class="tooltiptext">On the research side, we&#39;re lacking
some really fundamental tools right now.</span></span>
		<span class="tooltip">Por ejemplo, todos sabemos 
que la información errónea<span class="tooltiptext">For example,</span></span>
		<span class="tooltip">puede ser un gran problema hoy,<span class="tooltiptext">we all know that misinformation
might be a problem now,</span></span>
		<span class="tooltip">pero no tenemos dimensión
de toda la información falsa que circula.<span class="tooltiptext">but we don&#39;t actually have a measurement
of how much misinformation is out there.</span></span>
		<span class="tooltip">Más aún, no tomamos dimensión<span class="tooltiptext">And more importantly,</span></span>
		<span class="tooltip">de lo rápido que está creciendo 
este problema,<span class="tooltiptext">we don&#39;t have a measure of how fast
that problem is growing,</span></span>
		<span class="tooltip">ni cuánto contribuyen al problema
los grandes modelos de lenguaje.<span class="tooltiptext">and we don&#39;t know how much large language
models are contributing to the problem.</span></span>
		<span class="tooltip">Debemos investigar 
para construir nuevas herramientas<span class="tooltiptext">So we need research to build new tools
to face the new risks</span></span>
		<span class="tooltip">y poder enfrentar los nuevos riesgos
que nos acechan.<span class="tooltiptext">that we are threatened by.</span></span>
	</p>
	<p>
		<span class="tooltip">Es mucho pedir,<span class="tooltiptext">It&#39;s a very big ask,</span></span>
		<span class="tooltip">pero sé que podemos lograrlo,<span class="tooltiptext">but I&#39;m pretty confident
that we can get there</span></span>
		<span class="tooltip">porque tenemos un apoyo global
al respecto.<span class="tooltiptext">because I think we actually have
global support for this.</span></span>
		<span class="tooltip">Ayer se dio a conocer una nueva encuesta,<span class="tooltiptext">There was a new survey
just released yesterday,</span></span>
		<span class="tooltip">según la cual el 91 % de la gente pensaba
que debemos manejar la IA con cuidado.<span class="tooltiptext">said that 91 percent of people agree
that we should carefully manage AI.</span></span>
		<span class="tooltip">Pues hagámoslo realidad.<span class="tooltiptext">So let&#39;s make that happen.</span></span>
		<span class="tooltip">Nuestro futuro depende de ello.<span class="tooltiptext">Our future depends on it.</span></span>
	</p>
	<p>
		<span class="tooltip">Muchas gracias.<span class="tooltiptext">Thank you very much.</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">(Applause)</span></span>
	</p>
	<p>
		<span class="tooltip">Chris Anderson: Gracias.
Hablemos un poco más.<span class="tooltiptext">Chris Anderson: Thank you for that,
come, let&#39;s talk a sec.</span></span>
		<span class="tooltip">Primero, una inquietud mía.<span class="tooltiptext">So first of all, I&#39;m curious.</span></span>
		<span class="tooltip">Esas diapositivas tan impactantes
del comienzo,<span class="tooltiptext">Those dramatic slides
you showed at the start</span></span>
		<span class="tooltip">donde el GPT  decía que TED
es una organización siniestra.<span class="tooltiptext">where GPT was saying
that TED is the sinister organization.</span></span>
		<span class="tooltip">Para que arroje algo así,
es porque algo especial se hizo, ¿verdad?<span class="tooltiptext">I mean, it took some special prompting
to bring that out, right?</span></span>
	</p>
	<p>
		<span class="tooltip">Gary Marcus: Usó el llamado ‘jailbreak’.<span class="tooltiptext">Gary Marcus:
That was a so-called jailbreak.</span></span>
		<span class="tooltip">Tengo un amigo 
que hace este tipo de cosas,<span class="tooltiptext">I have a friend
who does those kinds of things</span></span>
		<span class="tooltip">y me contactó porque supo
que a mí me interesaba todo esto.<span class="tooltiptext">who approached me because he saw
I was interested in these things.</span></span>
		<span class="tooltip">Así que le escribí y le dije
que iba a dar una charla TED.<span class="tooltiptext">So I wrote to him, I said
I was going to give a TED talk.</span></span>
		<span class="tooltip">A los 10 minutos, apareció con eso.<span class="tooltiptext">And like 10 minutes later,
he came back with that.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Pero para eso, 
¿no hay que decir, por ejemplo,<span class="tooltiptext">CA: But to get something like that,
don&#39;t you have to say something like,</span></span>
		<span class="tooltip">“Imagina que eres un conspiranoico
que quiere poner un meme en la web?<span class="tooltiptext">imagine that you are a conspiracy theorist
trying to present a meme on the web.</span></span>
		<span class="tooltip">¿Qué escribirías sobre TED?“.<span class="tooltiptext">What would you write
about TED in that case?</span></span>
		<span class="tooltip">Así funciona, ¿verdad?<span class="tooltiptext">It&#39;s that kind of thing, right?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Hay muchos ‘jailbreaks’ 
con personajes ficticios,<span class="tooltiptext">GM: So there are a lot of jailbreaks
that are around fictional characters,</span></span>
		<span class="tooltip">pero no me detengo demasiado en eso,<span class="tooltiptext">but I don&#39;t focus on that as much</span></span>
		<span class="tooltip">porque la realidad es que hoy 
existen grandes modelos de lenguaje<span class="tooltiptext">because the reality is that there are
large language models out there</span></span>
		<span class="tooltip">en la internet oscura.<span class="tooltiptext">on the dark web now.</span></span>
		<span class="tooltip">Por ejemplo, hace poco se lanzó
uno de los modelos de Meta,<span class="tooltiptext">For example, one of Meta&#39;s models
was recently released,</span></span>
		<span class="tooltip">y un actor malintencionado puede usarlo
sin que haya barreras de seguridad.<span class="tooltiptext">so a bad actor can just use one
of those without the guardrails at all.</span></span>
		<span class="tooltip">Si se dedican a crear
información falsa a gran escala,<span class="tooltiptext">If their business is to create
misinformation at scale,</span></span>
		<span class="tooltip">no necesitan vulnerar la seguridad
sino que usarán otro modelo.<span class="tooltiptext">they don&#39;t have to do the jailbreak,
they&#39;ll just use a different model.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Claro, es verdad.<span class="tooltiptext">CA: Right, indeed.</span></span>
	</p>
	<p>
		<span class="tooltip">(Risas)<span class="tooltiptext">(Laughter)</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Ahora lo entiendes.<span class="tooltiptext">GM: Now you&#39;re getting it.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Lo que está bien claro<span class="tooltiptext">CA: No, no, no, but I mean, look,</span></span>
		<span class="tooltip">es que los actores malintencionados
pueden usarlo para cualquier fin.<span class="tooltiptext">I think what&#39;s clear is that bad actors
can use this stuff for anything.</span></span>
		<span class="tooltip">Me refiero a que el riesgo 
de fraude y ese tipo de cosas<span class="tooltiptext">I mean, the risk for, you know,</span></span>
		<span class="tooltip">es muy evidente.<span class="tooltiptext">evil types of scams and all the rest of it
is absolutely evident.</span></span>
		<span class="tooltip">Aunque es levemente distinto<span class="tooltiptext">It&#39;s slightly different, though,</span></span>
		<span class="tooltip">a decir que el GPT típico, 
el que usa una escuela, por ejemplo,<span class="tooltiptext">from saying that mainstream GPT
as used, say, in school</span></span>
		<span class="tooltip">o un usuario común de internet,<span class="tooltiptext">or by an ordinary user on the internet</span></span>
		<span class="tooltip">les devolverá algo tan negativo.<span class="tooltiptext">is going to give them
something that is that bad.</span></span>
		<span class="tooltip">Hay que esmerarse para que sea tan malo.<span class="tooltiptext">You have to push quite hard
for it to be that bad.</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Un grupo de trols
puede hacer ese trabajo,<span class="tooltiptext">GM: I think the troll farms
have to work for it,</span></span>
		<span class="tooltip">pero no tienen que esmerarse demasiado.<span class="tooltiptext">but I don&#39;t think
they have to work that hard.</span></span>
		<span class="tooltip">Mi amigo tardó solo cinco minutos,
aun con GPT-4 y las barreras de seguridad.<span class="tooltiptext">It did only take my friend five minutes
even with GPT-4 and its guardrails.</span></span>
		<span class="tooltip">Si vivieras de eso,
se puede usar el GPT-4,<span class="tooltiptext">And if you had to do that for a living,
you could use GPT-4.</span></span>
		<span class="tooltip">pero se puede hacer mejor 
con un modelo en la internet oscura.<span class="tooltiptext">Just there would be a more efficient way
to do it with a model on the dark web.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: En cuanto a tu idea de combinar<span class="tooltiptext">CA: So this idea you&#39;ve got of combining</span></span>
		<span class="tooltip">la tradición simbólica de la IA
con estos modelos de lenguaje,<span class="tooltiptext">the symbolic tradition of AI
with these language models,</span></span>
		<span class="tooltip">¿ves algo así en el tipo
de valoración humana<span class="tooltiptext">do you see any aspect of that
in the kind of human feedback</span></span>
		<span class="tooltip">que se está incorporando ahora
a los sistemas?<span class="tooltiptext">that is being built into the systems now?</span></span>
		<span class="tooltip">Según Greg Brockman,
no solo vemos las predicciones<span class="tooltiptext">I mean, you hear Greg Brockman
saying that, you know,</span></span>
		<span class="tooltip">sino que damos devoluciones 
permanentemente.<span class="tooltiptext">that we don&#39;t just look at predictions,
but constantly giving it feedback.</span></span>
		<span class="tooltip">¿No sería esto una especie
de sabiduría simbólica?<span class="tooltiptext">Isn’t that ... giving it a form
of, sort of, symbolic wisdom?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Se lo puede pensar así.<span class="tooltiptext">GM: You could think about it that way.</span></span>
		<span class="tooltip">Llama la atención que no se ha publicado<span class="tooltiptext">It&#39;s interesting that none of the details</span></span>
		<span class="tooltip">ninguno de los detalles
sobre su funcionamiento,<span class="tooltiptext">about how it actually works are published,</span></span>
		<span class="tooltip">así que no sabemos qué contiene el GPT-4,<span class="tooltiptext">so we don&#39;t actually know
exactly what&#39;s in GPT-4.</span></span>
		<span class="tooltip">ni su tamaño,<span class="tooltiptext">We don&#39;t know how big it is.</span></span>
		<span class="tooltip">ni cómo funciona el aprendizaje reforzado,<span class="tooltiptext">We don&#39;t know how the RLHF
reinforcement learning works,</span></span>
		<span class="tooltip">ni qué otros accesorios hay allí.<span class="tooltiptext">we don&#39;t know what other
gadgets are in there.</span></span>
		<span class="tooltip">Pero posiblemente haya
un elemento de símbolos<span class="tooltiptext">But there is probably
an element of symbols</span></span>
		<span class="tooltip">que se está empezando a incorporar,<span class="tooltiptext">already starting
to be incorporated a little bit,</span></span>
		<span class="tooltip">aunque es Greg quien debería explicarlo.<span class="tooltiptext">but Greg would have to answer that.</span></span>
	</p>
	<p>
		<span class="tooltip">El principal problema
es que gran parte del conocimiento<span class="tooltiptext">I think the fundamental problem
is that most of the knowledge</span></span>
		<span class="tooltip">que hoy existe en los sistemas 
de redes neuronales<span class="tooltiptext">in the neural network systems
that we have right now</span></span>
		<span class="tooltip">se representa como estadísticas
entre ciertas palabras.<span class="tooltiptext">is represented as statistics
between particular words.</span></span>
		<span class="tooltip">Y el conocimiento real que queremos
es sobre estadísticas,<span class="tooltiptext">And the real knowledge
that we want is about statistics,</span></span>
		<span class="tooltip">sobre las relaciones
entre las entidades del mundo.<span class="tooltiptext">about relationships
between entities in the world.</span></span>
		<span class="tooltip">Hoy, la representación
está a un nivel de detalle equivocado.<span class="tooltiptext">So it&#39;s represented right now
at the wrong grain level.</span></span>
		<span class="tooltip">Hay que cruzar un gran puente.<span class="tooltiptext">And so there&#39;s a big bridge to cross.</span></span>
		<span class="tooltip">Actualmente, tenemos
las barreras de seguridad,<span class="tooltiptext">So what you get now
is you have these guardrails,</span></span>
		<span class="tooltip">pero no son muy confiables.<span class="tooltiptext">but they&#39;re not very reliable.</span></span>
	</p>
	<p>
		<span class="tooltip">Yo tenía un ejemplo
que dio un programa nocturno de TV.<span class="tooltiptext">So I had an example that made
late night television,</span></span>
		<span class="tooltip">Era “¿Cuál sería la religión
del primer presidente judío?“.<span class="tooltiptext">which was, &quot;What would be the religion
of the first Jewish president?&quot;</span></span>
		<span class="tooltip">Ahora lo arreglaron,<span class="tooltiptext">And it&#39;s been fixed now,</span></span>
		<span class="tooltip">pero el sistema arrojaba 
una larga perorata:<span class="tooltiptext">but the system gave this
long song and dance</span></span>
		<span class="tooltip">“No tenemos idea de cuál sería la religión
del primer presidente judío”,<span class="tooltiptext">about &quot;We have no idea what the religion</span></span>
		<span class="tooltip">“No es bueno hablar
de la religión de las personas”,<span class="tooltiptext">of the first Jewish president would be.</span></span>
		<span class="tooltip">“La religión de la gente
ha cambiado”, etc.<span class="tooltiptext">It&#39;s not good to talk
about people&#39;s religions&quot;</span></span>
		<span class="tooltip">Lo mismo pasó 
con el presidente de 2 metros.<span class="tooltiptext">and &quot;people&#39;s religions
have varied&quot; and so forth</span></span>
		<span class="tooltip">Dijo que hubo presidentes
de diversas alturas,<span class="tooltiptext">and did the same thing
with a seven-foot-tall president.</span></span>
		<span class="tooltip">pero ninguno de 2 metros.<span class="tooltiptext">And it said that people of all
heights have been president,</span></span>
		<span class="tooltip">Este tipo de información inventada
demuestra que no entiende la idea.<span class="tooltiptext">but there haven&#39;t actually been
any seven-foot presidents.</span></span>
		<span class="tooltip">Es limitado, considera ciertas palabras
y no puede generalizar.<span class="tooltiptext">So some of this stuff that it makes up,
it&#39;s not really getting the idea.</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Considerando los altos riesgos,<span class="tooltiptext">It&#39;s very narrow, particular words,
not really general enough.</span></span>
		<span class="tooltip">¿qué te parece que está ocurriendo?<span class="tooltiptext">CA: Given that the stakes
are so high in this,</span></span>
		<span class="tooltip">¿Cuál es tu sensación?<span class="tooltiptext">what do you see actually happening
out there right now?</span></span>
		<span class="tooltip">Porque está el riesgo de que una persona
crea que la estás atacando,<span class="tooltiptext">What do you sense is happening?</span></span>
		<span class="tooltip">y eso reduce las probabilidades
de que se produzca la síntesis<span class="tooltiptext">Because there&#39;s a risk that people feel
attacked by you, for example,</span></span>
		<span class="tooltip">de la que hablaste antes.<span class="tooltiptext">and that it actually almost decreases
the chances of this synthesis</span></span>
		<span class="tooltip">¿Tienes alguna esperanza?<span class="tooltiptext">that you&#39;re talking about happening.</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Eso me da pie para mencionar algo
que olvidé en mi charla.<span class="tooltiptext">Do you see any hopeful signs of this?</span></span>
		<span class="tooltip">Hace unos días, Sundar, 
el director de Google,<span class="tooltiptext">GM: You just reminded me
of the one line I forgot from my talk.</span></span>
		<span class="tooltip">se pronunció  a favor 
de la regulación global<span class="tooltiptext">It&#39;s so interesting that Sundar,
the CEO of Google,</span></span>
		<span class="tooltip">en la entrevista de la CBS, “60 minutos”.<span class="tooltiptext">just actually also came out
for global governance</span></span>
		<span class="tooltip">Creo que las propias empresas 
quieren algún tipo de reglamentación.<span class="tooltiptext">in the CBS &quot;60 Minutes&quot; interview
that he did a couple of days ago.</span></span>
		<span class="tooltip">Es una tarea muy complicada
lograr que todos estén de acuerdo,<span class="tooltiptext">I think that the companies themselves
want to see some kind of regulation.</span></span>
		<span class="tooltip">pero la necesidad de hacer algo
es cada vez más palpable,<span class="tooltiptext">I think it’s a very complicated dance
to get everybody on the same page,</span></span>
		<span class="tooltip">y es lo que puede llevar 
a la conexión global que propongo.<span class="tooltiptext">but I think there’s actually growing
sentiment we need to do something here</span></span>
	</p>
	<p>
		<span class="tooltip">CA: ¿Crees que la ONU o los países
se unirán para lograrlo,<span class="tooltiptext">and that that can drive the kind of
global affiliation I&#39;m arguing for.</span></span>
		<span class="tooltip">o crees que esto es una necesidad
de cierta espectacularidad filantrópica,<span class="tooltiptext">CA: I mean, do you think the UN or nations
can somehow come together and do that</span></span>
		<span class="tooltip">la de financiar una estructura
regulatoria a nivel global?<span class="tooltiptext">or is this potentially a need for some
spectacular act of philanthropy</span></span>
		<span class="tooltip">¿Cómo será?<span class="tooltiptext">to try and fund a global
governance structure?</span></span>
	</p>
	<p>
		<span class="tooltip">GM: Estoy abierto a todos los modelos.<span class="tooltiptext">How is it going to happen?</span></span>
		<span class="tooltip">Habrá un poco de las dos cosas.<span class="tooltiptext">GM: I&#39;m open to all models
if we can get this done.</span></span>
		<span class="tooltip">Quizá los filántropos patrocinen talleres,
que queremos organizar,<span class="tooltiptext">I think it might take some of both.</span></span>
		<span class="tooltip">para acercar a las partes.<span class="tooltiptext">It might take some philanthropists
sponsoring workshops,</span></span>
		<span class="tooltip">Quizá la ONU quiera participar.
De hecho, ya he hablado con ellos.<span class="tooltiptext">which we&#39;re thinking of running,
to try to bring the parties together.</span></span>
		<span class="tooltip">Hay muchos modelos,<span class="tooltiptext">Maybe UN will want to be involved,
I&#39;ve had some conversations with them.</span></span>
		<span class="tooltip">y habrá mucho por dialogar.<span class="tooltiptext">I think there are
a lot of different models</span></span>
	</p>
	<p>
		<span class="tooltip">CA: Gary, gracias por esta charla.<span class="tooltiptext">and it&#39;ll take a lot of conversations.</span></span>
	</p>
	<p>
		<span class="tooltip">GA: Gracias a ti.<span class="tooltiptext">CA: Gary, thank you so much for your talk.</span></span>
	</p>
	<p>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">GA: Thank you so much.</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	