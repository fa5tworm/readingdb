<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Desbloquea la competencia en inglés con nuestra plataforma innovadora basada en las transcripciones de TED Talks. Sumérgete en un contenido cautivador, accede a traducciones instantáneas y únete a una comunidad global de estudiantes. ¡Comienza tu aventura de lectura hoy mismo! | Unlock English proficiency with our innovative platform powered by TED Talk transcripts. Dive into captivating content, access instant translations, and join a global community of learners. Start your reading adventure today!">
		<meta name="keywords" content="lectura en inglés, transcripciones de TED Talks, aprendizaje de idiomas, traducciones instantáneas, comunidad global, aventura de lectura, mejorar inglés, mejorar habilidades de lectura, plataforma educativa, recursos de lectura, educación en línea, English reading, TED Talks transcripts, language learning, instant translations, global community, reading adventure, improve English, improve reading skills, educational platform, reading resources, online education, English proficiency, learn English, English learning resources, bilingual education, language exchange, study English online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Sinan Aral : How we can protect truth in the age of misinformation</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>How we can protect truth in the age of misinformation</h1>
	<h2 class='speaker'>Sinan Aral</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your English speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">So, on April 23 of 2013,<span class="tooltiptext">El 23 de abril de 2013,</span></span>
		<span class="tooltip">the Associated Press
put out the following tweet on Twitter.<span class="tooltiptext">Associated Press 
puso el siguiente tuit en Twitter.</span></span>
		<span class="tooltip">It said, &quot;Breaking news:<span class="tooltiptext">Decía: &quot;Noticia de última hora:</span></span>
		<span class="tooltip">Two explosions at the White House<span class="tooltiptext">dos explosiones en la Casa Blanca.</span></span>
		<span class="tooltip">and Barack Obama has been injured.&quot;<span class="tooltiptext">Barack Obama ha resultado herido&quot;.</span></span>
		<span class="tooltip">This tweet was retweeted 4,000 times
in less than five minutes,<span class="tooltiptext">Este tuit fue retuiteado 4000 veces 
en menos de cinco minutos,</span></span>
		<span class="tooltip">and it went viral thereafter.<span class="tooltiptext">y se hizo viral a partir de ese instante.</span></span>
	</p>
	<p>
		<span class="tooltip">Now, this tweet wasn&#39;t real news
put out by the Associated Press.<span class="tooltiptext">Ahora bien, este tuit 
no fue una noticia verdadera</span></span>
		<span class="tooltip">In fact it was false news, or fake news,<span class="tooltiptext">difundida por la agencia Associated Press.</span></span>
		<span class="tooltip">that was propagated by Syrian hackers<span class="tooltiptext">En realidad, fue una noticia falsa,</span></span>
		<span class="tooltip">that had infiltrated
the Associated Press Twitter handle.<span class="tooltiptext">propagada por &#39;hackers&#39; sirios</span></span>
		<span class="tooltip">Their purpose was to disrupt society,
but they disrupted much more.<span class="tooltiptext">que se habían hecho con el control
del Twitter de Associated Press.</span></span>
		<span class="tooltip">Because automated trading algorithms<span class="tooltiptext">Su objetivo era alterar a la sociedad, 
pero alteraron mucho más,</span></span>
		<span class="tooltip">immediately seized
on the sentiment on this tweet,<span class="tooltiptext">porque los algoritmos 
automatizados de negociación</span></span>
		<span class="tooltip">and began trading based on the potential<span class="tooltiptext">inmediatamente interpretaron
la sensibilidad de este tuit,</span></span>
		<span class="tooltip">that the president of the United States
had been injured or killed<span class="tooltiptext">y comenzaron a operar
en base a la posibilidad</span></span>
		<span class="tooltip">in this explosion.<span class="tooltiptext">de que el presidente de los EE. UU. 
hubiese sido herido o asesinado</span></span>
		<span class="tooltip">And as they started tweeting,<span class="tooltiptext">en esa explosión.</span></span>
		<span class="tooltip">they immediately sent
the stock market crashing,<span class="tooltiptext">Y cuando empezaron a tuitear,</span></span>
		<span class="tooltip">wiping out 140 billion dollars
in equity value in a single day.<span class="tooltiptext">hicieron que el mercado de valores
se desplomara al instante,</span></span>
	</p>
	<p>
		<span class="tooltip">Robert Mueller, special counsel
prosecutor in the United States,<span class="tooltiptext">y se perdieron 140 mil millones de dólares
en valor bursátil en un solo día.</span></span>
		<span class="tooltip">issued indictments
against three Russian companies<span class="tooltiptext">Robert Mueller, consejero 
y fiscal especial de los Estados Unidos,</span></span>
		<span class="tooltip">and 13 Russian individuals<span class="tooltiptext">acusó penalmente a tres compañías rusas</span></span>
		<span class="tooltip">on a conspiracy to defraud
the United States<span class="tooltiptext">y a 13 individuos rusos</span></span>
		<span class="tooltip">by meddling in the 2016
presidential election.<span class="tooltiptext">de conspirar para cometer fraude 
contra los Estados Unidos</span></span>
		<span class="tooltip">And what this indictment tells as a story<span class="tooltiptext">al entrometerse en las elecciones
presidenciales de 2016.</span></span>
		<span class="tooltip">is the story of the Internet
Research Agency,<span class="tooltiptext">Lo que esta acusación deja al descubierto</span></span>
		<span class="tooltip">the shadowy arm of the Kremlin
on social media.<span class="tooltiptext">es la historia de la Agencia
de Investigación de Internet,</span></span>
		<span class="tooltip">During the presidential election alone,<span class="tooltiptext">el oscuro brazo del Kremlin 
en las redes sociales.</span></span>
		<span class="tooltip">the Internet Agency&#39;s efforts<span class="tooltiptext">Solo en las elecciones presidenciales,</span></span>
		<span class="tooltip">reached 126 million people
on Facebook in the United States,<span class="tooltiptext">los intentos de la Agencia de Internet</span></span>
		<span class="tooltip">issued three million individual tweets<span class="tooltiptext">llegaron a 126 millones de personas 
en Facebook en los Estados Unidos,</span></span>
		<span class="tooltip">and 43 hours&#39; worth of YouTube content.<span class="tooltiptext">emitieron tres millones 
de tuits individuales</span></span>
		<span class="tooltip">All of which was fake --<span class="tooltiptext">y 43 horas de contenido de YouTube.</span></span>
		<span class="tooltip">misinformation designed to sow discord
in the US presidential election.<span class="tooltiptext">Todo lo cual era falso,</span></span>
	</p>
	<p>
		<span class="tooltip">A recent study by Oxford University<span class="tooltiptext">desinformación diseñada para meter cizaña
en la elección presidencial de EE. UU.</span></span>
		<span class="tooltip">showed that in the recent
Swedish elections,<span class="tooltiptext">Un estudio reciente
realizado por la Universidad de Oxford</span></span>
		<span class="tooltip">one third of all of the information
spreading on social media<span class="tooltiptext">mostró que en las últimas 
elecciones suecas,</span></span>
		<span class="tooltip">about the election<span class="tooltiptext">un tercio de toda la información
que se difundió en las redes sociales</span></span>
		<span class="tooltip">was fake or misinformation.<span class="tooltiptext">sobre las elecciones</span></span>
	</p>
	<p>
		<span class="tooltip">In addition, these types
of social-media misinformation campaigns<span class="tooltiptext">era falsa o incorrecta.</span></span>
		<span class="tooltip">can spread what has been called
&quot;genocidal propaganda,&quot;<span class="tooltiptext">Además, este tipo de campañas
de desinformación en redes sociales</span></span>
		<span class="tooltip">for instance against
the Rohingya in Burma,<span class="tooltiptext">pueden difundir lo que se ha llamado 
&quot;propaganda genocida&quot;,</span></span>
		<span class="tooltip">triggering mob killings in India.<span class="tooltiptext">por ejemplo contra los rohingya en Burma,</span></span>
	</p>
	<p>
		<span class="tooltip">We studied fake news<span class="tooltiptext">que desencadenó linchamientos en la India.</span></span>
		<span class="tooltip">and began studying it
before it was a popular term.<span class="tooltiptext">Estudiamos las noticias falsas</span></span>
		<span class="tooltip">And we recently published
the largest-ever longitudinal study<span class="tooltiptext">y comenzamos a hacerlo 
antes de que fuera un término popular.</span></span>
		<span class="tooltip">of the spread of fake news online<span class="tooltiptext">Y hemos publicado recientemente el estudio
longitudinal más grande jamás realizado</span></span>
		<span class="tooltip">on the cover of &quot;Science&quot;
in March of this year.<span class="tooltiptext">sobre la difusión
de noticias falsas en línea</span></span>
		<span class="tooltip">We studied all of the verified
true and false news stories<span class="tooltiptext">en la portada de la revista &quot;Science&quot; 
en marzo de este año.</span></span>
		<span class="tooltip">that ever spread on Twitter,<span class="tooltiptext">Estudiamos todas las noticias 
verificadas como verdaderas y falsas</span></span>
		<span class="tooltip">from its inception in 2006 to 2017.<span class="tooltiptext">que se propagaron por Twitter,</span></span>
		<span class="tooltip">And when we studied this information,<span class="tooltiptext">desde su creación en 2006 hasta 2017.</span></span>
		<span class="tooltip">we studied verified news stories<span class="tooltiptext">Y cuando estudiamos esta información,</span></span>
		<span class="tooltip">that were verified by six
independent fact-checking organizations.<span class="tooltiptext">tomamos las noticias
verificadas y revisadas</span></span>
		<span class="tooltip">So we knew which stories were true<span class="tooltiptext">por seis organizaciones
independientes de comprobación de datos.</span></span>
		<span class="tooltip">and which stories were false.<span class="tooltiptext">Así que sabíamos cuáles eran ciertas</span></span>
		<span class="tooltip">We can measure their diffusion,<span class="tooltiptext">y cuáles falsas.</span></span>
		<span class="tooltip">the speed of their diffusion,<span class="tooltiptext">Podemos medir su difusión,</span></span>
		<span class="tooltip">the depth and breadth of their diffusion,<span class="tooltiptext">la velocidad de su difusión,</span></span>
		<span class="tooltip">how many people become entangled
in this information cascade and so on.<span class="tooltiptext">el alcance de su difusión,</span></span>
		<span class="tooltip">And what we did in this paper<span class="tooltiptext">cuántas personas se enredan 
en esta cascada de información, etc.</span></span>
		<span class="tooltip">was we compared the spread of true news
to the spread of false news.<span class="tooltiptext">Y lo que hicimos en esta investigación</span></span>
		<span class="tooltip">And here&#39;s what we found.<span class="tooltiptext">fue comparar la propagación
de noticias verdaderas con las falsas.</span></span>
	</p>
	<p>
		<span class="tooltip">We found that false news
diffused further, faster, deeper<span class="tooltiptext">Y estos son los resultados.</span></span>
		<span class="tooltip">and more broadly than the truth<span class="tooltiptext">Hallamos que una noticia falsa 
llega más lejos, más rápido</span></span>
		<span class="tooltip">in every category of information
that we studied,<span class="tooltiptext">y tiene más alcance que la verdadera</span></span>
		<span class="tooltip">sometimes by an order of magnitude.<span class="tooltiptext">en todas las categorías de información 
que hemos estudiado,</span></span>
		<span class="tooltip">And in fact, false political news
was the most viral.<span class="tooltiptext">a veces en un orden de magnitud.</span></span>
		<span class="tooltip">It diffused further, faster,
deeper and more broadly<span class="tooltiptext">Y las noticias falsas en el ámbito
de la política fueron las más virales.</span></span>
		<span class="tooltip">than any other type of false news.<span class="tooltiptext">Se difunden más lejos, más rápido, 
y tienen mayor alcance</span></span>
		<span class="tooltip">When we saw this,<span class="tooltiptext">que cualquier otro tipo
de noticias falsas.</span></span>
		<span class="tooltip">we were at once worried but also curious.<span class="tooltiptext">Cuando vimos esto,</span></span>
		<span class="tooltip">Why?<span class="tooltiptext">sentimos a la vez
preocupación y curiosidad.</span></span>
		<span class="tooltip">Why does false news travel
so much further, faster, deeper<span class="tooltiptext">¿Por qué?</span></span>
		<span class="tooltip">and more broadly than the truth?<span class="tooltiptext">¿Por qué las noticias falsas llegan
más lejos, más rápido,</span></span>
	</p>
	<p>
		<span class="tooltip">The first hypothesis
that we came up with was,<span class="tooltiptext">y tienen mayor alcance que la verdad?</span></span>
		<span class="tooltip">&quot;Well, maybe people who spread false news
have more followers or follow more people,<span class="tooltiptext">La primera hipótesis 
que se nos ocurrió fue:</span></span>
		<span class="tooltip">or tweet more often,<span class="tooltiptext">&quot;Bueno, tal vez quienes
difunden noticias falsas</span></span>
		<span class="tooltip">or maybe they&#39;re more often &#39;verified&#39;
users of Twitter, with more credibility,<span class="tooltiptext">tienen más seguidores
o siguen a más gente,</span></span>
		<span class="tooltip">or maybe they&#39;ve been on Twitter longer.&quot;<span class="tooltiptext">o tuitean con más frecuencia,</span></span>
		<span class="tooltip">So we checked each one of these in turn.<span class="tooltiptext">o tal vez son más usuarios &#39;verificados&#39;
de Twitter, con más credibilidad,</span></span>
		<span class="tooltip">And what we found
was exactly the opposite.<span class="tooltiptext">o tal vez han estado
en Twitter más tiempo&quot;.</span></span>
		<span class="tooltip">False-news spreaders had fewer followers,<span class="tooltiptext">Así que inspeccionamos
cada uno de estos casos.</span></span>
		<span class="tooltip">followed fewer people, were less active,<span class="tooltiptext">Y lo que encontramos 
fue exactamente lo contrario.</span></span>
		<span class="tooltip">less often &quot;verified&quot;<span class="tooltiptext">Quienes difundían noticias falsas
tenían menos seguidores,</span></span>
		<span class="tooltip">and had been on Twitter
for a shorter period of time.<span class="tooltiptext">seguían a menos gente, eran menos activos,
eran usuarios poco &quot;verificados&quot;</span></span>
		<span class="tooltip">And yet,<span class="tooltiptext">y habían estado en Twitter 
por un período de tiempo más corto.</span></span>
		<span class="tooltip">false news was 70 percent more likely
to be retweeted than the truth,<span class="tooltiptext">Y sin embargo,</span></span>
		<span class="tooltip">controlling for all of these
and many other factors.<span class="tooltiptext">las noticias falsas eran un 70 %
más propensas a ser retuiteadas,</span></span>
	</p>
	<p>
		<span class="tooltip">So we had to come up
with other explanations.<span class="tooltiptext">teniendo en cuenta estos 
y muchos otros factores.</span></span>
		<span class="tooltip">And we devised what we called
a &quot;novelty hypothesis.&quot;<span class="tooltiptext">Así que tuvimos que buscar 
otras explicaciones.</span></span>
		<span class="tooltip">So if you read the literature,<span class="tooltiptext">E ideamos lo que llamamos 
&quot;hipótesis de la novedad&quot;.</span></span>
		<span class="tooltip">it is well known that human attention
is drawn to novelty,<span class="tooltiptext">Si leemos documentaciones sobre el tema,</span></span>
		<span class="tooltip">things that are new in the environment.<span class="tooltiptext">es bien sabido que la atención humana 
se siente atraída por la novedad,</span></span>
		<span class="tooltip">And if you read the sociology literature,<span class="tooltiptext">cosas que son nuevas en el entorno.</span></span>
		<span class="tooltip">you know that we like to share
novel information.<span class="tooltiptext">Y si leemos la literatura sociológica,</span></span>
		<span class="tooltip">It makes us seem like we have access
to inside information,<span class="tooltiptext">veremos que nos gusta compartir 
información novedosa.</span></span>
		<span class="tooltip">and we gain in status
by spreading this kind of information.<span class="tooltiptext">Sentimos que tenemos acceso 
a información privilegiada,</span></span>
	</p>
	<p>
		<span class="tooltip">So what we did was we measured the novelty
of an incoming true or false tweet,<span class="tooltiptext">y ganamos estatus mediante la difusión
de este tipo de información.</span></span>
		<span class="tooltip">compared to the corpus
of what that individual had seen<span class="tooltiptext">Decidimos entonces medir
la novedad de un tuit verdadero o falso,</span></span>
		<span class="tooltip">in the 60 days prior on Twitter.<span class="tooltiptext">en comparación con el corpus 
de lo que esa persona había visto</span></span>
		<span class="tooltip">But that wasn&#39;t enough,
because we thought to ourselves,<span class="tooltiptext">en Twitter los 60 días anteriores.</span></span>
		<span class="tooltip">&quot;Well, maybe false news is more novel
in an information-theoretic sense,<span class="tooltiptext">Pero no fue suficiente, porque pensamos:</span></span>
		<span class="tooltip">but maybe people
don&#39;t perceive it as more novel.&quot;<span class="tooltiptext">&quot;Bueno, quizá las noticias falsas
son más novedosas en un sentido teórico,</span></span>
	</p>
	<p>
		<span class="tooltip">So to understand people&#39;s
perceptions of false news,<span class="tooltiptext">pero tal vez la gente 
no las percibe como más novedosas&quot;.</span></span>
		<span class="tooltip">we looked at the information
and the sentiment<span class="tooltiptext">Así que para entender cómo
la gente percibe las noticias falsas,</span></span>
		<span class="tooltip">contained in the replies
to true and false tweets.<span class="tooltiptext">nos fijamos en la información 
y el componente afectivo</span></span>
		<span class="tooltip">And what we found<span class="tooltiptext">de las respuestas 
a los tuits verdaderos y falsos.</span></span>
		<span class="tooltip">was that across a bunch
of different measures of sentiment --<span class="tooltiptext">Y lo que detectamos</span></span>
		<span class="tooltip">surprise, disgust, fear, sadness,<span class="tooltiptext">fue que, teniendo en cuenta 
un montón de sentimientos diferentes,</span></span>
		<span class="tooltip">anticipation, joy and trust --<span class="tooltiptext">como sorpresa, disgusto, miedo, tristeza,</span></span>
		<span class="tooltip">false news exhibited significantly more
surprise and disgust<span class="tooltiptext">expectativa, alegría y confianza,</span></span>
		<span class="tooltip">in the replies to false tweets.<span class="tooltiptext">las noticias falsas generaron
significativamente más sorpresa y disgusto</span></span>
		<span class="tooltip">And true news exhibited
significantly more anticipation,<span class="tooltiptext">en las respuestas a los falsos tuits.</span></span>
		<span class="tooltip">joy and trust<span class="tooltiptext">Y las noticias verdaderas mostraron
significativamente más expectativas,</span></span>
		<span class="tooltip">in reply to true tweets.<span class="tooltiptext">alegría y confianza</span></span>
		<span class="tooltip">The surprise corroborates
our novelty hypothesis.<span class="tooltiptext">en respuesta a los tuits verdaderos.</span></span>
		<span class="tooltip">This is new and surprising,
and so we&#39;re more likely to share it.<span class="tooltiptext">La sorpresa corrobora 
nuestra hipótesis de la novedad.</span></span>
	</p>
	<p>
		<span class="tooltip">At the same time,
there was congressional testimony<span class="tooltiptext">Esto es nuevo y sorprendente, 
por lo que es más fácil que se comparta.</span></span>
		<span class="tooltip">in front of both houses of Congress
in the United States,<span class="tooltiptext">Al mismo tiempo, 
hubo testimonios ante el Congreso</span></span>
		<span class="tooltip">looking at the role of bots
in the spread of misinformation.<span class="tooltiptext">en las dos cámaras parlamentarias 
de los Estados Unidos</span></span>
		<span class="tooltip">So we looked at this too --<span class="tooltiptext">sobre el papel de los robots 
en la propagación de información errónea.</span></span>
		<span class="tooltip">we used multiple sophisticated
bot-detection algorithms<span class="tooltiptext">Así que consideramos esto también.</span></span>
		<span class="tooltip">to find the bots in our data
and to pull them out.<span class="tooltiptext">Utilizamos múltiples algoritmos 
complejos de rastreo</span></span>
		<span class="tooltip">So we pulled them out,
we put them back in<span class="tooltiptext">para encontrar los robots
en nuestros datos y sacarlos.</span></span>
		<span class="tooltip">and we compared what happens
to our measurement.<span class="tooltiptext">Los sacamos, los volvimos a poner</span></span>
		<span class="tooltip">And what we found was that, yes indeed,<span class="tooltiptext">y comparamos lo que sucede 
con nuestras mediciones.</span></span>
		<span class="tooltip">bots were accelerating
the spread of false news online,<span class="tooltiptext">Descubrimos que, efectivamente,</span></span>
		<span class="tooltip">but they were accelerating
the spread of true news<span class="tooltiptext">los robots aceleraban la propagación
de noticias falsas en línea,</span></span>
		<span class="tooltip">at approximately the same rate.<span class="tooltiptext">pero aceleraban
la propagación de las verdaderas</span></span>
		<span class="tooltip">Which means bots are not responsible<span class="tooltiptext">aproximadamente a la misma velocidad.</span></span>
		<span class="tooltip">for the differential diffusion
of truth and falsity online.<span class="tooltiptext">Lo que significa que los robots
no son los responsables</span></span>
		<span class="tooltip">We can&#39;t abdicate that responsibility,<span class="tooltiptext">de la difusión diferencial 
de la verdad y la mentira en línea.</span></span>
		<span class="tooltip">because we, humans,
are responsible for that spread.<span class="tooltiptext">No podemos renunciar
a esa responsabilidad,</span></span>
	</p>
	<p>
		<span class="tooltip">Now, everything
that I have told you so far,<span class="tooltiptext">porque nosotros, los seres humanos, 
somos responsables de esa propagación.</span></span>
		<span class="tooltip">unfortunately for all of us,<span class="tooltiptext">Ahora bien, todo lo que
les he dicho hasta el momento,</span></span>
		<span class="tooltip">is the good news.<span class="tooltiptext">por desgracia para todos nosotros,</span></span>
	</p>
	<p>
		<span class="tooltip">The reason is because
it&#39;s about to get a whole lot worse.<span class="tooltiptext">es la buena noticia.</span></span>
		<span class="tooltip">And two specific technologies
are going to make it worse.<span class="tooltiptext">La razón es que está 
a punto de ponerse mucho peor.</span></span>
		<span class="tooltip">We are going to see the rise
of a tremendous wave of synthetic media.<span class="tooltiptext">Y dos tecnologías específicas 
van a empeorar la situación.</span></span>
		<span class="tooltip">Fake video, fake audio
that is very convincing to the human eye.<span class="tooltiptext">Vamos a presenciar el aumento
de una tremenda ola de medios sintéticos.</span></span>
		<span class="tooltip">And this will powered by two technologies.<span class="tooltiptext">Video falso, audio falso,
muy convincentes para el ojo humano.</span></span>
	</p>
	<p>
		<span class="tooltip">The first of these is known
as &quot;generative adversarial networks.&quot;<span class="tooltiptext">Y esto será impulsado por dos tecnologías.</span></span>
		<span class="tooltip">This is a machine-learning model
with two networks:<span class="tooltiptext">La primera es conocida como 
&quot;redes de confrontación generativas&quot;.</span></span>
		<span class="tooltip">a discriminator,<span class="tooltiptext">Es un modelo de aprendizaje
automático con dos redes:</span></span>
		<span class="tooltip">whose job it is to determine
whether something is true or false,<span class="tooltiptext">un discriminador,</span></span>
		<span class="tooltip">and a generator,<span class="tooltiptext">cuyo trabajo es determinar 
si algo es verdadero o falso,</span></span>
		<span class="tooltip">whose job it is to generate
synthetic media.<span class="tooltiptext">y un generador,</span></span>
		<span class="tooltip">So the synthetic generator
generates synthetic video or audio,<span class="tooltiptext">cuyo trabajo es generar medios sintéticos.</span></span>
		<span class="tooltip">and the discriminator tries to tell,
&quot;Is this real or is this fake?&quot;<span class="tooltiptext">El generador sintético
genera un video o audio sintético,</span></span>
		<span class="tooltip">And in fact, it is the job
of the generator<span class="tooltiptext">y el discriminador trata de distinguir 
si es verdadero o falso.</span></span>
		<span class="tooltip">to maximize the likelihood
that it will fool the discriminator<span class="tooltiptext">Y, de hecho, el trabajo del generador</span></span>
		<span class="tooltip">into thinking the synthetic
video and audio that it is creating<span class="tooltiptext">es maximizar la probabilidad
de engañar al discriminador</span></span>
		<span class="tooltip">is actually true.<span class="tooltiptext">para que crea que el video
y el audio sintéticos que está creando</span></span>
		<span class="tooltip">Imagine a machine in a hyperloop,<span class="tooltiptext">son realmente ciertos.</span></span>
		<span class="tooltip">trying to get better
and better at fooling us.<span class="tooltiptext">Imaginen una máquina en un Hyperloop,</span></span>
	</p>
	<p>
		<span class="tooltip">This, combined with the second technology,<span class="tooltiptext">que se perfecciona más y más
con el fin de engañarnos.</span></span>
		<span class="tooltip">which is essentially the democratization
of artificial intelligence to the people,<span class="tooltiptext">Esto, combinado con la segunda tecnología,</span></span>
		<span class="tooltip">the ability for anyone,<span class="tooltiptext">que es esencialmente la democratización 
de la inteligencia artificial,</span></span>
		<span class="tooltip">without any background
in artificial intelligence<span class="tooltiptext">la capacidad de cualquier persona,</span></span>
		<span class="tooltip">or machine learning,<span class="tooltiptext">sin ningún tipo de experiencia 
en inteligencia artificial</span></span>
		<span class="tooltip">to deploy these kinds of algorithms
to generate synthetic media<span class="tooltiptext">o aprendizaje automático,</span></span>
		<span class="tooltip">makes it ultimately so much easier
to create videos.<span class="tooltiptext">de implementar este tipo de algoritmos 
para generar los medios sintéticos</span></span>
	</p>
	<p>
		<span class="tooltip">The White House issued
a false, doctored video<span class="tooltiptext">hace que, en última instancia,
sea mucho más fácil crear videos.</span></span>
		<span class="tooltip">of a journalist interacting with an intern
who was trying to take his microphone.<span class="tooltiptext">La Casa Blanca emitió 
el video falso y adulterado</span></span>
		<span class="tooltip">They removed frames from this video<span class="tooltiptext">de una pasante que intentaba 
sacarle el micrófono a un periodista.</span></span>
		<span class="tooltip">in order to make his actions
seem more punchy.<span class="tooltiptext">Eliminaron fotogramas de este video</span></span>
		<span class="tooltip">And when videographers
and stuntmen and women<span class="tooltiptext">para que las acciones del periodista
pareciesen más violentas.</span></span>
		<span class="tooltip">were interviewed
about this type of technique,<span class="tooltiptext">Y cuando camarógrafos y dobles</span></span>
		<span class="tooltip">they said, &quot;Yes, we use this
in the movies all the time<span class="tooltiptext">fueron consultados
acerca de este tipo de técnica,</span></span>
		<span class="tooltip">to make our punches and kicks
look more choppy and more aggressive.&quot;<span class="tooltiptext">dijeron: &quot;Sí, siempre 
lo hacemos en las películas</span></span>
		<span class="tooltip">They then put out this video<span class="tooltiptext">para que nuestros puñetazos y patadas 
parezcan más rápidos y agresivos&quot;.</span></span>
		<span class="tooltip">and partly used it as justification<span class="tooltiptext">Entonces mostraron este video</span></span>
		<span class="tooltip">to revoke Jim Acosta,
the reporter&#39;s, press pass<span class="tooltiptext">y lo utilizaron parcialmente como excusa</span></span>
		<span class="tooltip">from the White House.<span class="tooltiptext">para denegar el acceso de Jim Acosta
como periodista a la Casa Blanca.</span></span>
		<span class="tooltip">And CNN had to sue
to have that press pass reinstated.<span class="tooltiptext">Y la CNN tuvo que demandarlos 
para regresarle su pase de prensa.</span></span>
	</p>
	<p>
		<span class="tooltip">There are about five different paths
that I can think of that we can follow<span class="tooltiptext">Hay unos cinco modos diferentes
que se me ocurren</span></span>
		<span class="tooltip">to try and address some
of these very difficult problems today.<span class="tooltiptext">para tratar de abordar algunos 
de estos problemas difíciles hoy en día.</span></span>
		<span class="tooltip">Each one of them has promise,<span class="tooltiptext">Cada uno es prometedor,</span></span>
		<span class="tooltip">but each one of them
has its own challenges.<span class="tooltiptext">pero tiene sus propios desafíos.</span></span>
		<span class="tooltip">The first one is labeling.<span class="tooltiptext">El primero es el etiquetado.</span></span>
		<span class="tooltip">Think about it this way:<span class="tooltiptext">Piénsenlo de esta manera:</span></span>
		<span class="tooltip">when you go to the grocery store
to buy food to consume,<span class="tooltiptext">cuando van a la tienda 
para comprar alimentos,</span></span>
		<span class="tooltip">it&#39;s extensively labeled.<span class="tooltiptext">está todo etiquetado.</span></span>
		<span class="tooltip">You know how many calories it has,<span class="tooltiptext">Saben la cantidad de calorías que tiene,</span></span>
		<span class="tooltip">how much fat it contains --<span class="tooltiptext">la cantidad de grasa que contiene,</span></span>
		<span class="tooltip">and yet when we consume information,
we have no labels whatsoever.<span class="tooltiptext">pero, cuando consumimos información, 
no tenemos etiquetas de ningún tipo.</span></span>
		<span class="tooltip">What is contained in this information?<span class="tooltiptext">¿Qué contiene esta información?</span></span>
		<span class="tooltip">Is the source credible?<span class="tooltiptext">¿Es creíble la fuente?</span></span>
		<span class="tooltip">Where is this information gathered from?<span class="tooltiptext">¿De dónde se obtuvo esta información?</span></span>
		<span class="tooltip">We have none of that information<span class="tooltiptext">No tenemos ninguno de esos datos
cuando consumimos información.</span></span>
		<span class="tooltip">when we are consuming information.<span class="tooltiptext">Esa es una vía potencial,
pero viene con sus desafíos.</span></span>
		<span class="tooltip">That is a potential avenue,
but it comes with its challenges.<span class="tooltiptext">Por ejemplo, ¿quién decide en la sociedad
lo que es cierto y lo que es falso?</span></span>
		<span class="tooltip">For instance, who gets to decide,
in society, what&#39;s true and what&#39;s false?<span class="tooltiptext">¿Son los gobiernos?</span></span>
		<span class="tooltip">Is it the governments?<span class="tooltiptext">¿Es Facebook?</span></span>
		<span class="tooltip">Is it Facebook?<span class="tooltiptext">¿Es un consorcio independiente
de verificadores?</span></span>
		<span class="tooltip">Is it an independent
consortium of fact-checkers?<span class="tooltiptext">¿Y quién controla a los verificadores?</span></span>
		<span class="tooltip">And who&#39;s checking the fact-checkers?<span class="tooltiptext">Otra vía potencial son los incentivos.</span></span>
	</p>
	<p>
		<span class="tooltip">Another potential avenue is incentives.<span class="tooltiptext">Sabemos que durante 
la elección presidencial de EE. UU.</span></span>
		<span class="tooltip">We know that during
the US presidential election<span class="tooltiptext">se produjo una oleada de información falsa
que procedía de Macedonia.</span></span>
		<span class="tooltip">there was a wave of misinformation
that came from Macedonia<span class="tooltiptext">No tenía ningún fin político</span></span>
		<span class="tooltip">that didn&#39;t have any political motive<span class="tooltiptext">pero sí un fin económico.</span></span>
		<span class="tooltip">but instead had an economic motive.<span class="tooltiptext">Y este fin económico existió</span></span>
		<span class="tooltip">And this economic motive existed,<span class="tooltiptext">porque las noticias falsas viajan 
mucho más lejos, más rápido,</span></span>
		<span class="tooltip">because false news travels
so much farther, faster<span class="tooltiptext">y tienen mayor alcance que la verdad,</span></span>
		<span class="tooltip">and more deeply than the truth,<span class="tooltiptext">y se puede ganar dinero con la publicidad 
mientras se atrae la atención</span></span>
		<span class="tooltip">and you can earn advertising dollars
as you garner eyeballs and attention<span class="tooltiptext">con este tipo de información.</span></span>
		<span class="tooltip">with this type of information.<span class="tooltiptext">Pero si podemos reducir la difusión 
de esta información,</span></span>
		<span class="tooltip">But if we can depress the spread
of this information,<span class="tooltiptext">tal vez se reduciría
el incentivo económico</span></span>
		<span class="tooltip">perhaps it would reduce
the economic incentive<span class="tooltiptext">para producirla.</span></span>
		<span class="tooltip">to produce it at all in the first place.<span class="tooltiptext">En tercer lugar, pensemos en la regulación</span></span>
	</p>
	<p>
		<span class="tooltip">Third, we can think about regulation,<span class="tooltiptext">y, desde luego, debemos
pensar en esta opción.</span></span>
		<span class="tooltip">and certainly, we should think
about this option.<span class="tooltiptext">En EE. UU., en la actualidad,</span></span>
		<span class="tooltip">In the United States, currently,<span class="tooltiptext">estamos explorando lo que podría suceder 
si Facebook y otros medios se regularan.</span></span>
		<span class="tooltip">we are exploring what might happen
if Facebook and others are regulated.<span class="tooltiptext">Aunque debemos tener en cuenta cosas 
como la regulación del discurso político,</span></span>
		<span class="tooltip">While we should consider things
like regulating political speech,<span class="tooltiptext">es decir, etiquetarlo 
como discurso político,</span></span>
		<span class="tooltip">labeling the fact
that it&#39;s political speech,<span class="tooltiptext">asegurarse de que los actores extranjeros
no puedan financiar el discurso político,</span></span>
		<span class="tooltip">making sure foreign actors
can&#39;t fund political speech,<span class="tooltiptext">también tiene sus propios peligros.</span></span>
		<span class="tooltip">it also has its own dangers.<span class="tooltiptext">Por ejemplo, Malasia acaba de instituir 
una condena de seis años de prisión</span></span>
		<span class="tooltip">For instance, Malaysia just instituted
a six-year prison sentence<span class="tooltiptext">para cualquier persona que sea sorprendida
difundiendo datos falsos.</span></span>
		<span class="tooltip">for anyone found spreading misinformation.<span class="tooltiptext">Y en los regímenes autoritarios,</span></span>
		<span class="tooltip">And in authoritarian regimes,<span class="tooltiptext">este tipo de políticas se pueden utilizar 
para suprimir las opiniones minoritarias</span></span>
		<span class="tooltip">these kinds of policies can be used
to suppress minority opinions<span class="tooltiptext">y para seguir ampliando la represión.</span></span>
		<span class="tooltip">and to continue to extend repression.<span class="tooltiptext">La cuarta opción posible 
es la transparencia.</span></span>
	</p>
	<p>
		<span class="tooltip">The fourth possible option
is transparency.<span class="tooltiptext">Queremos saber cómo funcionan
los algoritmos de Facebook.</span></span>
		<span class="tooltip">We want to know
how do Facebook&#39;s algorithms work.<span class="tooltiptext">¿De qué manera los datos 
se combinan con los algoritmos</span></span>
		<span class="tooltip">How does the data
combine with the algorithms<span class="tooltiptext">para producir los resultados que vemos?</span></span>
		<span class="tooltip">to produce the outcomes that we see?<span class="tooltiptext">Queremos que abran el kimono</span></span>
		<span class="tooltip">We want them to open the kimono<span class="tooltiptext">y nos muestren exactamente 
el funcionamiento interno de Facebook.</span></span>
		<span class="tooltip">and show us exactly the inner workings
of how Facebook is working.<span class="tooltiptext">Y si queremos conocer el efecto
de las redes sociales en la sociedad,</span></span>
		<span class="tooltip">And if we want to know
social media&#39;s effect on society,<span class="tooltiptext">necesitamos que científicos, 
investigadores y otras personas</span></span>
		<span class="tooltip">we need scientists, researchers<span class="tooltiptext">tengan acceso a este tipo de información.</span></span>
		<span class="tooltip">and others to have access
to this kind of information.<span class="tooltiptext">Pero al mismo tiempo,</span></span>
		<span class="tooltip">But at the same time,<span class="tooltiptext">estamos pidiendo a Facebook 
poner todo bajo llave</span></span>
		<span class="tooltip">we are asking Facebook
to lock everything down,<span class="tooltiptext">para mantener los datos seguros.</span></span>
		<span class="tooltip">to keep all of the data secure.<span class="tooltiptext">Así, Facebook y las otras 
plataformas de medios sociales</span></span>
	</p>
	<p>
		<span class="tooltip">So, Facebook and the other
social media platforms<span class="tooltiptext">se enfrentan a lo que llamo 
&quot;la paradoja de la transparencia&quot;.</span></span>
		<span class="tooltip">are facing what I call
a transparency paradox.<span class="tooltiptext">Les estamos pidiendo</span></span>
		<span class="tooltip">We are asking them, at the same time,<span class="tooltiptext">que sean abiertas, transparentes 
y, al mismo tiempo, seguras.</span></span>
		<span class="tooltip">to be open and transparent
and, simultaneously secure.<span class="tooltiptext">Esta es una aguja muy difícil enhebrar,</span></span>
		<span class="tooltip">This is a very difficult needle to thread,<span class="tooltiptext">pero deberán enhebrar esta aguja</span></span>
		<span class="tooltip">but they will need to thread this needle<span class="tooltiptext">si queremos alcanzar la promesa 
de las tecnologías sociales</span></span>
		<span class="tooltip">if we are to achieve the promise
of social technologies<span class="tooltiptext">y, a la vez, evitar sus riesgos.</span></span>
		<span class="tooltip">while avoiding their peril.<span class="tooltiptext">La última opción posible</span></span>
	</p>
	<p>
		<span class="tooltip">The final thing that we could think about
is algorithms and machine learning.<span class="tooltiptext">son los algoritmos 
y el aprendizaje automático,</span></span>
		<span class="tooltip">Technology devised to root out
and understand fake news, how it spreads,<span class="tooltiptext">tecnología ideada para erradicar 
y entender las noticias falsas,</span></span>
		<span class="tooltip">and to try and dampen its flow.<span class="tooltiptext">cómo se transmiten, 
y tratar de reducir su difusión.</span></span>
		<span class="tooltip">Humans have to be in the loop
of this technology,<span class="tooltiptext">La humanidad tiene que estar
en el bucle de esta tecnología,</span></span>
		<span class="tooltip">because we can never escape<span class="tooltiptext">porque nunca podremos negar</span></span>
		<span class="tooltip">that underlying any technological
solution or approach<span class="tooltiptext">que detrás de cualquier
solución o enfoque tecnológico</span></span>
		<span class="tooltip">is a fundamental ethical
and philosophical question<span class="tooltiptext">hay una pregunta ética
y filosófica fundamental</span></span>
		<span class="tooltip">about how do we define truth and falsity,<span class="tooltiptext">acerca de cómo definimos
la verdad y la falsedad,</span></span>
		<span class="tooltip">to whom do we give the power
to define truth and falsity<span class="tooltiptext">a quién le damos el poder
de definir la verdad y la mentira,</span></span>
		<span class="tooltip">and which opinions are legitimate,<span class="tooltiptext">y qué opiniones son legítimas,</span></span>
		<span class="tooltip">which type of speech
should be allowed and so on.<span class="tooltiptext">qué tipo de discurso 
debe permitirse y así sucesivamente.</span></span>
		<span class="tooltip">Technology is not a solution for that.<span class="tooltiptext">La tecnología no es 
una solución en este caso.</span></span>
		<span class="tooltip">Ethics and philosophy
is a solution for that.<span class="tooltiptext">La ética y la filosofía son la solución.</span></span>
	</p>
	<p>
		<span class="tooltip">Nearly every theory
of human decision making,<span class="tooltiptext">Casi todas las teorías 
de la toma de decisiones humanas,</span></span>
		<span class="tooltip">human cooperation and human coordination<span class="tooltiptext">la cooperación humana
y la coordinación humana</span></span>
		<span class="tooltip">has some sense of the truth at its core.<span class="tooltiptext">tienen un cierto sentido 
de la verdad en su esencia.</span></span>
		<span class="tooltip">But with the rise of fake news,<span class="tooltiptext">Pero con el aumento de noticias falsas,</span></span>
		<span class="tooltip">the rise of fake video,<span class="tooltiptext">de videos falsos,</span></span>
		<span class="tooltip">the rise of fake audio,<span class="tooltiptext">de audios falsos,</span></span>
		<span class="tooltip">we are teetering on the brink
of the end of reality,<span class="tooltiptext">estamos al borde del precipicio 
del fin de la realidad,</span></span>
		<span class="tooltip">where we cannot tell
what is real from what is fake.<span class="tooltiptext">donde no podemos diferenciar
lo que es real de lo que es falso.</span></span>
		<span class="tooltip">And that&#39;s potentially
incredibly dangerous.<span class="tooltiptext">Y eso es potencialmente 
muy peligroso.</span></span>
	</p>
	<p>
		<span class="tooltip">We have to be vigilant
in defending the truth<span class="tooltiptext">Tenemos que estar vigilantes 
en la defensa de la verdad</span></span>
		<span class="tooltip">against misinformation.<span class="tooltiptext">contra la información errónea,</span></span>
		<span class="tooltip">With our technologies, with our policies<span class="tooltiptext">con nuestras tecnologías, 
con nuestras políticas</span></span>
		<span class="tooltip">and, perhaps most importantly,<span class="tooltiptext">y, quizás lo más importante,</span></span>
		<span class="tooltip">with our own individual responsibilities,<span class="tooltiptext">con nuestras propias responsabilidades,</span></span>
		<span class="tooltip">decisions, behaviors and actions.<span class="tooltiptext">decisiones, comportamientos
y acciones individuales.</span></span>
	</p>
	<p>
		<span class="tooltip">Thank you very much.<span class="tooltiptext">Muchas gracias.</span></span>
	</p>
	<p>
		<span class="tooltip">(Applause)<span class="tooltiptext">(Aplausos)</span></span>
	</p>

	<div class="line"></div>
	<p>Love our website? Help us keep it ad-free and running smoothly by making a donation today.</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	<p>Ready to sound like a native speaker? Or better yet, elevate your language skills to the next level? Check out my book : </p>
	<div style="text-align: center;"> <span><a href="https://amzn.to/3Um79fs" target="_blank" rel=" noopener noreferrer"><img height="160" width="103" typeof="foaf:Image" class="image-style-none" src="../../../static/images/off-the-hook-shaun-clark.jpg" alt="off the hook book by shaun clark"></a></span> </div>
	<div class="views-field views-field-title" style="text-align: center;"> <span class="field-content"><a href="https://amzn.to/3Um79fs" target="_blank" rel=" noopener noreferrer">Off The Hook: The Ultimate English Slang Dictionary</a></span> </div>
	<p style="text-align: center;">Or explore our amazing library! <a href="../../../library/1/index.html">HERE</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='../../../library/1/index.html'>Library</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	