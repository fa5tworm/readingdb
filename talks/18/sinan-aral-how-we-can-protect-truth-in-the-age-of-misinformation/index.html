<!DOCTYPE html>
	<html lang='en'>
	<head>
		<meta charset='UTF-8'>
		<meta name='viewport' content='width=device-width, initial-scale=1.0'>
		<meta name="description" content="Unlock your Spanish reading skills: Immerse yourself in a contextual and practical learning enhanced by high-quality instant translations.">
      	<meta name="keywords" content="Spanish reading, Spanish language learning, instant translations, reading adventure, improve Spanish, improve reading skills, educational platform, Spanish reading resources, online education, Spanish proficiency, learn Spanish, Spanish learning resources, bilingual education, language exchange, study Spanish online">
		<link rel="apple-touch-icon" sizes="180x180" href="../../../static/favicons/apple-touch-icon.png">
		<link rel="icon" type="image/png" sizes="32x32" href="../../../static/favicons/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="../../../static/favicons/favicon-16x16.png">
		<link rel="manifest" href="../../../static/favicons/site.webmanifest">
		<title>Sinan Aral : How we can protect truth in the age of misinformation</title>
		<link rel='stylesheet' href='../../../static/styles/styles.css'>
		<script defer data-domain="readingdb.org" src="https://plausible.io/js/script.js"></script>
	</head>
	<body>

	<h1 class='title'>How we can protect truth in the age of misinformation</h1>
	<h2 class='speaker'>Sinan Aral</h2>
	<div class='transcript books'>
	<p>Are you ready to improve your Spanish speaking skills, check <a href='https://referral.lingoda.com/6Dztrv'>Lingoda</a> today!</p>
		<p>
		<span class="tooltip">El 23 de abril de 2013,<span class="tooltiptext">So, on April 23 of 2013,</span></span>
		<span class="tooltip">Associated Press 
puso el siguiente tuit en Twitter.<span class="tooltiptext">the Associated Press
put out the following tweet on Twitter.</span></span>
		<span class="tooltip">Decía: &quot;Noticia de última hora:<span class="tooltiptext">It said, &quot;Breaking news:</span></span>
		<span class="tooltip">dos explosiones en la Casa Blanca.<span class="tooltiptext">Two explosions at the White House</span></span>
		<span class="tooltip">Barack Obama ha resultado herido&quot;.<span class="tooltiptext">and Barack Obama has been injured.&quot;</span></span>
		<span class="tooltip">Este tuit fue retuiteado 4000 veces 
en menos de cinco minutos,<span class="tooltiptext">This tweet was retweeted 4,000 times
in less than five minutes,</span></span>
		<span class="tooltip">y se hizo viral a partir de ese instante.<span class="tooltiptext">and it went viral thereafter.</span></span>
		<span class="tooltip">Ahora bien, este tuit 
no fue una noticia verdadera<span class="tooltiptext">Now, this tweet wasn&#39;t real news
put out by the Associated Press.</span></span>
		<span class="tooltip">difundida por la agencia Associated Press.<span class="tooltiptext">In fact it was false news, or fake news,</span></span>
		<span class="tooltip">En realidad, fue una noticia falsa,<span class="tooltiptext">that was propagated by Syrian hackers</span></span>
		<span class="tooltip">propagada por &#39;hackers&#39; sirios<span class="tooltiptext">that had infiltrated
the Associated Press Twitter handle.</span></span>
		<span class="tooltip">que se habían hecho con el control
del Twitter de Associated Press.<span class="tooltiptext">Their purpose was to disrupt society,
but they disrupted much more.</span></span>
		<span class="tooltip">Su objetivo era alterar a la sociedad, 
pero alteraron mucho más,<span class="tooltiptext">Because automated trading algorithms</span></span>
		<span class="tooltip">porque los algoritmos 
automatizados de negociación<span class="tooltiptext">immediately seized
on the sentiment on this tweet,</span></span>
		<span class="tooltip">inmediatamente interpretaron
la sensibilidad de este tuit,<span class="tooltiptext">and began trading based on the potential</span></span>
		<span class="tooltip">y comenzaron a operar
en base a la posibilidad<span class="tooltiptext">that the president of the United States
had been injured or killed</span></span>
		<span class="tooltip">de que el presidente de los EE. UU. 
hubiese sido herido o asesinado<span class="tooltiptext">in this explosion.</span></span>
		<span class="tooltip">en esa explosión.<span class="tooltiptext">And as they started tweeting,</span></span>
		<span class="tooltip">Y cuando empezaron a tuitear,<span class="tooltiptext">they immediately sent
the stock market crashing,</span></span>
		<span class="tooltip">hicieron que el mercado de valores
se desplomara al instante,<span class="tooltiptext">wiping out 140 billion dollars
in equity value in a single day.</span></span>
		<span class="tooltip">y se perdieron 140 mil millones de dólares
en valor bursátil en un solo día.<span class="tooltiptext">Robert Mueller, special counsel
prosecutor in the United States,</span></span>
		<span class="tooltip">Robert Mueller, consejero 
y fiscal especial de los Estados Unidos,<span class="tooltiptext">issued indictments
against three Russian companies</span></span>
		<span class="tooltip">acusó penalmente a tres compañías rusas<span class="tooltiptext">and 13 Russian individuals</span></span>
		<span class="tooltip">y a 13 individuos rusos<span class="tooltiptext">on a conspiracy to defraud
the United States</span></span>
		<span class="tooltip">de conspirar para cometer fraude 
contra los Estados Unidos<span class="tooltiptext">by meddling in the 2016
presidential election.</span></span>
		<span class="tooltip">al entrometerse en las elecciones
presidenciales de 2016.<span class="tooltiptext">And what this indictment tells as a story</span></span>
		<span class="tooltip">Lo que esta acusación deja al descubierto<span class="tooltiptext">is the story of the Internet
Research Agency,</span></span>
		<span class="tooltip">es la historia de la Agencia
de Investigación de Internet,<span class="tooltiptext">the shadowy arm of the Kremlin
on social media.</span></span>
		<span class="tooltip">el oscuro brazo del Kremlin 
en las redes sociales.<span class="tooltiptext">During the presidential election alone,</span></span>
		<span class="tooltip">Solo en las elecciones presidenciales,<span class="tooltiptext">the Internet Agency&#39;s efforts</span></span>
		<span class="tooltip">los intentos de la Agencia de Internet<span class="tooltiptext">reached 126 million people
on Facebook in the United States,</span></span>
		<span class="tooltip">llegaron a 126 millones de personas 
en Facebook en los Estados Unidos,<span class="tooltiptext">issued three million individual tweets</span></span>
		<span class="tooltip">emitieron tres millones 
de tuits individuales<span class="tooltiptext">and 43 hours&#39; worth of YouTube content.</span></span>
		<span class="tooltip">y 43 horas de contenido de YouTube.<span class="tooltiptext">All of which was fake --</span></span>
		<span class="tooltip">Todo lo cual era falso,<span class="tooltiptext">misinformation designed to sow discord
in the US presidential election.</span></span>
		<span class="tooltip">desinformación diseñada para meter cizaña
en la elección presidencial de EE. UU.<span class="tooltiptext">A recent study by Oxford University</span></span>
		<span class="tooltip">Un estudio reciente
realizado por la Universidad de Oxford<span class="tooltiptext">showed that in the recent
Swedish elections,</span></span>
		<span class="tooltip">mostró que en las últimas 
elecciones suecas,<span class="tooltiptext">one third of all of the information
spreading on social media</span></span>
		<span class="tooltip">un tercio de toda la información
que se difundió en las redes sociales<span class="tooltiptext">about the election</span></span>
		<span class="tooltip">sobre las elecciones<span class="tooltiptext">was fake or misinformation.</span></span>
		<span class="tooltip">era falsa o incorrecta.<span class="tooltiptext">In addition, these types
of social-media misinformation campaigns</span></span>
		<span class="tooltip">Además, este tipo de campañas
de desinformación en redes sociales<span class="tooltiptext">can spread what has been called
&quot;genocidal propaganda,&quot;</span></span>
		<span class="tooltip">pueden difundir lo que se ha llamado 
&quot;propaganda genocida&quot;,<span class="tooltiptext">for instance against
the Rohingya in Burma,</span></span>
		<span class="tooltip">por ejemplo contra los rohingya en Burma,<span class="tooltiptext">triggering mob killings in India.</span></span>
		<span class="tooltip">que desencadenó linchamientos en la India.<span class="tooltiptext">We studied fake news</span></span>
		<span class="tooltip">Estudiamos las noticias falsas<span class="tooltiptext">and began studying it
before it was a popular term.</span></span>
		<span class="tooltip">y comenzamos a hacerlo 
antes de que fuera un término popular.<span class="tooltiptext">And we recently published
the largest-ever longitudinal study</span></span>
		<span class="tooltip">Y hemos publicado recientemente el estudio
longitudinal más grande jamás realizado<span class="tooltiptext">of the spread of fake news online</span></span>
		<span class="tooltip">sobre la difusión
de noticias falsas en línea<span class="tooltiptext">on the cover of &quot;Science&quot;
in March of this year.</span></span>
		<span class="tooltip">en la portada de la revista &quot;Science&quot; 
en marzo de este año.<span class="tooltiptext">We studied all of the verified
true and false news stories</span></span>
		<span class="tooltip">Estudiamos todas las noticias 
verificadas como verdaderas y falsas<span class="tooltiptext">that ever spread on Twitter,</span></span>
		<span class="tooltip">que se propagaron por Twitter,<span class="tooltiptext">from its inception in 2006 to 2017.</span></span>
		<span class="tooltip">desde su creación en 2006 hasta 2017.<span class="tooltiptext">And when we studied this information,</span></span>
		<span class="tooltip">Y cuando estudiamos esta información,<span class="tooltiptext">we studied verified news stories</span></span>
		<span class="tooltip">tomamos las noticias
verificadas y revisadas<span class="tooltiptext">that were verified by six
independent fact-checking organizations.</span></span>
		<span class="tooltip">por seis organizaciones
independientes de comprobación de datos.<span class="tooltiptext">So we knew which stories were true</span></span>
		<span class="tooltip">Así que sabíamos cuáles eran ciertas<span class="tooltiptext">and which stories were false.</span></span>
		<span class="tooltip">y cuáles falsas.<span class="tooltiptext">We can measure their diffusion,</span></span>
		<span class="tooltip">Podemos medir su difusión,<span class="tooltiptext">the speed of their diffusion,</span></span>
		<span class="tooltip">la velocidad de su difusión,<span class="tooltiptext">the depth and breadth of their diffusion,</span></span>
		<span class="tooltip">el alcance de su difusión,<span class="tooltiptext">how many people become entangled
in this information cascade and so on.</span></span>
		<span class="tooltip">cuántas personas se enredan 
en esta cascada de información, etc.<span class="tooltiptext">And what we did in this paper</span></span>
		<span class="tooltip">Y lo que hicimos en esta investigación<span class="tooltiptext">was we compared the spread of true news
to the spread of false news.</span></span>
		<span class="tooltip">fue comparar la propagación
de noticias verdaderas con las falsas.<span class="tooltiptext">And here&#39;s what we found.</span></span>
		<span class="tooltip">Y estos son los resultados.<span class="tooltiptext">We found that false news
diffused further, faster, deeper</span></span>
		<span class="tooltip">Hallamos que una noticia falsa 
llega más lejos, más rápido<span class="tooltiptext">and more broadly than the truth</span></span>
		<span class="tooltip">y tiene más alcance que la verdadera<span class="tooltiptext">in every category of information
that we studied,</span></span>
		<span class="tooltip">en todas las categorías de información 
que hemos estudiado,<span class="tooltiptext">sometimes by an order of magnitude.</span></span>
		<span class="tooltip">a veces en un orden de magnitud.<span class="tooltiptext">And in fact, false political news
was the most viral.</span></span>
		<span class="tooltip">Y las noticias falsas en el ámbito
de la política fueron las más virales.<span class="tooltiptext">It diffused further, faster,
deeper and more broadly</span></span>
		<span class="tooltip">Se difunden más lejos, más rápido, 
y tienen mayor alcance<span class="tooltiptext">than any other type of false news.</span></span>
		<span class="tooltip">que cualquier otro tipo
de noticias falsas.<span class="tooltiptext">When we saw this,</span></span>
		<span class="tooltip">Cuando vimos esto,<span class="tooltiptext">we were at once worried but also curious.</span></span>
		<span class="tooltip">sentimos a la vez
preocupación y curiosidad.<span class="tooltiptext">Why?</span></span>
		<span class="tooltip">¿Por qué?<span class="tooltiptext">Why does false news travel
so much further, faster, deeper</span></span>
		<span class="tooltip">¿Por qué las noticias falsas llegan
más lejos, más rápido,<span class="tooltiptext">and more broadly than the truth?</span></span>
		<span class="tooltip">y tienen mayor alcance que la verdad?<span class="tooltiptext">The first hypothesis
that we came up with was,</span></span>
		<span class="tooltip">La primera hipótesis 
que se nos ocurrió fue:<span class="tooltiptext">&quot;Well, maybe people who spread false news
have more followers or follow more people,</span></span>
		<span class="tooltip">&quot;Bueno, tal vez quienes
difunden noticias falsas<span class="tooltiptext">or tweet more often,</span></span>
		<span class="tooltip">tienen más seguidores
o siguen a más gente,<span class="tooltiptext">or maybe they&#39;re more often &#39;verified&#39;
users of Twitter, with more credibility,</span></span>
		<span class="tooltip">o tuitean con más frecuencia,<span class="tooltiptext">or maybe they&#39;ve been on Twitter longer.&quot;</span></span>
		<span class="tooltip">o tal vez son más usuarios &#39;verificados&#39;
de Twitter, con más credibilidad,<span class="tooltiptext">So we checked each one of these in turn.</span></span>
		<span class="tooltip">o tal vez han estado
en Twitter más tiempo&quot;.<span class="tooltiptext">And what we found
was exactly the opposite.</span></span>
		<span class="tooltip">Así que inspeccionamos
cada uno de estos casos.<span class="tooltiptext">False-news spreaders had fewer followers,</span></span>
		<span class="tooltip">Y lo que encontramos 
fue exactamente lo contrario.<span class="tooltiptext">followed fewer people, were less active,</span></span>
		<span class="tooltip">Quienes difundían noticias falsas
tenían menos seguidores,<span class="tooltiptext">less often &quot;verified&quot;</span></span>
		<span class="tooltip">seguían a menos gente, eran menos activos,
eran usuarios poco &quot;verificados&quot;<span class="tooltiptext">and had been on Twitter
for a shorter period of time.</span></span>
		<span class="tooltip">y habían estado en Twitter 
por un período de tiempo más corto.<span class="tooltiptext">And yet,</span></span>
		<span class="tooltip">Y sin embargo,<span class="tooltiptext">false news was 70 percent more likely
to be retweeted than the truth,</span></span>
		<span class="tooltip">las noticias falsas eran un 70 %
más propensas a ser retuiteadas,<span class="tooltiptext">controlling for all of these
and many other factors.</span></span>
		<span class="tooltip">teniendo en cuenta estos 
y muchos otros factores.<span class="tooltiptext">So we had to come up
with other explanations.</span></span>
		<span class="tooltip">Así que tuvimos que buscar 
otras explicaciones.<span class="tooltiptext">And we devised what we called
a &quot;novelty hypothesis.&quot;</span></span>
		<span class="tooltip">E ideamos lo que llamamos 
&quot;hipótesis de la novedad&quot;.<span class="tooltiptext">So if you read the literature,</span></span>
		<span class="tooltip">Si leemos documentaciones sobre el tema,<span class="tooltiptext">it is well known that human attention
is drawn to novelty,</span></span>
		<span class="tooltip">es bien sabido que la atención humana 
se siente atraída por la novedad,<span class="tooltiptext">things that are new in the environment.</span></span>
		<span class="tooltip">cosas que son nuevas en el entorno.<span class="tooltiptext">And if you read the sociology literature,</span></span>
		<span class="tooltip">Y si leemos la literatura sociológica,<span class="tooltiptext">you know that we like to share
novel information.</span></span>
		<span class="tooltip">veremos que nos gusta compartir 
información novedosa.<span class="tooltiptext">It makes us seem like we have access
to inside information,</span></span>
		<span class="tooltip">Sentimos que tenemos acceso 
a información privilegiada,<span class="tooltiptext">and we gain in status
by spreading this kind of information.</span></span>
		<span class="tooltip">y ganamos estatus mediante la difusión
de este tipo de información.<span class="tooltiptext">So what we did was we measured the novelty
of an incoming true or false tweet,</span></span>
		<span class="tooltip">Decidimos entonces medir
la novedad de un tuit verdadero o falso,<span class="tooltiptext">compared to the corpus
of what that individual had seen</span></span>
		<span class="tooltip">en comparación con el corpus 
de lo que esa persona había visto<span class="tooltiptext">in the 60 days prior on Twitter.</span></span>
		<span class="tooltip">en Twitter los 60 días anteriores.<span class="tooltiptext">But that wasn&#39;t enough,
because we thought to ourselves,</span></span>
		<span class="tooltip">Pero no fue suficiente, porque pensamos:<span class="tooltiptext">&quot;Well, maybe false news is more novel
in an information-theoretic sense,</span></span>
		<span class="tooltip">&quot;Bueno, quizá las noticias falsas
son más novedosas en un sentido teórico,<span class="tooltiptext">but maybe people
don&#39;t perceive it as more novel.&quot;</span></span>
		<span class="tooltip">pero tal vez la gente 
no las percibe como más novedosas&quot;.<span class="tooltiptext">So to understand people&#39;s
perceptions of false news,</span></span>
		<span class="tooltip">Así que para entender cómo
la gente percibe las noticias falsas,<span class="tooltiptext">we looked at the information
and the sentiment</span></span>
		<span class="tooltip">nos fijamos en la información 
y el componente afectivo<span class="tooltiptext">contained in the replies
to true and false tweets.</span></span>
		<span class="tooltip">de las respuestas 
a los tuits verdaderos y falsos.<span class="tooltiptext">And what we found</span></span>
		<span class="tooltip">Y lo que detectamos<span class="tooltiptext">was that across a bunch
of different measures of sentiment --</span></span>
		<span class="tooltip">fue que, teniendo en cuenta 
un montón de sentimientos diferentes,<span class="tooltiptext">surprise, disgust, fear, sadness,</span></span>
		<span class="tooltip">como sorpresa, disgusto, miedo, tristeza,<span class="tooltiptext">anticipation, joy and trust --</span></span>
		<span class="tooltip">expectativa, alegría y confianza,<span class="tooltiptext">false news exhibited significantly more
surprise and disgust</span></span>
		<span class="tooltip">las noticias falsas generaron
significativamente más sorpresa y disgusto<span class="tooltiptext">in the replies to false tweets.</span></span>
		<span class="tooltip">en las respuestas a los falsos tuits.<span class="tooltiptext">And true news exhibited
significantly more anticipation,</span></span>
		<span class="tooltip">Y las noticias verdaderas mostraron
significativamente más expectativas,<span class="tooltiptext">joy and trust</span></span>
		<span class="tooltip">alegría y confianza<span class="tooltiptext">in reply to true tweets.</span></span>
		<span class="tooltip">en respuesta a los tuits verdaderos.<span class="tooltiptext">The surprise corroborates
our novelty hypothesis.</span></span>
		<span class="tooltip">La sorpresa corrobora 
nuestra hipótesis de la novedad.<span class="tooltiptext">This is new and surprising,
and so we&#39;re more likely to share it.</span></span>
		<span class="tooltip">Esto es nuevo y sorprendente, 
por lo que es más fácil que se comparta.<span class="tooltiptext">At the same time,
there was congressional testimony</span></span>
		<span class="tooltip">Al mismo tiempo, 
hubo testimonios ante el Congreso<span class="tooltiptext">in front of both houses of Congress
in the United States,</span></span>
		<span class="tooltip">en las dos cámaras parlamentarias 
de los Estados Unidos<span class="tooltiptext">looking at the role of bots
in the spread of misinformation.</span></span>
		<span class="tooltip">sobre el papel de los robots 
en la propagación de información errónea.<span class="tooltiptext">So we looked at this too --</span></span>
		<span class="tooltip">Así que consideramos esto también.<span class="tooltiptext">we used multiple sophisticated
bot-detection algorithms</span></span>
		<span class="tooltip">Utilizamos múltiples algoritmos 
complejos de rastreo<span class="tooltiptext">to find the bots in our data
and to pull them out.</span></span>
		<span class="tooltip">para encontrar los robots
en nuestros datos y sacarlos.<span class="tooltiptext">So we pulled them out,
we put them back in</span></span>
		<span class="tooltip">Los sacamos, los volvimos a poner<span class="tooltiptext">and we compared what happens
to our measurement.</span></span>
		<span class="tooltip">y comparamos lo que sucede 
con nuestras mediciones.<span class="tooltiptext">And what we found was that, yes indeed,</span></span>
		<span class="tooltip">Descubrimos que, efectivamente,<span class="tooltiptext">bots were accelerating
the spread of false news online,</span></span>
		<span class="tooltip">los robots aceleraban la propagación
de noticias falsas en línea,<span class="tooltiptext">but they were accelerating
the spread of true news</span></span>
		<span class="tooltip">pero aceleraban
la propagación de las verdaderas<span class="tooltiptext">at approximately the same rate.</span></span>
		<span class="tooltip">aproximadamente a la misma velocidad.<span class="tooltiptext">Which means bots are not responsible</span></span>
		<span class="tooltip">Lo que significa que los robots
no son los responsables<span class="tooltiptext">for the differential diffusion
of truth and falsity online.</span></span>
		<span class="tooltip">de la difusión diferencial 
de la verdad y la mentira en línea.<span class="tooltiptext">We can&#39;t abdicate that responsibility,</span></span>
		<span class="tooltip">No podemos renunciar
a esa responsabilidad,<span class="tooltiptext">because we, humans,
are responsible for that spread.</span></span>
		<span class="tooltip">porque nosotros, los seres humanos, 
somos responsables de esa propagación.<span class="tooltiptext">Now, everything
that I have told you so far,</span></span>
		<span class="tooltip">Ahora bien, todo lo que
les he dicho hasta el momento,<span class="tooltiptext">unfortunately for all of us,</span></span>
		<span class="tooltip">por desgracia para todos nosotros,<span class="tooltiptext">is the good news.</span></span>
		<span class="tooltip">es la buena noticia.<span class="tooltiptext">The reason is because
it&#39;s about to get a whole lot worse.</span></span>
		<span class="tooltip">La razón es que está 
a punto de ponerse mucho peor.<span class="tooltiptext">And two specific technologies
are going to make it worse.</span></span>
		<span class="tooltip">Y dos tecnologías específicas 
van a empeorar la situación.<span class="tooltiptext">We are going to see the rise
of a tremendous wave of synthetic media.</span></span>
		<span class="tooltip">Vamos a presenciar el aumento
de una tremenda ola de medios sintéticos.<span class="tooltiptext">Fake video, fake audio
that is very convincing to the human eye.</span></span>
		<span class="tooltip">Video falso, audio falso,
muy convincentes para el ojo humano.<span class="tooltiptext">And this will powered by two technologies.</span></span>
		<span class="tooltip">Y esto será impulsado por dos tecnologías.<span class="tooltiptext">The first of these is known
as &quot;generative adversarial networks.&quot;</span></span>
		<span class="tooltip">La primera es conocida como 
&quot;redes de confrontación generativas&quot;.<span class="tooltiptext">This is a machine-learning model
with two networks:</span></span>
		<span class="tooltip">Es un modelo de aprendizaje
automático con dos redes:<span class="tooltiptext">a discriminator,</span></span>
		<span class="tooltip">un discriminador,<span class="tooltiptext">whose job it is to determine
whether something is true or false,</span></span>
		<span class="tooltip">cuyo trabajo es determinar 
si algo es verdadero o falso,<span class="tooltiptext">and a generator,</span></span>
		<span class="tooltip">y un generador,<span class="tooltiptext">whose job it is to generate
synthetic media.</span></span>
		<span class="tooltip">cuyo trabajo es generar medios sintéticos.<span class="tooltiptext">So the synthetic generator
generates synthetic video or audio,</span></span>
		<span class="tooltip">El generador sintético
genera un video o audio sintético,<span class="tooltiptext">and the discriminator tries to tell,
&quot;Is this real or is this fake?&quot;</span></span>
		<span class="tooltip">y el discriminador trata de distinguir 
si es verdadero o falso.<span class="tooltiptext">And in fact, it is the job
of the generator</span></span>
		<span class="tooltip">Y, de hecho, el trabajo del generador<span class="tooltiptext">to maximize the likelihood
that it will fool the discriminator</span></span>
		<span class="tooltip">es maximizar la probabilidad
de engañar al discriminador<span class="tooltiptext">into thinking the synthetic
video and audio that it is creating</span></span>
		<span class="tooltip">para que crea que el video
y el audio sintéticos que está creando<span class="tooltiptext">is actually true.</span></span>
		<span class="tooltip">son realmente ciertos.<span class="tooltiptext">Imagine a machine in a hyperloop,</span></span>
		<span class="tooltip">Imaginen una máquina en un Hyperloop,<span class="tooltiptext">trying to get better
and better at fooling us.</span></span>
		<span class="tooltip">que se perfecciona más y más
con el fin de engañarnos.<span class="tooltiptext">This, combined with the second technology,</span></span>
		<span class="tooltip">Esto, combinado con la segunda tecnología,<span class="tooltiptext">which is essentially the democratization
of artificial intelligence to the people,</span></span>
		<span class="tooltip">que es esencialmente la democratización 
de la inteligencia artificial,<span class="tooltiptext">the ability for anyone,</span></span>
		<span class="tooltip">la capacidad de cualquier persona,<span class="tooltiptext">without any background
in artificial intelligence</span></span>
		<span class="tooltip">sin ningún tipo de experiencia 
en inteligencia artificial<span class="tooltiptext">or machine learning,</span></span>
		<span class="tooltip">o aprendizaje automático,<span class="tooltiptext">to deploy these kinds of algorithms
to generate synthetic media</span></span>
		<span class="tooltip">de implementar este tipo de algoritmos 
para generar los medios sintéticos<span class="tooltiptext">makes it ultimately so much easier
to create videos.</span></span>
		<span class="tooltip">hace que, en última instancia,
sea mucho más fácil crear videos.<span class="tooltiptext">The White House issued
a false, doctored video</span></span>
		<span class="tooltip">La Casa Blanca emitió 
el video falso y adulterado<span class="tooltiptext">of a journalist interacting with an intern
who was trying to take his microphone.</span></span>
		<span class="tooltip">de una pasante que intentaba 
sacarle el micrófono a un periodista.<span class="tooltiptext">They removed frames from this video</span></span>
		<span class="tooltip">Eliminaron fotogramas de este video<span class="tooltiptext">in order to make his actions
seem more punchy.</span></span>
		<span class="tooltip">para que las acciones del periodista
pareciesen más violentas.<span class="tooltiptext">And when videographers
and stuntmen and women</span></span>
		<span class="tooltip">Y cuando camarógrafos y dobles<span class="tooltiptext">were interviewed
about this type of technique,</span></span>
		<span class="tooltip">fueron consultados
acerca de este tipo de técnica,<span class="tooltiptext">they said, &quot;Yes, we use this
in the movies all the time</span></span>
		<span class="tooltip">dijeron: &quot;Sí, siempre 
lo hacemos en las películas<span class="tooltiptext">to make our punches and kicks
look more choppy and more aggressive.&quot;</span></span>
		<span class="tooltip">para que nuestros puñetazos y patadas 
parezcan más rápidos y agresivos&quot;.<span class="tooltiptext">They then put out this video</span></span>
		<span class="tooltip">Entonces mostraron este video<span class="tooltiptext">and partly used it as justification</span></span>
		<span class="tooltip">y lo utilizaron parcialmente como excusa<span class="tooltiptext">to revoke Jim Acosta,
the reporter&#39;s, press pass</span></span>
		<span class="tooltip">para denegar el acceso de Jim Acosta
como periodista a la Casa Blanca.<span class="tooltiptext">from the White House.</span></span>
		<span class="tooltip">Y la CNN tuvo que demandarlos 
para regresarle su pase de prensa.<span class="tooltiptext">And CNN had to sue
to have that press pass reinstated.</span></span>
		<span class="tooltip">Hay unos cinco modos diferentes
que se me ocurren<span class="tooltiptext">There are about five different paths
that I can think of that we can follow</span></span>
		<span class="tooltip">para tratar de abordar algunos 
de estos problemas difíciles hoy en día.<span class="tooltiptext">to try and address some
of these very difficult problems today.</span></span>
		<span class="tooltip">Cada uno es prometedor,<span class="tooltiptext">Each one of them has promise,</span></span>
		<span class="tooltip">pero tiene sus propios desafíos.<span class="tooltiptext">but each one of them
has its own challenges.</span></span>
		<span class="tooltip">El primero es el etiquetado.<span class="tooltiptext">The first one is labeling.</span></span>
		<span class="tooltip">Piénsenlo de esta manera:<span class="tooltiptext">Think about it this way:</span></span>
		<span class="tooltip">cuando van a la tienda 
para comprar alimentos,<span class="tooltiptext">when you go to the grocery store
to buy food to consume,</span></span>
		<span class="tooltip">está todo etiquetado.<span class="tooltiptext">it&#39;s extensively labeled.</span></span>
		<span class="tooltip">Saben la cantidad de calorías que tiene,<span class="tooltiptext">You know how many calories it has,</span></span>
		<span class="tooltip">la cantidad de grasa que contiene,<span class="tooltiptext">how much fat it contains --</span></span>
		<span class="tooltip">pero, cuando consumimos información, 
no tenemos etiquetas de ningún tipo.<span class="tooltiptext">and yet when we consume information,
we have no labels whatsoever.</span></span>
		<span class="tooltip">¿Qué contiene esta información?<span class="tooltiptext">What is contained in this information?</span></span>
		<span class="tooltip">¿Es creíble la fuente?<span class="tooltiptext">Is the source credible?</span></span>
		<span class="tooltip">¿De dónde se obtuvo esta información?<span class="tooltiptext">Where is this information gathered from?</span></span>
		<span class="tooltip">No tenemos ninguno de esos datos
cuando consumimos información.<span class="tooltiptext">We have none of that information</span></span>
		<span class="tooltip">Esa es una vía potencial,
pero viene con sus desafíos.<span class="tooltiptext">when we are consuming information.</span></span>
		<span class="tooltip">Por ejemplo, ¿quién decide en la sociedad
lo que es cierto y lo que es falso?<span class="tooltiptext">That is a potential avenue,
but it comes with its challenges.</span></span>
		<span class="tooltip">¿Son los gobiernos?<span class="tooltiptext">For instance, who gets to decide,
in society, what&#39;s true and what&#39;s false?</span></span>
		<span class="tooltip">¿Es Facebook?<span class="tooltiptext">Is it the governments?</span></span>
		<span class="tooltip">¿Es un consorcio independiente
de verificadores?<span class="tooltiptext">Is it Facebook?</span></span>
		<span class="tooltip">¿Y quién controla a los verificadores?<span class="tooltiptext">Is it an independent
consortium of fact-checkers?</span></span>
		<span class="tooltip">Otra vía potencial son los incentivos.<span class="tooltiptext">And who&#39;s checking the fact-checkers?</span></span>
		<span class="tooltip">Sabemos que durante 
la elección presidencial de EE. UU.<span class="tooltiptext">Another potential avenue is incentives.</span></span>
		<span class="tooltip">se produjo una oleada de información falsa
que procedía de Macedonia.<span class="tooltiptext">We know that during
the US presidential election</span></span>
		<span class="tooltip">No tenía ningún fin político<span class="tooltiptext">there was a wave of misinformation
that came from Macedonia</span></span>
		<span class="tooltip">pero sí un fin económico.<span class="tooltiptext">that didn&#39;t have any political motive</span></span>
		<span class="tooltip">Y este fin económico existió<span class="tooltiptext">but instead had an economic motive.</span></span>
		<span class="tooltip">porque las noticias falsas viajan 
mucho más lejos, más rápido,<span class="tooltiptext">And this economic motive existed,</span></span>
		<span class="tooltip">y tienen mayor alcance que la verdad,<span class="tooltiptext">because false news travels
so much farther, faster</span></span>
		<span class="tooltip">y se puede ganar dinero con la publicidad 
mientras se atrae la atención<span class="tooltiptext">and more deeply than the truth,</span></span>
		<span class="tooltip">con este tipo de información.<span class="tooltiptext">and you can earn advertising dollars
as you garner eyeballs and attention</span></span>
		<span class="tooltip">Pero si podemos reducir la difusión 
de esta información,<span class="tooltiptext">with this type of information.</span></span>
		<span class="tooltip">tal vez se reduciría
el incentivo económico<span class="tooltiptext">But if we can depress the spread
of this information,</span></span>
		<span class="tooltip">para producirla.<span class="tooltiptext">perhaps it would reduce
the economic incentive</span></span>
		<span class="tooltip">En tercer lugar, pensemos en la regulación<span class="tooltiptext">to produce it at all in the first place.</span></span>
		<span class="tooltip">y, desde luego, debemos
pensar en esta opción.<span class="tooltiptext">Third, we can think about regulation,</span></span>
		<span class="tooltip">En EE. UU., en la actualidad,<span class="tooltiptext">and certainly, we should think
about this option.</span></span>
		<span class="tooltip">estamos explorando lo que podría suceder 
si Facebook y otros medios se regularan.<span class="tooltiptext">In the United States, currently,</span></span>
		<span class="tooltip">Aunque debemos tener en cuenta cosas 
como la regulación del discurso político,<span class="tooltiptext">we are exploring what might happen
if Facebook and others are regulated.</span></span>
		<span class="tooltip">es decir, etiquetarlo 
como discurso político,<span class="tooltiptext">While we should consider things
like regulating political speech,</span></span>
		<span class="tooltip">asegurarse de que los actores extranjeros
no puedan financiar el discurso político,<span class="tooltiptext">labeling the fact
that it&#39;s political speech,</span></span>
		<span class="tooltip">también tiene sus propios peligros.<span class="tooltiptext">making sure foreign actors
can&#39;t fund political speech,</span></span>
		<span class="tooltip">Por ejemplo, Malasia acaba de instituir 
una condena de seis años de prisión<span class="tooltiptext">it also has its own dangers.</span></span>
		<span class="tooltip">para cualquier persona que sea sorprendida
difundiendo datos falsos.<span class="tooltiptext">For instance, Malaysia just instituted
a six-year prison sentence</span></span>
		<span class="tooltip">Y en los regímenes autoritarios,<span class="tooltiptext">for anyone found spreading misinformation.</span></span>
		<span class="tooltip">este tipo de políticas se pueden utilizar 
para suprimir las opiniones minoritarias<span class="tooltiptext">And in authoritarian regimes,</span></span>
		<span class="tooltip">y para seguir ampliando la represión.<span class="tooltiptext">these kinds of policies can be used
to suppress minority opinions</span></span>
		<span class="tooltip">La cuarta opción posible 
es la transparencia.<span class="tooltiptext">and to continue to extend repression.</span></span>
		<span class="tooltip">Queremos saber cómo funcionan
los algoritmos de Facebook.<span class="tooltiptext">The fourth possible option
is transparency.</span></span>
		<span class="tooltip">¿De qué manera los datos 
se combinan con los algoritmos<span class="tooltiptext">We want to know
how do Facebook&#39;s algorithms work.</span></span>
		<span class="tooltip">para producir los resultados que vemos?<span class="tooltiptext">How does the data
combine with the algorithms</span></span>
		<span class="tooltip">Queremos que abran el kimono<span class="tooltiptext">to produce the outcomes that we see?</span></span>
		<span class="tooltip">y nos muestren exactamente 
el funcionamiento interno de Facebook.<span class="tooltiptext">We want them to open the kimono</span></span>
		<span class="tooltip">Y si queremos conocer el efecto
de las redes sociales en la sociedad,<span class="tooltiptext">and show us exactly the inner workings
of how Facebook is working.</span></span>
		<span class="tooltip">necesitamos que científicos, 
investigadores y otras personas<span class="tooltiptext">And if we want to know
social media&#39;s effect on society,</span></span>
		<span class="tooltip">tengan acceso a este tipo de información.<span class="tooltiptext">we need scientists, researchers</span></span>
		<span class="tooltip">Pero al mismo tiempo,<span class="tooltiptext">and others to have access
to this kind of information.</span></span>
		<span class="tooltip">estamos pidiendo a Facebook 
poner todo bajo llave<span class="tooltiptext">But at the same time,</span></span>
		<span class="tooltip">para mantener los datos seguros.<span class="tooltiptext">we are asking Facebook
to lock everything down,</span></span>
		<span class="tooltip">Así, Facebook y las otras 
plataformas de medios sociales<span class="tooltiptext">to keep all of the data secure.</span></span>
		<span class="tooltip">se enfrentan a lo que llamo 
&quot;la paradoja de la transparencia&quot;.<span class="tooltiptext">So, Facebook and the other
social media platforms</span></span>
		<span class="tooltip">Les estamos pidiendo<span class="tooltiptext">are facing what I call
a transparency paradox.</span></span>
		<span class="tooltip">que sean abiertas, transparentes 
y, al mismo tiempo, seguras.<span class="tooltiptext">We are asking them, at the same time,</span></span>
		<span class="tooltip">Esta es una aguja muy difícil enhebrar,<span class="tooltiptext">to be open and transparent
and, simultaneously secure.</span></span>
		<span class="tooltip">pero deberán enhebrar esta aguja<span class="tooltiptext">This is a very difficult needle to thread,</span></span>
		<span class="tooltip">si queremos alcanzar la promesa 
de las tecnologías sociales<span class="tooltiptext">but they will need to thread this needle</span></span>
		<span class="tooltip">y, a la vez, evitar sus riesgos.<span class="tooltiptext">if we are to achieve the promise
of social technologies</span></span>
		<span class="tooltip">La última opción posible<span class="tooltiptext">while avoiding their peril.</span></span>
		<span class="tooltip">son los algoritmos 
y el aprendizaje automático,<span class="tooltiptext">The final thing that we could think about
is algorithms and machine learning.</span></span>
		<span class="tooltip">tecnología ideada para erradicar 
y entender las noticias falsas,<span class="tooltiptext">Technology devised to root out
and understand fake news, how it spreads,</span></span>
		<span class="tooltip">cómo se transmiten, 
y tratar de reducir su difusión.<span class="tooltiptext">and to try and dampen its flow.</span></span>
		<span class="tooltip">La humanidad tiene que estar
en el bucle de esta tecnología,<span class="tooltiptext">Humans have to be in the loop
of this technology,</span></span>
		<span class="tooltip">porque nunca podremos negar<span class="tooltiptext">because we can never escape</span></span>
		<span class="tooltip">que detrás de cualquier
solución o enfoque tecnológico<span class="tooltiptext">that underlying any technological
solution or approach</span></span>
		<span class="tooltip">hay una pregunta ética
y filosófica fundamental<span class="tooltiptext">is a fundamental ethical
and philosophical question</span></span>
		<span class="tooltip">acerca de cómo definimos
la verdad y la falsedad,<span class="tooltiptext">about how do we define truth and falsity,</span></span>
		<span class="tooltip">a quién le damos el poder
de definir la verdad y la mentira,<span class="tooltiptext">to whom do we give the power
to define truth and falsity</span></span>
		<span class="tooltip">y qué opiniones son legítimas,<span class="tooltiptext">and which opinions are legitimate,</span></span>
		<span class="tooltip">qué tipo de discurso 
debe permitirse y así sucesivamente.<span class="tooltiptext">which type of speech
should be allowed and so on.</span></span>
		<span class="tooltip">La tecnología no es 
una solución en este caso.<span class="tooltiptext">Technology is not a solution for that.</span></span>
		<span class="tooltip">La ética y la filosofía son la solución.<span class="tooltiptext">Ethics and philosophy
is a solution for that.</span></span>
		<span class="tooltip">Casi todas las teorías 
de la toma de decisiones humanas,<span class="tooltiptext">Nearly every theory
of human decision making,</span></span>
		<span class="tooltip">la cooperación humana
y la coordinación humana<span class="tooltiptext">human cooperation and human coordination</span></span>
		<span class="tooltip">tienen un cierto sentido 
de la verdad en su esencia.<span class="tooltiptext">has some sense of the truth at its core.</span></span>
		<span class="tooltip">Pero con el aumento de noticias falsas,<span class="tooltiptext">But with the rise of fake news,</span></span>
		<span class="tooltip">de videos falsos,<span class="tooltiptext">the rise of fake video,</span></span>
		<span class="tooltip">de audios falsos,<span class="tooltiptext">the rise of fake audio,</span></span>
		<span class="tooltip">estamos al borde del precipicio 
del fin de la realidad,<span class="tooltiptext">we are teetering on the brink
of the end of reality,</span></span>
		<span class="tooltip">donde no podemos diferenciar
lo que es real de lo que es falso.<span class="tooltiptext">where we cannot tell
what is real from what is fake.</span></span>
		<span class="tooltip">Y eso es potencialmente 
muy peligroso.<span class="tooltiptext">And that&#39;s potentially
incredibly dangerous.</span></span>
		<span class="tooltip">Tenemos que estar vigilantes 
en la defensa de la verdad<span class="tooltiptext">We have to be vigilant
in defending the truth</span></span>
		<span class="tooltip">contra la información errónea,<span class="tooltiptext">against misinformation.</span></span>
		<span class="tooltip">con nuestras tecnologías, 
con nuestras políticas<span class="tooltiptext">With our technologies, with our policies</span></span>
		<span class="tooltip">y, quizás lo más importante,<span class="tooltiptext">and, perhaps most importantly,</span></span>
		<span class="tooltip">con nuestras propias responsabilidades,<span class="tooltiptext">with our own individual responsibilities,</span></span>
		<span class="tooltip">decisiones, comportamientos
y acciones individuales.<span class="tooltiptext">decisions, behaviors and actions.</span></span>
		<span class="tooltip">Muchas gracias.<span class="tooltiptext">Thank you very much.</span></span>
		<span class="tooltip">(Aplausos)<span class="tooltiptext">(Applause)</span></span>
	</p>

	<div class="line"></div>
	<p>Enjoying my website? Your donation helps maintain its ad-free experience and smooth operation. Your support is truly appreciated and helps me continue providing quality content. Thank you for considering a donation!</p>
	<p>To donate, simply click the PayPal link below:<p/>
	<p><a href="https://www.paypal.com/paypalme/otechai" target='_blank'>Donate via PayPal</a></p>
	
</div>
<span onclick='topFunction()' id='gotop' title='Go to top'><svg width="32" height="32" viewBox="0 0 100 100">
	   <path fill="white" d="m50 0c-13.262 0-25.98 5.2695-35.355 14.645s-14.645 22.094-14.645 35.355 5.2695 25.98 14.645 35.355 22.094 14.645 35.355 14.645 25.98-5.2695 35.355-14.645 14.645-22.094 14.645-35.355-5.2695-25.98-14.645-35.355-22.094-14.645-35.355-14.645zm20.832 62.5-20.832-22.457-20.625 22.457c-1.207 0.74219-2.7656 0.57812-3.7891-0.39844-1.0273-0.98047-1.2695-2.5273-0.58594-3.7695l22.918-25c0.60156-0.61328 1.4297-0.96094 2.2891-0.96094 0.86328 0 1.6914 0.34766 2.293 0.96094l22.918 25c0.88672 1.2891 0.6875 3.0352-0.47266 4.0898-1.1562 1.0508-2.9141 1.0859-4.1133 0.078125z"></path>
	 </svg></span>

	    <div class="footer">
	        <div class="left"><a href='../../../index.html'>ReadingDB</a></div>
	        <div class="center"><a href="https://twitter.com/readingdb" class="twitter-link">
	    <svg class="twitter-icon" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg">
	        <path d="M22.46 6c-.85.38-1.78.64-2.75.76 1-.6 1.76-1.55 2.12-2.68-.93.55-1.96.95-3.06 1.17-.88-.94-2.13-1.53-3.51-1.53-2.66 0-4.81 2.16-4.81 4.81 0 .38.04.75.13 1.1-4-.2-7.58-2.11-9.96-5.02-.42.72-.66 1.56-.66 2.46 0 1.68.85 3.16 2.14 4.02-.79-.02-1.53-.24-2.18-.6v.06c0 2.35 1.67 4.31 3.88 4.76-.4.1-.83.16-1.27.16-.31 0-.62-.03-.92-.08.63 1.96 2.45 3.39 4.61 3.43-1.69 1.32-3.83 2.1-6.15 2.1-.4 0-.8-.02-1.19-.07 2.19 1.4 4.78 2.22 7.57 2.22 9.07 0 14.02-7.52 14.02-14.02 0-.21 0-.41-.01-.61.96-.69 1.79-1.56 2.45-2.55-.88.39-1.83.65-2.82.77z"/>
	    </svg>
	</a></div>
	        <div class="right"><a href='https://www.paypal.com/paypalme/otechai'>Donate</a></div>
	    </div>
	<script>

		var mybutton = document.getElementById('gotop');
		window.onscroll = function() {scrollFunction()};
		function scrollFunction() {
			if (document.documentElement.scrollTop > 20 || document.body.scrollTop > 20) {
				mybutton.style.display = 'block';
			} else {
				mybutton.style.display = 'none';
			}
		}
		function topFunction() {
			document.body.scrollTop = 0;
			document.documentElement.scrollTop = 0;
		}
	</script>
	<script src="../../../static/scripts/script.js"></script>
</body>
</html>
	